{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DH-Parametertabelle youBot\n",
    "\n",
    "$\\begin{array}{rr} \\hline\n",
    "\\mathbf{Gelenk} &\\mathbf{\\theta} &\\mathbf{d} &\\mathbf{a} &\\mathbf{\\alpha} \\\\ \\hline\n",
    "\\mathbf{1} &0        &0.075 &0.033 &-\\pi / 2 \\\\ \\hline\n",
    "\\mathbf{2} &-\\pi / 2 &0     &0.155 &0 \\\\ \\hline\n",
    "\\mathbf{3} &0        &0     &0.135 &0 \\\\ \\hline\n",
    "\\mathbf{4} &\\pi / 2  &0     &0     &\\pi / 2 \\\\ \\hline\n",
    "\\mathbf{5} &\\pi / 2  &0.218 &0     &0 \\\\ \\hline\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DH Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# dh_theta_values = np.array([0, -np.pi / 2, 0, np.pi / 2, np.pi / 2])\n",
    "# dh_alpha_values = np.array([-np.pi / 2, 0, 0, np.pi / 2, 0])\n",
    "# dh_a_values = np.array([0.033, 0.155, 0.135, 0, 0])\n",
    "# dh_d_values = np.array([0.075, 0, 0, 0, 0.218])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir programmieren nun eine Python-Funktion <b>dhIthFrame</b> zur Erstellung eines einzelnen DH-Frames. Dabei übergeben wir noch keine Parameter, sondern bleiben gänzlich auf symbolischer Ebene mit $\\theta$, $d$, $a$ und $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dhIthFrame(theta, d, a, alpha):\n",
    "    \n",
    "#     rot_theta = np.matrix([ [np.cos(theta), -np.sin(theta), 0, 0], \n",
    "#                             [np.sin(theta), np.cos(theta), 0, 0], [0, 0, 1, 0], \n",
    "#                             [0, 0, 0, 1] ])\n",
    "    \n",
    "#     trans_d = np.matrix([ [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, d], [0, 0, 0, 1] ])\n",
    "#     trans_a = np.matrix([ [1, 0, 0, a], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1] ])\n",
    "    \n",
    "#     rot_alpha = np.matrix([ [1, 0, 0, 0], \n",
    "#                             [0, np.cos(alpha), -np.sin(alpha), 0], \n",
    "#                             [0, np.sin(alpha), np.cos(alpha), 0], [0, 0, 0, 1] ])\n",
    "    \n",
    "#     dh_ith_frame = rot_theta * trans_d * trans_a * rot_alpha\n",
    "    \n",
    "#     return dh_ith_frame;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses DH-Frame ist unsere Blaupause für die Forwärtstransformation am youBot. Wir definieren eine Python-Funktion <b>buildDhTcpFrame</b>, in welcher wir die Argumente eines solchen Blaupause-Frames durch die DH-Parameter und den Symbolen für die Gelenkwinkel $q_{1}$ bis $q_{5}$ iterativ substituieren und die resultierenden Frames zu einem Ergebnis-Frame akkumulieren. Anschließend vereinfachen wir noch das Ergebnis mit <b>trigsimp</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def buildDhTcpFrame(q_array):\n",
    "#     dh_frame = np.identity(4)\n",
    "      \n",
    "#     for i in range(5):\n",
    "#         tmp_dh_ith = dhIthFrame(q_array[i] + dh_theta_values[i], \n",
    "#                                 dh_d_values[i], \n",
    "#                                 dh_a_values[i], \n",
    "#                                 dh_alpha_values[i])\n",
    "#         dh_frame = np.matmul(dh_frame, tmp_dh_ith)\n",
    "    \n",
    "#     return dh_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    dmax = np.radians(165)\n",
    "    dmin = np.radians(-168)\n",
    "\n",
    "    for i, arr in enumerate(data):\n",
    "        for j, value in enumerate(arr):\n",
    "            data[i][j] = (2 * (value - dmin) / (dmax - dmin)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(data):\n",
    "    dmax = np.radians(165)\n",
    "    dmin = np.radians(-168)\n",
    "    \n",
    "    for i, arr in enumerate(data):\n",
    "        for j, value in enumerate(arr):\n",
    "            data[i][j] = (((value + 1) * (dmax - dmin)) / 2) + dmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "def generate_data(iterations=5):\n",
    "    #Maximale und minimale Werte (based on robo freedom tests) */\n",
    "    a1 = [165, -168]\n",
    "    a2 = [85, -64]\n",
    "    a3 = [145, -141]\n",
    "    a4 = [101, -101]\n",
    "    a5 = [155, -161]\n",
    "    joint_limits = [a1, a2, a3, a4, a5]\n",
    "    pos_arr = []\n",
    "    for i in range(iterations):\n",
    "        degree_joint_pos = []\n",
    "        for joint_range in joint_limits:\n",
    "            joint_val = np.random.randint(joint_range[1], joint_range[0] + 1)\n",
    "            degree_joint_pos.append(joint_val)\n",
    "        degree_joint_pos = np.asarray(degree_joint_pos)\n",
    "        radians = np.radians(degree_joint_pos)\n",
    "#         radians = degree_joint_pos\n",
    "        pos_arr.append(radians)\n",
    "    \n",
    "    positions = np.asarray(pos_arr)\n",
    "    \n",
    "    tcp = []\n",
    "    for i in range(iterations):\n",
    "        frame = utils.buildDhTcpFrame(positions[i])\n",
    "        frame = np.asarray(frame.flatten())\n",
    "        frame = frame[0:, :12]\n",
    "        frame = np.squeeze(frame)\n",
    "#         xyz = frame[3::4]\n",
    "#         frame[3] *= 100\n",
    "#         frame[7] *= 100\n",
    "#         frame[11] *= 100\n",
    "        tcp.append(frame)\n",
    "\n",
    "    tcp = np.asarray(tcp)\n",
    "\n",
    "    return positions, tcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteDuplicate(tcp, pos):\n",
    "    isDuplicate = []\n",
    "    for i in range(len(tcp)):\n",
    "        xyz = tcp[i][3::4]\n",
    "        for j in range((i+1), len(tcp)):\n",
    "            xyz_ = tcp[j][3::4]\n",
    "            if xyz[0] == xyz_[0] and xyz[1] == xyz_[1] and xyz[2] == xyz_[2]:\n",
    "                isDuplicate.append(i)\n",
    "    \n",
    "#     print(len(isDuplicate))\n",
    "    new_tcp = np.delete(tcp, isDuplicate, 0)\n",
    "    new_joint_pos = np.delete(pos, isDuplicate, 0)\n",
    "    return new_tcp, new_joint_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kuka YouBot Gelenkwinkelgrenzenin Grad [+/-]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(np.random.randint(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_step(iterations=100):\n",
    "    #Maximale und minimale Werte (based on robo freedom tests) */\n",
    "    a1 = [165, -168]\n",
    "    a2 = [85, -64]\n",
    "    a3 = [145, -141]\n",
    "    a4 = [101, -101]\n",
    "    a5 = [155, -161]\n",
    "    joint_limits = [a1, a2, a3, a4, a5]\n",
    "    state = np.zeros(5)\n",
    "    pos_arr = []\n",
    "    \n",
    "    \n",
    "    for i in range(iterations):\n",
    "        degree_joint_pos = []\n",
    "        for i, joint_range in enumerate(joint_limits):\n",
    "            step = (2*np.random.randint(0,2)-1) * np.random.randint(1,6)\n",
    "            if((step + state[i]) > joint_range[0] or (step + state[i]) < joint_range[1]):\n",
    "                step *= -np.random.randint(1,6)\n",
    "            state[i]+= step\n",
    "            degree_joint_pos.append(state[i])\n",
    "\n",
    "        degree_joint_pos = np.asarray(degree_joint_pos)\n",
    "        radians = np.radians(degree_joint_pos)\n",
    "        pos_arr.append(radians)\n",
    "    \n",
    "#     for i, joint_range in enumerate(joint_limits):\n",
    "#         for joint_val in range(joint_range[1], joint_range[0] + 1):\n",
    "#             degree_joint_pos = []\n",
    "#             for j in range(5):\n",
    "#                 if i is j:\n",
    "#                     degree_joint_pos.append(joint_val)\n",
    "#                 else:\n",
    "#                     degree_joint_pos.append(state[i])\n",
    "            \n",
    "#             degree_joint_pos = np.asarray(degree_joint_pos)\n",
    "#             radians = np.radians(degree_joint_pos)\n",
    "# #         radians = degree_joint_pos\n",
    "#             pos_arr.append(radians)\n",
    "#     state[i] = joint_range[0]\n",
    "    \n",
    "    positions = np.asarray(pos_arr)\n",
    "    print(\"positions calculated\")\n",
    "    tcp = []\n",
    "    for i in range(len(positions)):\n",
    "        frame = utils.buildDhTcpFrame(positions[i])\n",
    "        frame = np.asarray(frame.flatten())\n",
    "        frame = frame[0:, :12]\n",
    "        frame = np.squeeze(frame)\n",
    "#         xyz = frame[3::4]\n",
    "#         frame[3] *= 100\n",
    "#         frame[7] *= 100\n",
    "#         frame[11] *= 100\n",
    "        tcp.append(frame)\n",
    "    \n",
    "    tcp = np.asarray(tcp)\n",
    "    print(\"tcp calculated\")\n",
    "    tcp, positions = deleteDuplicate(tcp, positions)\n",
    "    print(\"duplicates erased\")\n",
    "    return positions, tcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions calculated\n",
      "tcp calculated\n",
      "duplicates erased\n",
      "8972\n",
      "8972\n"
     ]
    }
   ],
   "source": [
    "ppos, ttcp = generate_data_step(10000)\n",
    "print(len(ttcp))\n",
    "print(len(ppos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generiere eine Anzahl von zufälligen Gelenkwinkelpositionen und dazugehöriges TCP Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13310742378234863\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "joint_pos, tcp_pos = generate_data(100)\n",
    "# max_tcp = np.amax(np.absolute(tcp_positions))\n",
    "# tcp_positions = tcp_positions / max_tcp\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCP Shape: (100, 12)\n",
      "Joint Shape: (100, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"TCP Shape:\", tcp_pos.shape)\n",
    "print(\"Joint Shape:\", joint_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pytransform3d.rotations import *\n",
    "%matplotlib notebook\n",
    "\n",
    "tcp = tcp_pos\n",
    "\n",
    "ax = plot_basis(R=np.eye(3), ax_s=5)\n",
    "f = 5\n",
    "samples = np.random.randint(0, len(tcp), 5)\n",
    "for i in samples:\n",
    "    point = np.asarray([tcp[i][3] *f, tcp[i][7] *f, tcp[i][11] *f])\n",
    "    rot = np.asarray([[tcp[i][0], tcp[i][1], tcp[i][2]],\n",
    "                      [tcp[i][4], tcp[i][5], tcp[i][6]],\n",
    "                      [tcp[i][8], tcp[i][9], tcp[i][10]]])\n",
    "    plot_basis(ax, R=rot, p=point)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "    \n",
    "# layer = Dense(units=100, \n",
    "#           input_dim=12,\n",
    "#           kernel_initializer='random_normal',\n",
    "#           use_bias=True,\n",
    "#           bias_initializer='random_normal',\n",
    "#           activation='tanh')\n",
    "layer = Dense(units=500, \n",
    "          input_dim=12,\n",
    "          kernel_initializer='random_normal',\n",
    "          use_bias=False)\n",
    "\n",
    "model.add(layer)\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "dropout = Dropout(0.5)\n",
    "model.add(dropout)\n",
    "\n",
    "hidden_layers = 2\n",
    "\n",
    "for i in range(hidden_layers):\n",
    "#     layer = Dense(units=100, \n",
    "#                   kernel_initializer='random_normal',\n",
    "#                   use_bias=True,\n",
    "#                   bias_initializer='random_normal',\n",
    "#                   activation='tanh')\n",
    "    layer = Dense(units=500, \n",
    "                  kernel_initializer='random_normal',\n",
    "                  use_bias=False)\n",
    "    model.add(layer)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    if i is not (hidden_layers - 1):\n",
    "        dropout = Dropout(0.5)\n",
    "        model.add(dropout)\n",
    "    \n",
    "# layer = Dense(units=5, \n",
    "#               kernel_initializer='random_normal',\n",
    "#               use_bias=True,\n",
    "#               bias_initializer='random_normal',\n",
    "#               activation='tanh')\n",
    "layer = Dense(units=5, \n",
    "              kernel_initializer='random_normal',\n",
    "              use_bias=False,\n",
    "              activation='tanh')\n",
    "model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ygtt, ypredt = gen(2)\n",
    "# custom_loss(ygtt[1], ypredt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "# For a mean squared error regression problem\n",
    "rms = RMSprop(learning_rate=0.01, rho=0.9)\n",
    "adam=Adam(lr=1.0e-3)\n",
    "\n",
    "model.compile(optimizer=adam,loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 500)               6000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 500)               250000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 500)               250000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 2500      \n",
      "=================================================================\n",
      "Total params: 514,500\n",
      "Trainable params: 511,500\n",
      "Non-trainable params: 3,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils as tf\n",
    "\n",
    "def gen(batch_size):\n",
    "#     jpos, tcp = generate_data(batch_size)\n",
    "    jpos, tcp = generate_data_step(batch_size)\n",
    "    normalize(jpos)\n",
    "    tpos = tf.normalize(tcp, axis=-1, order=2)\n",
    "    return jpos, tpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "eins = [0.19392999, 0.06677545, 0.0319066 ]\n",
    "zwei = [0.19392999, 0.06677545, 0.0319066 ]\n",
    "\n",
    "if eins == zwei:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "jpos, tpos = gen(100)\n",
    "# isDuplicate(tpos)\n",
    "print(len(jpos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchlauf:  0\n",
      "positions calculated\n",
      "tcp calculated\n",
      "duplicates erased\n",
      "Train on 8996 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "8996/8996 [==============================] - 0s 10us/step - loss: 0.1567 - val_loss: 0.0674\n",
      "Epoch 2/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.1499 - val_loss: 0.0644\n",
      "Epoch 3/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.1392 - val_loss: 0.0614\n",
      "Epoch 4/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.1283 - val_loss: 0.0593\n",
      "Epoch 5/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.1174 - val_loss: 0.0588\n",
      "Epoch 6/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.1093 - val_loss: 0.0597\n",
      "Epoch 7/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.1038 - val_loss: 0.0618\n",
      "Epoch 8/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.1001 - val_loss: 0.0648\n",
      "Epoch 9/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0975 - val_loss: 0.0680\n",
      "Epoch 10/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0962 - val_loss: 0.0710\n",
      "Epoch 11/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0940 - val_loss: 0.0735\n",
      "Epoch 12/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0922 - val_loss: 0.0752\n",
      "Epoch 13/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0904 - val_loss: 0.0761\n",
      "Epoch 14/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0881 - val_loss: 0.0761\n",
      "Epoch 15/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0865 - val_loss: 0.0752\n",
      "Epoch 16/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0844 - val_loss: 0.0737\n",
      "Epoch 17/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0818 - val_loss: 0.0715\n",
      "Epoch 18/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0806 - val_loss: 0.0689\n",
      "Epoch 19/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0794 - val_loss: 0.0659\n",
      "Epoch 20/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0766 - val_loss: 0.0628\n",
      "Epoch 21/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0758 - val_loss: 0.0598\n",
      "Epoch 22/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0748 - val_loss: 0.0569\n",
      "Epoch 23/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0724 - val_loss: 0.0544\n",
      "Epoch 24/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0712 - val_loss: 0.0523\n",
      "Epoch 25/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0699 - val_loss: 0.0507\n",
      "Epoch 26/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0688 - val_loss: 0.0496\n",
      "Epoch 27/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0669 - val_loss: 0.0489\n",
      "Epoch 28/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0662 - val_loss: 0.0485\n",
      "Epoch 29/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0641 - val_loss: 0.0484\n",
      "Epoch 30/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0634 - val_loss: 0.0486\n",
      "Epoch 31/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0624 - val_loss: 0.0489\n",
      "Epoch 32/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0614 - val_loss: 0.0493\n",
      "Epoch 33/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0604 - val_loss: 0.0497\n",
      "Epoch 34/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0602 - val_loss: 0.0501\n",
      "Epoch 35/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0580 - val_loss: 0.0503\n",
      "Epoch 36/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0574 - val_loss: 0.0504\n",
      "Epoch 37/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0575 - val_loss: 0.0502\n",
      "Epoch 38/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0560 - val_loss: 0.0499\n",
      "Epoch 39/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0552 - val_loss: 0.0495\n",
      "Epoch 40/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0546 - val_loss: 0.0489\n",
      "Epoch 41/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0537 - val_loss: 0.0484\n",
      "Epoch 42/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0531 - val_loss: 0.0478\n",
      "Epoch 43/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0523 - val_loss: 0.0473\n",
      "Epoch 44/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0513 - val_loss: 0.0469\n",
      "Epoch 45/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0512 - val_loss: 0.0466\n",
      "Epoch 46/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0503 - val_loss: 0.0464\n",
      "Epoch 47/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0502 - val_loss: 0.0462\n",
      "Epoch 48/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0492 - val_loss: 0.0461\n",
      "Epoch 49/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0491 - val_loss: 0.0460\n",
      "Epoch 50/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0486 - val_loss: 0.0460\n",
      "Epoch 51/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0483 - val_loss: 0.0460\n",
      "Epoch 52/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0478 - val_loss: 0.0461\n",
      "Epoch 53/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0475 - val_loss: 0.0462\n",
      "Epoch 54/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0466 - val_loss: 0.0463\n",
      "Epoch 55/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0463 - val_loss: 0.0465\n",
      "Epoch 56/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0457 - val_loss: 0.0466\n",
      "Epoch 57/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0455 - val_loss: 0.0468\n",
      "Epoch 58/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0449 - val_loss: 0.0469\n",
      "Epoch 59/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0450 - val_loss: 0.0470\n",
      "Epoch 60/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0444 - val_loss: 0.0471\n",
      "Epoch 61/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0439 - val_loss: 0.0471\n",
      "Epoch 62/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0437 - val_loss: 0.0471\n",
      "Epoch 63/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0435 - val_loss: 0.0471\n",
      "Epoch 64/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0431 - val_loss: 0.0471\n",
      "Epoch 65/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0425 - val_loss: 0.0471\n",
      "Epoch 66/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0425 - val_loss: 0.0471\n",
      "Epoch 67/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0420 - val_loss: 0.0471\n",
      "Epoch 68/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0413 - val_loss: 0.0471\n",
      "Epoch 69/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0413 - val_loss: 0.0471\n",
      "Epoch 70/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0410 - val_loss: 0.0471\n",
      "Epoch 71/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0409 - val_loss: 0.0472\n",
      "Epoch 72/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0410 - val_loss: 0.0473\n",
      "Epoch 73/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0401 - val_loss: 0.0473\n",
      "Epoch 74/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0397 - val_loss: 0.0474\n",
      "Epoch 75/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0400 - val_loss: 0.0475\n",
      "Epoch 76/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0398 - val_loss: 0.0476\n",
      "Epoch 77/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0392 - val_loss: 0.0476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0388 - val_loss: 0.0476\n",
      "Epoch 79/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0389 - val_loss: 0.0476\n",
      "Epoch 80/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0381 - val_loss: 0.0475\n",
      "Epoch 81/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0380 - val_loss: 0.0474\n",
      "Epoch 82/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0377 - val_loss: 0.0473\n",
      "Epoch 83/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0377 - val_loss: 0.0472\n",
      "Epoch 84/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0370 - val_loss: 0.0471\n",
      "Epoch 85/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0371 - val_loss: 0.0470\n",
      "Epoch 86/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0365 - val_loss: 0.0470\n",
      "Epoch 87/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0367 - val_loss: 0.0470\n",
      "Epoch 88/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0365 - val_loss: 0.0470\n",
      "Epoch 89/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0364 - val_loss: 0.0470\n",
      "Epoch 90/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0360 - val_loss: 0.0469\n",
      "Epoch 91/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0360 - val_loss: 0.0469\n",
      "Epoch 92/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0361 - val_loss: 0.0469\n",
      "Epoch 93/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0357 - val_loss: 0.0468\n",
      "Epoch 94/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0353 - val_loss: 0.0468\n",
      "Epoch 95/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0350 - val_loss: 0.0468\n",
      "Epoch 96/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0352 - val_loss: 0.0467\n",
      "Epoch 97/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0348 - val_loss: 0.0466\n",
      "Epoch 98/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0343 - val_loss: 0.0466\n",
      "Epoch 99/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0347 - val_loss: 0.0465\n",
      "Epoch 100/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0342 - val_loss: 0.0464\n",
      "Epoch 101/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0341 - val_loss: 0.0464\n",
      "Epoch 102/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0336 - val_loss: 0.0464\n",
      "Epoch 103/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0334 - val_loss: 0.0463\n",
      "Epoch 104/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0333 - val_loss: 0.0463\n",
      "Epoch 105/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0334 - val_loss: 0.0463\n",
      "Epoch 106/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0330 - val_loss: 0.0463\n",
      "Epoch 107/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0328 - val_loss: 0.0463\n",
      "Epoch 108/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0327 - val_loss: 0.0463\n",
      "Epoch 109/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0325 - val_loss: 0.0463\n",
      "Epoch 110/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0328 - val_loss: 0.0463\n",
      "Epoch 111/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0322 - val_loss: 0.0462\n",
      "Epoch 112/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0324 - val_loss: 0.0461\n",
      "Epoch 113/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0318 - val_loss: 0.0461\n",
      "Epoch 114/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0315 - val_loss: 0.0460\n",
      "Epoch 115/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0320 - val_loss: 0.0460\n",
      "Epoch 116/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0316 - val_loss: 0.0459\n",
      "Epoch 117/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0313 - val_loss: 0.0459\n",
      "Epoch 118/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0312 - val_loss: 0.0459\n",
      "Epoch 119/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0313 - val_loss: 0.0459\n",
      "Epoch 120/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0310 - val_loss: 0.0458\n",
      "Epoch 121/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0314 - val_loss: 0.0458\n",
      "Epoch 122/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0311 - val_loss: 0.0457\n",
      "Epoch 123/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0306 - val_loss: 0.0456\n",
      "Epoch 124/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0304 - val_loss: 0.0455\n",
      "Epoch 125/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0305 - val_loss: 0.0455\n",
      "Epoch 126/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0304 - val_loss: 0.0455\n",
      "Epoch 127/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0302 - val_loss: 0.0454\n",
      "Epoch 128/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0299 - val_loss: 0.0454\n",
      "Epoch 129/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0302 - val_loss: 0.0454\n",
      "Epoch 130/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0302 - val_loss: 0.0454\n",
      "Epoch 131/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0293 - val_loss: 0.0454\n",
      "Epoch 132/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0294 - val_loss: 0.0454\n",
      "Epoch 133/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0295 - val_loss: 0.0453\n",
      "Epoch 134/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0291 - val_loss: 0.0453\n",
      "Epoch 135/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0292 - val_loss: 0.0453\n",
      "Epoch 136/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0290 - val_loss: 0.0452\n",
      "Epoch 137/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0291 - val_loss: 0.0451\n",
      "Epoch 138/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0289 - val_loss: 0.0450\n",
      "Epoch 139/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0293 - val_loss: 0.0450\n",
      "Epoch 140/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0285 - val_loss: 0.0449\n",
      "Epoch 141/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0290 - val_loss: 0.0449\n",
      "Epoch 142/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0289 - val_loss: 0.0448\n",
      "Epoch 143/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0286 - val_loss: 0.0448\n",
      "Epoch 144/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0286 - val_loss: 0.0448\n",
      "Epoch 145/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0277 - val_loss: 0.0448\n",
      "Epoch 146/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0282 - val_loss: 0.0447\n",
      "Epoch 147/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0281 - val_loss: 0.0446\n",
      "Epoch 148/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0276 - val_loss: 0.0446\n",
      "Epoch 149/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0275 - val_loss: 0.0445\n",
      "Epoch 150/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0278 - val_loss: 0.0445\n",
      "Epoch 151/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0275 - val_loss: 0.0444\n",
      "Epoch 152/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0277 - val_loss: 0.0444\n",
      "Epoch 153/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0272 - val_loss: 0.0443\n",
      "Epoch 154/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0274 - val_loss: 0.0442\n",
      "Epoch 155/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0271 - val_loss: 0.0441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0272 - val_loss: 0.0441\n",
      "Epoch 157/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0272 - val_loss: 0.0440\n",
      "Epoch 158/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0274 - val_loss: 0.0440\n",
      "Epoch 159/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0269 - val_loss: 0.0440\n",
      "Epoch 160/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0263 - val_loss: 0.0440\n",
      "Epoch 161/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0266 - val_loss: 0.0440\n",
      "Epoch 162/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0265 - val_loss: 0.0440\n",
      "Epoch 163/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0267 - val_loss: 0.0440\n",
      "Epoch 164/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0263 - val_loss: 0.0440\n",
      "Epoch 165/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0264 - val_loss: 0.0440\n",
      "Epoch 166/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0260 - val_loss: 0.0440\n",
      "Epoch 167/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0263 - val_loss: 0.0439\n",
      "Epoch 168/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0263 - val_loss: 0.0438\n",
      "Epoch 169/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0262 - val_loss: 0.0438\n",
      "Epoch 170/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0260 - val_loss: 0.0438\n",
      "Epoch 171/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0262 - val_loss: 0.0437\n",
      "Epoch 172/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0256 - val_loss: 0.0437\n",
      "Epoch 173/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0260 - val_loss: 0.0436\n",
      "Epoch 174/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0256 - val_loss: 0.0435\n",
      "Epoch 175/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0257 - val_loss: 0.0434\n",
      "Epoch 176/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0260 - val_loss: 0.0434\n",
      "Epoch 177/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0254 - val_loss: 0.0433\n",
      "Epoch 178/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0255 - val_loss: 0.0433\n",
      "Epoch 179/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0251 - val_loss: 0.0432\n",
      "Epoch 180/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0255 - val_loss: 0.0432\n",
      "Epoch 181/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0251 - val_loss: 0.0432\n",
      "Epoch 182/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0250 - val_loss: 0.0433\n",
      "Epoch 183/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0250 - val_loss: 0.0433\n",
      "Epoch 184/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0244 - val_loss: 0.0433\n",
      "Epoch 185/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0246 - val_loss: 0.0433\n",
      "Epoch 186/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0250 - val_loss: 0.0433\n",
      "Epoch 187/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0246 - val_loss: 0.0433\n",
      "Epoch 188/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0245 - val_loss: 0.0433\n",
      "Epoch 189/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0246 - val_loss: 0.0432\n",
      "Epoch 190/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0246 - val_loss: 0.0432\n",
      "Epoch 191/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0244 - val_loss: 0.0431\n",
      "Epoch 192/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0247 - val_loss: 0.0431\n",
      "Epoch 193/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0246 - val_loss: 0.0430\n",
      "Epoch 194/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0246 - val_loss: 0.0429\n",
      "Epoch 195/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0240 - val_loss: 0.0429\n",
      "Epoch 196/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0246 - val_loss: 0.0428\n",
      "Epoch 197/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0242 - val_loss: 0.0428\n",
      "Epoch 198/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0239 - val_loss: 0.0428\n",
      "Epoch 199/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0239 - val_loss: 0.0428\n",
      "Epoch 200/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0240 - val_loss: 0.0427\n",
      "Epoch 201/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0242 - val_loss: 0.0427\n",
      "Epoch 202/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0238 - val_loss: 0.0427\n",
      "Epoch 203/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0236 - val_loss: 0.0426\n",
      "Epoch 204/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0237 - val_loss: 0.0426\n",
      "Epoch 205/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0233 - val_loss: 0.0426\n",
      "Epoch 206/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0236 - val_loss: 0.0426\n",
      "Epoch 207/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0235 - val_loss: 0.0426\n",
      "Epoch 208/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0233 - val_loss: 0.0426\n",
      "Epoch 209/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0231 - val_loss: 0.0426\n",
      "Epoch 210/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0231 - val_loss: 0.0426\n",
      "Epoch 211/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0233 - val_loss: 0.0425\n",
      "Epoch 212/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0231 - val_loss: 0.0425\n",
      "Epoch 213/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0231 - val_loss: 0.0424\n",
      "Epoch 214/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0231 - val_loss: 0.0424\n",
      "Epoch 215/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0232 - val_loss: 0.0424\n",
      "Epoch 216/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0228 - val_loss: 0.0424\n",
      "Epoch 217/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0230 - val_loss: 0.0424\n",
      "Epoch 218/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0230 - val_loss: 0.0424\n",
      "Epoch 219/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0231 - val_loss: 0.0424\n",
      "Epoch 220/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0225 - val_loss: 0.0423\n",
      "Epoch 221/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0228 - val_loss: 0.0423\n",
      "Epoch 222/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0224 - val_loss: 0.0423\n",
      "Epoch 223/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0227 - val_loss: 0.0423\n",
      "Epoch 224/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0228 - val_loss: 0.0422\n",
      "Epoch 225/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0225 - val_loss: 0.0422\n",
      "Epoch 226/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0224 - val_loss: 0.0422\n",
      "Epoch 227/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0224 - val_loss: 0.0422\n",
      "Epoch 228/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0226 - val_loss: 0.0422\n",
      "Epoch 229/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0221 - val_loss: 0.0422\n",
      "Epoch 230/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0220 - val_loss: 0.0422\n",
      "Epoch 231/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0226 - val_loss: 0.0422\n",
      "Epoch 232/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0225 - val_loss: 0.0421\n",
      "Epoch 233/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0223 - val_loss: 0.0421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0221 - val_loss: 0.0420\n",
      "Epoch 235/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0219 - val_loss: 0.0419\n",
      "Epoch 236/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0222 - val_loss: 0.0419\n",
      "Epoch 237/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0220 - val_loss: 0.0418\n",
      "Epoch 238/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0220 - val_loss: 0.0418\n",
      "Epoch 239/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0220 - val_loss: 0.0418\n",
      "Epoch 240/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0218 - val_loss: 0.0418\n",
      "Epoch 241/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0217 - val_loss: 0.0418\n",
      "Epoch 242/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0219 - val_loss: 0.0419\n",
      "Epoch 243/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0219 - val_loss: 0.0419\n",
      "Epoch 244/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0220 - val_loss: 0.0420\n",
      "Epoch 245/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0217 - val_loss: 0.0420\n",
      "Epoch 246/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0215 - val_loss: 0.0420\n",
      "Epoch 247/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0217 - val_loss: 0.0420\n",
      "Epoch 248/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0214 - val_loss: 0.0419\n",
      "Epoch 249/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0215 - val_loss: 0.0419\n",
      "Epoch 250/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0218 - val_loss: 0.0419\n",
      "Epoch 251/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0213 - val_loss: 0.0419\n",
      "Epoch 252/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0211 - val_loss: 0.0418\n",
      "Epoch 253/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0213 - val_loss: 0.0419\n",
      "Epoch 254/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0212 - val_loss: 0.0419\n",
      "Epoch 255/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0213 - val_loss: 0.0419\n",
      "Epoch 256/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0213 - val_loss: 0.0419\n",
      "Epoch 257/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0211 - val_loss: 0.0419\n",
      "Epoch 258/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0210 - val_loss: 0.0418\n",
      "Epoch 259/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0210 - val_loss: 0.0418\n",
      "Epoch 260/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0210 - val_loss: 0.0417\n",
      "Epoch 261/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0213 - val_loss: 0.0417\n",
      "Epoch 262/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0208 - val_loss: 0.0417\n",
      "Epoch 263/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0208 - val_loss: 0.0416\n",
      "Epoch 264/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0208 - val_loss: 0.0416\n",
      "Epoch 265/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0207 - val_loss: 0.0416\n",
      "Epoch 266/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0205 - val_loss: 0.0416\n",
      "Epoch 267/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0207 - val_loss: 0.0416\n",
      "Epoch 268/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0204 - val_loss: 0.0416\n",
      "Epoch 269/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0208 - val_loss: 0.0416\n",
      "Epoch 270/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0205 - val_loss: 0.0416\n",
      "Epoch 271/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0203 - val_loss: 0.0416\n",
      "Epoch 272/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0205 - val_loss: 0.0416\n",
      "Epoch 273/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0205 - val_loss: 0.0416\n",
      "Epoch 274/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0205 - val_loss: 0.0417\n",
      "Epoch 275/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0205 - val_loss: 0.0416\n",
      "Epoch 276/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0202 - val_loss: 0.0416\n",
      "Epoch 277/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0202 - val_loss: 0.0416\n",
      "Epoch 278/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0201 - val_loss: 0.0416\n",
      "Epoch 279/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0202 - val_loss: 0.0416\n",
      "Epoch 280/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0204 - val_loss: 0.0415\n",
      "Epoch 281/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0203 - val_loss: 0.0415\n",
      "Epoch 282/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0202 - val_loss: 0.0415\n",
      "Epoch 283/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0201 - val_loss: 0.0414\n",
      "Epoch 284/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0202 - val_loss: 0.0414\n",
      "Epoch 285/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0201 - val_loss: 0.0414\n",
      "Epoch 286/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0199 - val_loss: 0.0413\n",
      "Epoch 287/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0204 - val_loss: 0.0413\n",
      "Epoch 288/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0199 - val_loss: 0.0413\n",
      "Epoch 289/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0196 - val_loss: 0.0412\n",
      "Epoch 290/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0198 - val_loss: 0.0412\n",
      "Epoch 291/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0201 - val_loss: 0.0412\n",
      "Epoch 292/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0200 - val_loss: 0.0412\n",
      "Epoch 293/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0197 - val_loss: 0.0413\n",
      "Epoch 294/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0197 - val_loss: 0.0413\n",
      "Epoch 295/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0196 - val_loss: 0.0413\n",
      "Epoch 296/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0193 - val_loss: 0.0414\n",
      "Epoch 297/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0194 - val_loss: 0.0414\n",
      "Epoch 298/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0195 - val_loss: 0.0414\n",
      "Epoch 299/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0197 - val_loss: 0.0414\n",
      "Epoch 300/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0195 - val_loss: 0.0414\n",
      "Epoch 301/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0195 - val_loss: 0.0414\n",
      "Epoch 302/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0195 - val_loss: 0.0414\n",
      "Epoch 303/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0195 - val_loss: 0.0414\n",
      "Epoch 304/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0193 - val_loss: 0.0414\n",
      "Epoch 305/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0191 - val_loss: 0.0415\n",
      "Epoch 306/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0196 - val_loss: 0.0415\n",
      "Epoch 307/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0193 - val_loss: 0.0415\n",
      "Epoch 308/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0197 - val_loss: 0.0415\n",
      "Epoch 309/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0193 - val_loss: 0.0414\n",
      "Epoch 310/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0192 - val_loss: 0.0414\n",
      "Epoch 311/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0193 - val_loss: 0.0413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0189 - val_loss: 0.0412\n",
      "Epoch 313/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0190 - val_loss: 0.0412\n",
      "Epoch 314/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0192 - val_loss: 0.0412\n",
      "Epoch 315/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0189 - val_loss: 0.0411\n",
      "Epoch 316/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0191 - val_loss: 0.0411\n",
      "Epoch 317/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0188 - val_loss: 0.0410\n",
      "Epoch 318/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0188 - val_loss: 0.0409\n",
      "Epoch 319/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0191 - val_loss: 0.0409\n",
      "Epoch 320/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0188 - val_loss: 0.0409\n",
      "Epoch 321/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0185 - val_loss: 0.0409\n",
      "Epoch 322/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0189 - val_loss: 0.0409\n",
      "Epoch 323/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0186 - val_loss: 0.0409\n",
      "Epoch 324/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0189 - val_loss: 0.0409\n",
      "Epoch 325/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0186 - val_loss: 0.0410\n",
      "Epoch 326/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0188 - val_loss: 0.0410\n",
      "Epoch 327/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0188 - val_loss: 0.0410\n",
      "Epoch 328/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0186 - val_loss: 0.0410\n",
      "Epoch 329/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0186 - val_loss: 0.0411\n",
      "Epoch 330/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0185 - val_loss: 0.0411\n",
      "Epoch 331/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0185 - val_loss: 0.0411\n",
      "Epoch 332/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0184 - val_loss: 0.0411\n",
      "Epoch 333/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0184 - val_loss: 0.0412\n",
      "Epoch 334/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0186 - val_loss: 0.0412\n",
      "Epoch 335/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0184 - val_loss: 0.0411\n",
      "Epoch 336/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0183 - val_loss: 0.0411\n",
      "Epoch 337/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0186 - val_loss: 0.0410\n",
      "Epoch 338/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0182 - val_loss: 0.0409\n",
      "Epoch 339/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0182 - val_loss: 0.0409\n",
      "Epoch 340/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0183 - val_loss: 0.0408\n",
      "Epoch 341/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0181 - val_loss: 0.0408\n",
      "Epoch 342/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0183 - val_loss: 0.0408\n",
      "Epoch 343/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0181 - val_loss: 0.0408\n",
      "Epoch 344/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0180 - val_loss: 0.0409\n",
      "Epoch 345/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0181 - val_loss: 0.0409\n",
      "Epoch 346/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0180 - val_loss: 0.0409\n",
      "Epoch 347/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 0.0408\n",
      "Epoch 348/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0182 - val_loss: 0.0408\n",
      "Epoch 349/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0184 - val_loss: 0.0408\n",
      "Epoch 350/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0177 - val_loss: 0.0408\n",
      "Epoch 351/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0182 - val_loss: 0.0408\n",
      "Epoch 352/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0179 - val_loss: 0.0409\n",
      "Epoch 353/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0180 - val_loss: 0.0409\n",
      "Epoch 354/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0179 - val_loss: 0.0409\n",
      "Epoch 355/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0184 - val_loss: 0.0409\n",
      "Epoch 356/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0180 - val_loss: 0.0410\n",
      "Epoch 357/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0180 - val_loss: 0.0410\n",
      "Epoch 358/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0178 - val_loss: 0.0410\n",
      "Epoch 359/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0179 - val_loss: 0.0409\n",
      "Epoch 360/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0179 - val_loss: 0.0409\n",
      "Epoch 361/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0178 - val_loss: 0.0408\n",
      "Epoch 362/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0177 - val_loss: 0.0407\n",
      "Epoch 363/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0173 - val_loss: 0.0406\n",
      "Epoch 364/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0175 - val_loss: 0.0406\n",
      "Epoch 365/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0178 - val_loss: 0.0405\n",
      "Epoch 366/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0177 - val_loss: 0.0405\n",
      "Epoch 367/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0176 - val_loss: 0.0406\n",
      "Epoch 368/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0176 - val_loss: 0.0406\n",
      "Epoch 369/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0175 - val_loss: 0.0406\n",
      "Epoch 370/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0176 - val_loss: 0.0407\n",
      "Epoch 371/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0176 - val_loss: 0.0407\n",
      "Epoch 372/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0176 - val_loss: 0.0408\n",
      "Epoch 373/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0178 - val_loss: 0.0408\n",
      "Epoch 374/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0174 - val_loss: 0.0408\n",
      "Epoch 375/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0178 - val_loss: 0.0407\n",
      "Epoch 376/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0174 - val_loss: 0.0407\n",
      "Epoch 377/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0175 - val_loss: 0.0406\n",
      "Epoch 378/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0173 - val_loss: 0.0406\n",
      "Epoch 379/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0175 - val_loss: 0.0406\n",
      "Epoch 380/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0172 - val_loss: 0.0406\n",
      "Epoch 381/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0174 - val_loss: 0.0406\n",
      "Epoch 382/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 0.0407\n",
      "Epoch 383/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 0.0407\n",
      "Epoch 384/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 0.0407\n",
      "Epoch 385/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0174 - val_loss: 0.0408\n",
      "Epoch 386/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0175 - val_loss: 0.0408\n",
      "Epoch 387/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0172 - val_loss: 0.0407\n",
      "Epoch 388/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0170 - val_loss: 0.0407\n",
      "Epoch 389/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0172 - val_loss: 0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0171 - val_loss: 0.0406\n",
      "Epoch 391/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0173 - val_loss: 0.0406\n",
      "Epoch 392/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0170 - val_loss: 0.0405\n",
      "Epoch 393/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0170 - val_loss: 0.0405\n",
      "Epoch 394/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0170 - val_loss: 0.0405\n",
      "Epoch 395/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0169 - val_loss: 0.0405\n",
      "Epoch 396/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0172 - val_loss: 0.0406\n",
      "Epoch 397/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0170 - val_loss: 0.0406\n",
      "Epoch 398/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0169 - val_loss: 0.0406\n",
      "Epoch 399/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0406\n",
      "Epoch 400/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0167 - val_loss: 0.0406\n",
      "Epoch 401/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0172 - val_loss: 0.0405\n",
      "Epoch 402/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0167 - val_loss: 0.0405\n",
      "Epoch 403/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0404\n",
      "Epoch 404/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0168 - val_loss: 0.0404\n",
      "Epoch 405/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0170 - val_loss: 0.0404\n",
      "Epoch 406/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0168 - val_loss: 0.0404\n",
      "Epoch 407/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0404\n",
      "Epoch 408/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0169 - val_loss: 0.0404\n",
      "Epoch 409/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0166 - val_loss: 0.0405\n",
      "Epoch 410/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0166 - val_loss: 0.0405\n",
      "Epoch 411/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0405\n",
      "Epoch 412/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0164 - val_loss: 0.0405\n",
      "Epoch 413/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0168 - val_loss: 0.0405\n",
      "Epoch 414/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0165 - val_loss: 0.0406\n",
      "Epoch 415/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0165 - val_loss: 0.0406\n",
      "Epoch 416/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0165 - val_loss: 0.0406\n",
      "Epoch 417/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0166 - val_loss: 0.0406\n",
      "Epoch 418/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0166 - val_loss: 0.0405\n",
      "Epoch 419/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0163 - val_loss: 0.0405\n",
      "Epoch 420/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0168 - val_loss: 0.0405\n",
      "Epoch 421/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0166 - val_loss: 0.0406\n",
      "Epoch 422/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0165 - val_loss: 0.0406\n",
      "Epoch 423/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0406\n",
      "Epoch 424/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0166 - val_loss: 0.0406\n",
      "Epoch 425/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0168 - val_loss: 0.0405\n",
      "Epoch 426/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0165 - val_loss: 0.0405\n",
      "Epoch 427/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0404\n",
      "Epoch 428/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0163 - val_loss: 0.0404\n",
      "Epoch 429/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0404\n",
      "Epoch 430/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0162 - val_loss: 0.0404\n",
      "Epoch 431/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0162 - val_loss: 0.0404\n",
      "Epoch 432/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0164 - val_loss: 0.0404\n",
      "Epoch 433/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0164 - val_loss: 0.0404\n",
      "Epoch 434/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0162 - val_loss: 0.0404\n",
      "Epoch 435/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0163 - val_loss: 0.0404\n",
      "Epoch 436/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0403\n",
      "Epoch 437/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0403\n",
      "Epoch 438/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0159 - val_loss: 0.0402\n",
      "Epoch 439/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0158 - val_loss: 0.0402\n",
      "Epoch 440/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0162 - val_loss: 0.0402\n",
      "Epoch 441/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0162 - val_loss: 0.0402\n",
      "Epoch 442/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0161 - val_loss: 0.0403\n",
      "Epoch 443/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0161 - val_loss: 0.0403\n",
      "Epoch 444/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0161 - val_loss: 0.0403\n",
      "Epoch 445/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0160 - val_loss: 0.0404\n",
      "Epoch 446/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0163 - val_loss: 0.0404\n",
      "Epoch 447/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0157 - val_loss: 0.0404\n",
      "Epoch 448/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0159 - val_loss: 0.0404\n",
      "Epoch 449/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0162 - val_loss: 0.0404\n",
      "Epoch 450/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0404\n",
      "Epoch 451/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0160 - val_loss: 0.0404\n",
      "Epoch 452/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0160 - val_loss: 0.0404\n",
      "Epoch 453/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0404\n",
      "Epoch 454/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0159 - val_loss: 0.0404\n",
      "Epoch 455/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0404\n",
      "Epoch 456/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0160 - val_loss: 0.0404\n",
      "Epoch 457/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0158 - val_loss: 0.0404\n",
      "Epoch 458/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0159 - val_loss: 0.0404\n",
      "Epoch 459/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0160 - val_loss: 0.0404\n",
      "Epoch 460/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0405\n",
      "Epoch 461/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0158 - val_loss: 0.0405\n",
      "Epoch 462/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0158 - val_loss: 0.0404\n",
      "Epoch 463/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0157 - val_loss: 0.0404\n",
      "Epoch 464/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0159 - val_loss: 0.0404\n",
      "Epoch 465/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0403\n",
      "Epoch 466/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0403\n",
      "Epoch 467/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0156 - val_loss: 0.0403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0157 - val_loss: 0.0403\n",
      "Epoch 469/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0157 - val_loss: 0.0403\n",
      "Epoch 470/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0158 - val_loss: 0.0403\n",
      "Epoch 471/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0156 - val_loss: 0.0404\n",
      "Epoch 472/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0403\n",
      "Epoch 473/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0155 - val_loss: 0.0403\n",
      "Epoch 474/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0157 - val_loss: 0.0403\n",
      "Epoch 475/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0403\n",
      "Epoch 476/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0156 - val_loss: 0.0403\n",
      "Epoch 477/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0403\n",
      "Epoch 478/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0403\n",
      "Epoch 479/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0402\n",
      "Epoch 480/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0153 - val_loss: 0.0402\n",
      "Epoch 481/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0402\n",
      "Epoch 482/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0402\n",
      "Epoch 483/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0153 - val_loss: 0.0402\n",
      "Epoch 484/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0403\n",
      "Epoch 485/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0156 - val_loss: 0.0403\n",
      "Epoch 486/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0152 - val_loss: 0.0403\n",
      "Epoch 487/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0150 - val_loss: 0.0404\n",
      "Epoch 488/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0153 - val_loss: 0.0404\n",
      "Epoch 489/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0154 - val_loss: 0.0403\n",
      "Epoch 490/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0153 - val_loss: 0.0403\n",
      "Epoch 491/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0402\n",
      "Epoch 492/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0153 - val_loss: 0.0401\n",
      "Epoch 493/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0155 - val_loss: 0.0401\n",
      "Epoch 494/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0154 - val_loss: 0.0401\n",
      "Epoch 495/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0149 - val_loss: 0.0401\n",
      "Epoch 496/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0153 - val_loss: 0.0401\n",
      "Epoch 497/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0150 - val_loss: 0.0402\n",
      "Epoch 498/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0153 - val_loss: 0.0403\n",
      "Epoch 499/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0403\n",
      "Epoch 500/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0404\n",
      "Epoch 501/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0404\n",
      "Epoch 502/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0404\n",
      "Epoch 503/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0150 - val_loss: 0.0404\n",
      "Epoch 504/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0151 - val_loss: 0.0404\n",
      "Epoch 505/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0147 - val_loss: 0.0403\n",
      "Epoch 506/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 0.0403\n",
      "Epoch 507/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0149 - val_loss: 0.0402\n",
      "Epoch 508/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 0.0402\n",
      "Epoch 509/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0402\n",
      "Epoch 510/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0402\n",
      "Epoch 511/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0150 - val_loss: 0.0402\n",
      "Epoch 512/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 0.0402\n",
      "Epoch 513/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0149 - val_loss: 0.0402\n",
      "Epoch 514/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0151 - val_loss: 0.0402\n",
      "Epoch 515/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0402\n",
      "Epoch 516/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0150 - val_loss: 0.0402\n",
      "Epoch 517/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0148 - val_loss: 0.0403\n",
      "Epoch 518/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0147 - val_loss: 0.0403\n",
      "Epoch 519/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0149 - val_loss: 0.0403\n",
      "Epoch 520/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 0.0403\n",
      "Epoch 521/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0148 - val_loss: 0.0403\n",
      "Epoch 522/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0149 - val_loss: 0.0404\n",
      "Epoch 523/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0148 - val_loss: 0.0403\n",
      "Epoch 524/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0148 - val_loss: 0.0403\n",
      "Epoch 525/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0149 - val_loss: 0.0403\n",
      "Epoch 526/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0149 - val_loss: 0.0403\n",
      "Epoch 527/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0148 - val_loss: 0.0402\n",
      "Epoch 528/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0148 - val_loss: 0.0401\n",
      "Epoch 529/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0148 - val_loss: 0.0401\n",
      "Epoch 530/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0148 - val_loss: 0.0400\n",
      "Epoch 531/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0147 - val_loss: 0.0400\n",
      "Epoch 532/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0150 - val_loss: 0.0401\n",
      "Epoch 533/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0147 - val_loss: 0.0400\n",
      "Epoch 534/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0146 - val_loss: 0.0401\n",
      "Epoch 535/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 0.0401\n",
      "Epoch 536/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0147 - val_loss: 0.0401\n",
      "Epoch 537/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0146 - val_loss: 0.0402\n",
      "Epoch 538/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0402\n",
      "Epoch 539/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0402\n",
      "Epoch 540/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0147 - val_loss: 0.0403\n",
      "Epoch 541/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0403\n",
      "Epoch 542/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0402\n",
      "Epoch 543/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 0.0402\n",
      "Epoch 544/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0401\n",
      "Epoch 545/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0400\n",
      "Epoch 547/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0400\n",
      "Epoch 548/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0147 - val_loss: 0.0400\n",
      "Epoch 549/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 0.0400\n",
      "Epoch 550/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0400\n",
      "Epoch 551/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0146 - val_loss: 0.0400\n",
      "Epoch 552/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0400\n",
      "Epoch 553/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0401\n",
      "Epoch 554/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0142 - val_loss: 0.0402\n",
      "Epoch 555/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0402\n",
      "Epoch 556/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0402\n",
      "Epoch 557/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0402\n",
      "Epoch 558/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0144 - val_loss: 0.0402\n",
      "Epoch 559/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0402\n",
      "Epoch 560/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0144 - val_loss: 0.0403\n",
      "Epoch 561/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0142 - val_loss: 0.0403\n",
      "Epoch 562/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0403\n",
      "Epoch 563/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0403\n",
      "Epoch 564/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0142 - val_loss: 0.0403\n",
      "Epoch 565/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0403\n",
      "Epoch 566/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0144 - val_loss: 0.0403\n",
      "Epoch 567/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 0.0402\n",
      "Epoch 568/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0402\n",
      "Epoch 569/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0402\n",
      "Epoch 570/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0142 - val_loss: 0.0401\n",
      "Epoch 571/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0400\n",
      "Epoch 572/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0399\n",
      "Epoch 573/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0399\n",
      "Epoch 574/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0398\n",
      "Epoch 575/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0142 - val_loss: 0.0398\n",
      "Epoch 576/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0399\n",
      "Epoch 577/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0399\n",
      "Epoch 578/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0144 - val_loss: 0.0400\n",
      "Epoch 579/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0401\n",
      "Epoch 580/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0402\n",
      "Epoch 581/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0403\n",
      "Epoch 582/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0403\n",
      "Epoch 583/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0403\n",
      "Epoch 584/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0403\n",
      "Epoch 585/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0402\n",
      "Epoch 586/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0140 - val_loss: 0.0402\n",
      "Epoch 587/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0402\n",
      "Epoch 588/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0140 - val_loss: 0.0402\n",
      "Epoch 589/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0403\n",
      "Epoch 590/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0403\n",
      "Epoch 591/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0403\n",
      "Epoch 592/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0403\n",
      "Epoch 593/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0403\n",
      "Epoch 594/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0140 - val_loss: 0.0403\n",
      "Epoch 595/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0403\n",
      "Epoch 596/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0402\n",
      "Epoch 597/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0401\n",
      "Epoch 598/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0401\n",
      "Epoch 599/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0401\n",
      "Epoch 600/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0400\n",
      "Epoch 601/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0400\n",
      "Epoch 602/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0400\n",
      "Epoch 603/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0400\n",
      "Epoch 604/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0400\n",
      "Epoch 605/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0401\n",
      "Epoch 606/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0402\n",
      "Epoch 607/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0402\n",
      "Epoch 608/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0402\n",
      "Epoch 609/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0403\n",
      "Epoch 610/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0403\n",
      "Epoch 611/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0403\n",
      "Epoch 612/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0403\n",
      "Epoch 613/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0403\n",
      "Epoch 614/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0403\n",
      "Epoch 615/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0403\n",
      "Epoch 616/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0403\n",
      "Epoch 617/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0403\n",
      "Epoch 618/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0403\n",
      "Epoch 619/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0402\n",
      "Epoch 620/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0402\n",
      "Epoch 621/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0402\n",
      "Epoch 622/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0401\n",
      "Epoch 623/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0401\n",
      "Epoch 625/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0402\n",
      "Epoch 626/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0402\n",
      "Epoch 627/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0403\n",
      "Epoch 628/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0403\n",
      "Epoch 629/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0403\n",
      "Epoch 630/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0403\n",
      "Epoch 631/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0404\n",
      "Epoch 632/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0404\n",
      "Epoch 633/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0404\n",
      "Epoch 634/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0405\n",
      "Epoch 635/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0404\n",
      "Epoch 636/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0404\n",
      "Epoch 637/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0404\n",
      "Epoch 638/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0404\n",
      "Epoch 639/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0403\n",
      "Epoch 640/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0403\n",
      "Epoch 641/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0403\n",
      "Epoch 642/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0402\n",
      "Epoch 643/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0402\n",
      "Epoch 644/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0402\n",
      "Epoch 645/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0402\n",
      "Epoch 646/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0402\n",
      "Epoch 647/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0402\n",
      "Epoch 648/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0402\n",
      "Epoch 649/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0401\n",
      "Epoch 650/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0401\n",
      "Epoch 651/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0401\n",
      "Epoch 652/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0401\n",
      "Epoch 653/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0401\n",
      "Epoch 654/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0401\n",
      "Epoch 655/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0402\n",
      "Epoch 656/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0402\n",
      "Epoch 657/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0402\n",
      "Epoch 658/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0403\n",
      "Epoch 659/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0403\n",
      "Epoch 660/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0403\n",
      "Epoch 661/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0403\n",
      "Epoch 662/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0403\n",
      "Epoch 663/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0403\n",
      "Epoch 664/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0403\n",
      "Epoch 665/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0402\n",
      "Epoch 666/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0402\n",
      "Epoch 667/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0402\n",
      "Epoch 668/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0402\n",
      "Epoch 669/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0403\n",
      "Epoch 670/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0403\n",
      "Epoch 671/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0403\n",
      "Epoch 672/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0403\n",
      "Epoch 673/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0403\n",
      "Epoch 674/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0403\n",
      "Epoch 675/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0403\n",
      "Epoch 676/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0403\n",
      "Epoch 677/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0403\n",
      "Epoch 678/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0403\n",
      "Epoch 679/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0403\n",
      "Epoch 680/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0403\n",
      "Epoch 681/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0403\n",
      "Epoch 682/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0403\n",
      "Epoch 683/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0403\n",
      "Epoch 684/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0403\n",
      "Epoch 685/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0403\n",
      "Epoch 686/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0403\n",
      "Epoch 687/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0403\n",
      "Epoch 688/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0404\n",
      "Epoch 689/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0127 - val_loss: 0.0404\n",
      "Epoch 690/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0404\n",
      "Epoch 691/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0405\n",
      "Epoch 692/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0405\n",
      "Epoch 693/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0405\n",
      "Epoch 694/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0128 - val_loss: 0.0405\n",
      "Epoch 695/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0405\n",
      "Epoch 696/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0404\n",
      "Epoch 697/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0403\n",
      "Epoch 698/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0402\n",
      "Epoch 699/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0402\n",
      "Epoch 700/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0402\n",
      "Epoch 701/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 0.0402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 702/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0128 - val_loss: 0.0402\n",
      "Epoch 703/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0403\n",
      "Epoch 704/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0403\n",
      "Epoch 705/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0404\n",
      "Epoch 706/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0404\n",
      "Epoch 707/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0404\n",
      "Epoch 708/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0404\n",
      "Epoch 709/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0127 - val_loss: 0.0404\n",
      "Epoch 710/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0128 - val_loss: 0.0403\n",
      "Epoch 711/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0403\n",
      "Epoch 712/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0403\n",
      "Epoch 713/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0402\n",
      "Epoch 714/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0402\n",
      "Epoch 715/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0401\n",
      "Epoch 716/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0401\n",
      "Epoch 717/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0401\n",
      "Epoch 718/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0402\n",
      "Epoch 719/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0127 - val_loss: 0.0402\n",
      "Epoch 720/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0403\n",
      "Epoch 721/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0403\n",
      "Epoch 722/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0404\n",
      "Epoch 723/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0404\n",
      "Epoch 724/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0404\n",
      "Epoch 725/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0404\n",
      "Epoch 726/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0404\n",
      "Epoch 727/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0403\n",
      "Epoch 728/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0403\n",
      "Epoch 729/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0403\n",
      "Epoch 730/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0403\n",
      "Epoch 731/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0127 - val_loss: 0.0403\n",
      "Epoch 732/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0402\n",
      "Epoch 733/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0402\n",
      "Epoch 734/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0403\n",
      "Epoch 735/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0402\n",
      "Epoch 736/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0402\n",
      "Epoch 737/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0402\n",
      "Epoch 738/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0402\n",
      "Epoch 739/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0128 - val_loss: 0.0402\n",
      "Epoch 740/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 0.0403\n",
      "Epoch 741/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0403\n",
      "Epoch 742/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0403\n",
      "Epoch 743/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0404\n",
      "Epoch 744/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0405\n",
      "Epoch 745/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0127 - val_loss: 0.0405\n",
      "Epoch 746/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0405\n",
      "Epoch 747/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0405\n",
      "Epoch 748/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0405\n",
      "Epoch 749/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0404\n",
      "Epoch 750/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0403\n",
      "Epoch 751/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0403\n",
      "Epoch 752/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0403\n",
      "Epoch 753/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0402\n",
      "Epoch 754/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0402\n",
      "Epoch 755/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0402\n",
      "Epoch 756/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0402\n",
      "Epoch 757/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0402\n",
      "Epoch 758/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0402\n",
      "Epoch 759/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 0.0403\n",
      "Epoch 760/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0404\n",
      "Epoch 761/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0404\n",
      "Epoch 762/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0405\n",
      "Epoch 763/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0406\n",
      "Epoch 764/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0407\n",
      "Epoch 765/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0408\n",
      "Epoch 766/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0408\n",
      "Epoch 767/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0407\n",
      "Epoch 768/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0407\n",
      "Epoch 769/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0406\n",
      "Epoch 770/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0405\n",
      "Epoch 771/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0404\n",
      "Epoch 772/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0403\n",
      "Epoch 773/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0403\n",
      "Epoch 774/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0403\n",
      "Epoch 775/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0403\n",
      "Epoch 776/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0403\n",
      "Epoch 777/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0403\n",
      "Epoch 778/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0404\n",
      "Epoch 779/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 0.0405\n",
      "Epoch 781/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0405\n",
      "Epoch 782/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0405\n",
      "Epoch 783/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0405\n",
      "Epoch 784/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0404\n",
      "Epoch 785/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0404\n",
      "Epoch 786/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0403\n",
      "Epoch 787/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0403\n",
      "Epoch 788/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0403\n",
      "Epoch 789/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0403\n",
      "Epoch 790/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0404\n",
      "Epoch 791/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0404\n",
      "Epoch 792/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0405\n",
      "Epoch 793/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0405\n",
      "Epoch 794/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0406\n",
      "Epoch 795/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0406\n",
      "Epoch 796/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0407\n",
      "Epoch 797/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0407\n",
      "Epoch 798/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0407\n",
      "Epoch 799/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0406\n",
      "Epoch 800/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0406\n",
      "Epoch 801/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0405\n",
      "Epoch 802/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0405\n",
      "Epoch 803/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0405\n",
      "Epoch 804/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0117 - val_loss: 0.0405\n",
      "Epoch 805/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0405\n",
      "Epoch 806/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0405\n",
      "Epoch 807/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0405\n",
      "Epoch 808/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0404\n",
      "Epoch 809/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0404\n",
      "Epoch 810/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0403\n",
      "Epoch 811/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0403\n",
      "Epoch 812/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0403\n",
      "Epoch 813/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0403\n",
      "Epoch 814/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0118 - val_loss: 0.0403\n",
      "Epoch 815/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0118 - val_loss: 0.0404\n",
      "Epoch 816/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0404\n",
      "Epoch 817/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0118 - val_loss: 0.0405\n",
      "Epoch 818/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0405\n",
      "Epoch 819/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0406\n",
      "Epoch 820/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0118 - val_loss: 0.0406\n",
      "Epoch 821/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0406\n",
      "Epoch 822/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0406\n",
      "Epoch 823/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0406\n",
      "Epoch 824/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0406\n",
      "Epoch 825/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0406\n",
      "Epoch 826/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0406\n",
      "Epoch 827/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0407\n",
      "Epoch 828/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0118 - val_loss: 0.0407\n",
      "Epoch 829/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0407\n",
      "Epoch 830/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0407\n",
      "Epoch 831/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0407\n",
      "Epoch 832/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0407\n",
      "Epoch 833/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0118 - val_loss: 0.0406\n",
      "Epoch 834/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0117 - val_loss: 0.0405\n",
      "Epoch 835/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0405\n",
      "Epoch 836/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0117 - val_loss: 0.0405\n",
      "Epoch 837/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0405\n",
      "Epoch 838/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0117 - val_loss: 0.0405\n",
      "Epoch 839/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0405\n",
      "Epoch 840/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0406\n",
      "Epoch 841/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0407\n",
      "Epoch 842/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0117 - val_loss: 0.0407\n",
      "Epoch 843/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0407\n",
      "Epoch 844/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0406\n",
      "Epoch 845/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0406\n",
      "Epoch 846/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0406\n",
      "Epoch 847/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0405\n",
      "Epoch 848/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0406\n",
      "Epoch 849/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0406\n",
      "Epoch 850/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0406\n",
      "Epoch 851/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0406\n",
      "Epoch 852/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0406\n",
      "Epoch 853/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0117 - val_loss: 0.0406\n",
      "Epoch 854/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0406\n",
      "Epoch 855/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0405\n",
      "Epoch 856/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0405\n",
      "Epoch 857/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 858/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0405\n",
      "Epoch 859/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0406\n",
      "Epoch 860/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0406\n",
      "Epoch 861/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0407\n",
      "Epoch 862/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0117 - val_loss: 0.0407\n",
      "Epoch 863/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0407\n",
      "Epoch 864/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0407\n",
      "Epoch 865/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0406\n",
      "Epoch 866/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0406\n",
      "Epoch 867/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0115 - val_loss: 0.0405\n",
      "Epoch 868/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0405\n",
      "Epoch 869/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0405\n",
      "Epoch 870/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0405\n",
      "Epoch 871/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0405\n",
      "Epoch 872/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0113 - val_loss: 0.0405\n",
      "Epoch 873/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0405\n",
      "Epoch 874/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0405\n",
      "Epoch 875/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0405\n",
      "Epoch 876/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0405\n",
      "Epoch 877/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0406\n",
      "Epoch 878/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0115 - val_loss: 0.0405\n",
      "Epoch 879/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0405\n",
      "Epoch 880/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0405\n",
      "Epoch 881/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0404\n",
      "Epoch 882/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0404\n",
      "Epoch 883/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0405\n",
      "Epoch 884/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0405\n",
      "Epoch 885/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0406\n",
      "Epoch 886/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0113 - val_loss: 0.0407\n",
      "Epoch 887/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0407\n",
      "Epoch 888/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0408\n",
      "Epoch 889/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0408\n",
      "Epoch 890/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0407\n",
      "Epoch 891/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0408\n",
      "Epoch 892/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0407\n",
      "Epoch 893/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0407\n",
      "Epoch 894/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0113 - val_loss: 0.0407\n",
      "Epoch 895/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0113 - val_loss: 0.0406\n",
      "Epoch 896/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0406\n",
      "Epoch 897/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0405\n",
      "Epoch 898/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0405\n",
      "Epoch 899/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0405\n",
      "Epoch 900/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0405\n",
      "Epoch 901/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0405\n",
      "Epoch 902/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0405\n",
      "Epoch 903/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0406\n",
      "Epoch 904/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0406\n",
      "Epoch 905/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0406\n",
      "Epoch 906/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0407\n",
      "Epoch 907/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0407\n",
      "Epoch 908/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0111 - val_loss: 0.0407\n",
      "Epoch 909/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0407\n",
      "Epoch 910/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0406\n",
      "Epoch 911/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0406\n",
      "Epoch 912/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0406\n",
      "Epoch 913/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0406\n",
      "Epoch 914/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0111 - val_loss: 0.0406\n",
      "Epoch 915/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0406\n",
      "Epoch 916/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0113 - val_loss: 0.0406\n",
      "Epoch 917/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0405\n",
      "Epoch 918/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0405\n",
      "Epoch 919/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0405\n",
      "Epoch 920/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0111 - val_loss: 0.0405\n",
      "Epoch 921/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0405\n",
      "Epoch 922/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0405\n",
      "Epoch 923/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0406\n",
      "Epoch 924/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0406\n",
      "Epoch 925/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0406\n",
      "Epoch 926/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0406\n",
      "Epoch 927/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0406\n",
      "Epoch 928/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0407\n",
      "Epoch 929/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0407\n",
      "Epoch 930/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 0.0407\n",
      "Epoch 931/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0407\n",
      "Epoch 932/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0407\n",
      "Epoch 933/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0407\n",
      "Epoch 934/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0111 - val_loss: 0.0408\n",
      "Epoch 935/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0407\n",
      "Epoch 937/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0111 - val_loss: 0.0407\n",
      "Epoch 938/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0407\n",
      "Epoch 939/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0406\n",
      "Epoch 940/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 0.0406\n",
      "Epoch 941/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0406\n",
      "Epoch 942/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0406\n",
      "Epoch 943/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0406\n",
      "Epoch 944/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0406\n",
      "Epoch 945/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0407\n",
      "Epoch 946/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0407\n",
      "Epoch 947/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0407\n",
      "Epoch 948/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0407\n",
      "Epoch 949/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 0.0407\n",
      "Epoch 950/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0109 - val_loss: 0.0407\n",
      "Epoch 951/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0406\n",
      "Epoch 952/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 0.0405\n",
      "Epoch 953/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0405\n",
      "Epoch 954/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0405\n",
      "Epoch 955/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0405\n",
      "Epoch 956/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0405\n",
      "Epoch 957/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0405\n",
      "Epoch 958/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0109 - val_loss: 0.0406\n",
      "Epoch 959/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0406\n",
      "Epoch 960/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0406\n",
      "Epoch 961/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0109 - val_loss: 0.0407\n",
      "Epoch 962/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0407\n",
      "Epoch 963/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0407\n",
      "Epoch 964/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0107 - val_loss: 0.0408\n",
      "Epoch 965/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0111 - val_loss: 0.0408\n",
      "Epoch 966/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0111 - val_loss: 0.0408\n",
      "Epoch 967/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0408\n",
      "Epoch 968/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0408\n",
      "Epoch 969/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0407\n",
      "Epoch 970/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0407\n",
      "Epoch 971/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0109 - val_loss: 0.0406\n",
      "Epoch 972/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 0.0405\n",
      "Epoch 973/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0405\n",
      "Epoch 974/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0404\n",
      "Epoch 975/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0404\n",
      "Epoch 976/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0109 - val_loss: 0.0405\n",
      "Epoch 977/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0405\n",
      "Epoch 978/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0405\n",
      "Epoch 979/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0406\n",
      "Epoch 980/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0109 - val_loss: 0.0406\n",
      "Epoch 981/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0406\n",
      "Epoch 982/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0406\n",
      "Epoch 983/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0406\n",
      "Epoch 984/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0406\n",
      "Epoch 985/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0406\n",
      "Epoch 986/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0109 - val_loss: 0.0406\n",
      "Epoch 987/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0405\n",
      "Epoch 988/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0405\n",
      "Epoch 989/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0405\n",
      "Epoch 990/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0405\n",
      "Epoch 991/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0405\n",
      "Epoch 992/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0406\n",
      "Epoch 993/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0106 - val_loss: 0.0407\n",
      "Epoch 994/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0407\n",
      "Epoch 995/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0408\n",
      "Epoch 996/1000\n",
      "8996/8996 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0408\n",
      "Epoch 997/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0409\n",
      "Epoch 998/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0408\n",
      "Epoch 999/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0408\n",
      "Epoch 1000/1000\n",
      "8996/8996 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0407\n",
      "Durchlauf:  1\n",
      "positions calculated\n",
      "tcp calculated\n",
      "duplicates erased\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "9000/9000 [==============================] - 0s 10us/step - loss: 0.2565 - val_loss: 0.2880\n",
      "Epoch 2/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.2221 - val_loss: 0.1956\n",
      "Epoch 3/1000\n",
      "9000/9000 [==============================] - 0s 10us/step - loss: 0.1768 - val_loss: 0.1386\n",
      "Epoch 4/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.1415 - val_loss: 0.1161\n",
      "Epoch 5/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.1176 - val_loss: 0.1104\n",
      "Epoch 6/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.1042 - val_loss: 0.1108\n",
      "Epoch 7/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0972 - val_loss: 0.1134\n",
      "Epoch 8/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0944 - val_loss: 0.1164\n",
      "Epoch 9/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0949 - val_loss: 0.1177\n",
      "Epoch 10/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0965 - val_loss: 0.1171\n",
      "Epoch 11/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0967 - val_loss: 0.1156\n",
      "Epoch 12/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0956 - val_loss: 0.1141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0940 - val_loss: 0.1126\n",
      "Epoch 14/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0924 - val_loss: 0.1108\n",
      "Epoch 15/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0894 - val_loss: 0.1092\n",
      "Epoch 16/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0862 - val_loss: 0.1081\n",
      "Epoch 17/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0837 - val_loss: 0.1072\n",
      "Epoch 18/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0791 - val_loss: 0.1053\n",
      "Epoch 19/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0754 - val_loss: 0.1015\n",
      "Epoch 20/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0716 - val_loss: 0.0969\n",
      "Epoch 21/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0678 - val_loss: 0.0931\n",
      "Epoch 22/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0643 - val_loss: 0.0906\n",
      "Epoch 23/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0628 - val_loss: 0.0887\n",
      "Epoch 24/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0607 - val_loss: 0.0867\n",
      "Epoch 25/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0582 - val_loss: 0.0843\n",
      "Epoch 26/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0560 - val_loss: 0.0821\n",
      "Epoch 27/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0535 - val_loss: 0.0804\n",
      "Epoch 28/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0504 - val_loss: 0.0793\n",
      "Epoch 29/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0474 - val_loss: 0.0790\n",
      "Epoch 30/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0452 - val_loss: 0.0795\n",
      "Epoch 31/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0440 - val_loss: 0.0801\n",
      "Epoch 32/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0428 - val_loss: 0.0799\n",
      "Epoch 33/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0422 - val_loss: 0.0784\n",
      "Epoch 34/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0413 - val_loss: 0.0753\n",
      "Epoch 35/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0402 - val_loss: 0.0714\n",
      "Epoch 36/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0392 - val_loss: 0.0673\n",
      "Epoch 37/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0381 - val_loss: 0.0637\n",
      "Epoch 38/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0376 - val_loss: 0.0606\n",
      "Epoch 39/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0372 - val_loss: 0.0582\n",
      "Epoch 40/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0368 - val_loss: 0.0565\n",
      "Epoch 41/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0360 - val_loss: 0.0555\n",
      "Epoch 42/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0355 - val_loss: 0.0552\n",
      "Epoch 43/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0345 - val_loss: 0.0557\n",
      "Epoch 44/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0338 - val_loss: 0.0566\n",
      "Epoch 45/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0332 - val_loss: 0.0577\n",
      "Epoch 46/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0325 - val_loss: 0.0587\n",
      "Epoch 47/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0326 - val_loss: 0.0595\n",
      "Epoch 48/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0319 - val_loss: 0.0601\n",
      "Epoch 49/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0319 - val_loss: 0.0607\n",
      "Epoch 50/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0307 - val_loss: 0.0612\n",
      "Epoch 51/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0305 - val_loss: 0.0620\n",
      "Epoch 52/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0299 - val_loss: 0.0628\n",
      "Epoch 53/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0297 - val_loss: 0.0637\n",
      "Epoch 54/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0294 - val_loss: 0.0645\n",
      "Epoch 55/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0293 - val_loss: 0.0649\n",
      "Epoch 56/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0288 - val_loss: 0.0650\n",
      "Epoch 57/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0286 - val_loss: 0.0649\n",
      "Epoch 58/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0284 - val_loss: 0.0643\n",
      "Epoch 59/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0277 - val_loss: 0.0637\n",
      "Epoch 60/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0276 - val_loss: 0.0628\n",
      "Epoch 61/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0274 - val_loss: 0.0618\n",
      "Epoch 62/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0269 - val_loss: 0.0608\n",
      "Epoch 63/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0269 - val_loss: 0.0599\n",
      "Epoch 64/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0266 - val_loss: 0.0589\n",
      "Epoch 65/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0262 - val_loss: 0.0581\n",
      "Epoch 66/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0261 - val_loss: 0.0576\n",
      "Epoch 67/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0256 - val_loss: 0.0572\n",
      "Epoch 68/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0256 - val_loss: 0.0570\n",
      "Epoch 69/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0256 - val_loss: 0.0570\n",
      "Epoch 70/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0256 - val_loss: 0.0572\n",
      "Epoch 71/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0250 - val_loss: 0.0577\n",
      "Epoch 72/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0251 - val_loss: 0.0582\n",
      "Epoch 73/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0252 - val_loss: 0.0588\n",
      "Epoch 74/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0243 - val_loss: 0.0592\n",
      "Epoch 75/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0244 - val_loss: 0.0595\n",
      "Epoch 76/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0244 - val_loss: 0.0595\n",
      "Epoch 77/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0243 - val_loss: 0.0594\n",
      "Epoch 78/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0240 - val_loss: 0.0591\n",
      "Epoch 79/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0239 - val_loss: 0.0588\n",
      "Epoch 80/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0237 - val_loss: 0.0585\n",
      "Epoch 81/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0235 - val_loss: 0.0582\n",
      "Epoch 82/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0234 - val_loss: 0.0580\n",
      "Epoch 83/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0234 - val_loss: 0.0578\n",
      "Epoch 84/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0232 - val_loss: 0.0577\n",
      "Epoch 85/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0231 - val_loss: 0.0576\n",
      "Epoch 86/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0228 - val_loss: 0.0574\n",
      "Epoch 87/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0228 - val_loss: 0.0572\n",
      "Epoch 88/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0229 - val_loss: 0.0569\n",
      "Epoch 89/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0224 - val_loss: 0.0566\n",
      "Epoch 90/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0223 - val_loss: 0.0563\n",
      "Epoch 91/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0222 - val_loss: 0.0560\n",
      "Epoch 92/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0222 - val_loss: 0.0558\n",
      "Epoch 93/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0221 - val_loss: 0.0557\n",
      "Epoch 94/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0217 - val_loss: 0.0557\n",
      "Epoch 95/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0215 - val_loss: 0.0557\n",
      "Epoch 96/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0216 - val_loss: 0.0558\n",
      "Epoch 97/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0217 - val_loss: 0.0559\n",
      "Epoch 98/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0214 - val_loss: 0.0560\n",
      "Epoch 99/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0215 - val_loss: 0.0561\n",
      "Epoch 100/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0212 - val_loss: 0.0561\n",
      "Epoch 101/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0212 - val_loss: 0.0561\n",
      "Epoch 102/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0211 - val_loss: 0.0560\n",
      "Epoch 103/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0210 - val_loss: 0.0559\n",
      "Epoch 104/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0210 - val_loss: 0.0558\n",
      "Epoch 105/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0208 - val_loss: 0.0557\n",
      "Epoch 106/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0206 - val_loss: 0.0555\n",
      "Epoch 107/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0203 - val_loss: 0.0554\n",
      "Epoch 108/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0202 - val_loss: 0.0553\n",
      "Epoch 109/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0203 - val_loss: 0.0551\n",
      "Epoch 110/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0199 - val_loss: 0.0551\n",
      "Epoch 111/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0203 - val_loss: 0.0550\n",
      "Epoch 112/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0199 - val_loss: 0.0549\n",
      "Epoch 113/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0202 - val_loss: 0.0549\n",
      "Epoch 114/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0200 - val_loss: 0.0548\n",
      "Epoch 115/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0201 - val_loss: 0.0548\n",
      "Epoch 116/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0198 - val_loss: 0.0547\n",
      "Epoch 117/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0198 - val_loss: 0.0546\n",
      "Epoch 118/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0197 - val_loss: 0.0545\n",
      "Epoch 119/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0195 - val_loss: 0.0544\n",
      "Epoch 120/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0193 - val_loss: 0.0543\n",
      "Epoch 121/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0196 - val_loss: 0.0542\n",
      "Epoch 122/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0193 - val_loss: 0.0542\n",
      "Epoch 123/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0193 - val_loss: 0.0542\n",
      "Epoch 124/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0192 - val_loss: 0.0541\n",
      "Epoch 125/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0189 - val_loss: 0.0540\n",
      "Epoch 126/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0190 - val_loss: 0.0539\n",
      "Epoch 127/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0190 - val_loss: 0.0537\n",
      "Epoch 128/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0189 - val_loss: 0.0536\n",
      "Epoch 129/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0190 - val_loss: 0.0535\n",
      "Epoch 130/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0188 - val_loss: 0.0534\n",
      "Epoch 131/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0188 - val_loss: 0.0534\n",
      "Epoch 132/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0186 - val_loss: 0.0533\n",
      "Epoch 133/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0184 - val_loss: 0.0533\n",
      "Epoch 134/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0184 - val_loss: 0.0533\n",
      "Epoch 135/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0182 - val_loss: 0.0531\n",
      "Epoch 136/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0185 - val_loss: 0.0530\n",
      "Epoch 137/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0182 - val_loss: 0.0529\n",
      "Epoch 138/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0183 - val_loss: 0.0528\n",
      "Epoch 139/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0181 - val_loss: 0.0526\n",
      "Epoch 140/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0181 - val_loss: 0.0524\n",
      "Epoch 141/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0182 - val_loss: 0.0522\n",
      "Epoch 142/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0180 - val_loss: 0.0521\n",
      "Epoch 143/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0180 - val_loss: 0.0521\n",
      "Epoch 144/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0179 - val_loss: 0.0520\n",
      "Epoch 145/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0181 - val_loss: 0.0520\n",
      "Epoch 146/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0178 - val_loss: 0.0520\n",
      "Epoch 147/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0176 - val_loss: 0.0520\n",
      "Epoch 148/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0174 - val_loss: 0.0521\n",
      "Epoch 149/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0177 - val_loss: 0.0522\n",
      "Epoch 150/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0176 - val_loss: 0.0523\n",
      "Epoch 151/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0174 - val_loss: 0.0522\n",
      "Epoch 152/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0175 - val_loss: 0.0521\n",
      "Epoch 153/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0174 - val_loss: 0.0520\n",
      "Epoch 154/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0172 - val_loss: 0.0518\n",
      "Epoch 155/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0174 - val_loss: 0.0517\n",
      "Epoch 156/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0174 - val_loss: 0.0517\n",
      "Epoch 157/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0171 - val_loss: 0.0517\n",
      "Epoch 158/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0171 - val_loss: 0.0517\n",
      "Epoch 159/1000\n",
      "9000/9000 [==============================] - 0s 6us/step - loss: 0.0171 - val_loss: 0.0517\n",
      "Epoch 160/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0170 - val_loss: 0.0516\n",
      "Epoch 161/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0170 - val_loss: 0.0515\n",
      "Epoch 162/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0169 - val_loss: 0.0515\n",
      "Epoch 163/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0171 - val_loss: 0.0514\n",
      "Epoch 164/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0169 - val_loss: 0.0513\n",
      "Epoch 165/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0170 - val_loss: 0.0512\n",
      "Epoch 166/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0170 - val_loss: 0.0509\n",
      "Epoch 167/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0167 - val_loss: 0.0508\n",
      "Epoch 168/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0169 - val_loss: 0.0508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0167 - val_loss: 0.0507\n",
      "Epoch 170/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0165 - val_loss: 0.0507\n",
      "Epoch 171/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0169 - val_loss: 0.0506\n",
      "Epoch 172/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0167 - val_loss: 0.0505\n",
      "Epoch 173/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0166 - val_loss: 0.0503\n",
      "Epoch 174/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0166 - val_loss: 0.0503\n",
      "Epoch 175/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0163 - val_loss: 0.0503\n",
      "Epoch 176/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0164 - val_loss: 0.0503\n",
      "Epoch 177/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0162 - val_loss: 0.0503\n",
      "Epoch 178/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0164 - val_loss: 0.0503\n",
      "Epoch 179/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0163 - val_loss: 0.0502\n",
      "Epoch 180/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0161 - val_loss: 0.0501\n",
      "Epoch 181/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0163 - val_loss: 0.0500\n",
      "Epoch 182/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0163 - val_loss: 0.0499\n",
      "Epoch 183/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0159 - val_loss: 0.0499\n",
      "Epoch 184/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0160 - val_loss: 0.0498\n",
      "Epoch 185/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0160 - val_loss: 0.0497\n",
      "Epoch 186/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0160 - val_loss: 0.0496\n",
      "Epoch 187/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0158 - val_loss: 0.0495\n",
      "Epoch 188/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0159 - val_loss: 0.0494\n",
      "Epoch 189/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0160 - val_loss: 0.0494\n",
      "Epoch 190/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0158 - val_loss: 0.0493\n",
      "Epoch 191/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0158 - val_loss: 0.0492\n",
      "Epoch 192/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0157 - val_loss: 0.0492\n",
      "Epoch 193/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0159 - val_loss: 0.0492\n",
      "Epoch 194/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0158 - val_loss: 0.0492\n",
      "Epoch 195/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0155 - val_loss: 0.0492\n",
      "Epoch 196/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0156 - val_loss: 0.0493\n",
      "Epoch 197/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0156 - val_loss: 0.0492\n",
      "Epoch 198/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0155 - val_loss: 0.0492\n",
      "Epoch 199/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0155 - val_loss: 0.0491\n",
      "Epoch 200/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0154 - val_loss: 0.0490\n",
      "Epoch 201/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0155 - val_loss: 0.0489\n",
      "Epoch 202/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0156 - val_loss: 0.0488\n",
      "Epoch 203/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0488\n",
      "Epoch 204/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0153 - val_loss: 0.0487\n",
      "Epoch 205/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0486\n",
      "Epoch 206/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0486\n",
      "Epoch 207/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0152 - val_loss: 0.0485\n",
      "Epoch 208/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0153 - val_loss: 0.0484\n",
      "Epoch 209/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0483\n",
      "Epoch 210/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0483\n",
      "Epoch 211/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0151 - val_loss: 0.0483\n",
      "Epoch 212/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0153 - val_loss: 0.0483\n",
      "Epoch 213/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0483\n",
      "Epoch 214/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 0.0484\n",
      "Epoch 215/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0151 - val_loss: 0.0484\n",
      "Epoch 216/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0151 - val_loss: 0.0484\n",
      "Epoch 217/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0149 - val_loss: 0.0484\n",
      "Epoch 218/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0150 - val_loss: 0.0482\n",
      "Epoch 219/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0150 - val_loss: 0.0480\n",
      "Epoch 220/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0148 - val_loss: 0.0478\n",
      "Epoch 221/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0149 - val_loss: 0.0477\n",
      "Epoch 222/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0148 - val_loss: 0.0477\n",
      "Epoch 223/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0148 - val_loss: 0.0478\n",
      "Epoch 224/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0147 - val_loss: 0.0478\n",
      "Epoch 225/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0146 - val_loss: 0.0477\n",
      "Epoch 226/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0147 - val_loss: 0.0477\n",
      "Epoch 227/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0147 - val_loss: 0.0475\n",
      "Epoch 228/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 0.0473\n",
      "Epoch 229/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0148 - val_loss: 0.0471\n",
      "Epoch 230/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0146 - val_loss: 0.0470\n",
      "Epoch 231/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 0.0469\n",
      "Epoch 232/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0145 - val_loss: 0.0468\n",
      "Epoch 233/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 0.0468\n",
      "Epoch 234/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0467\n",
      "Epoch 235/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0145 - val_loss: 0.0467\n",
      "Epoch 236/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 0.0467\n",
      "Epoch 237/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0144 - val_loss: 0.0467\n",
      "Epoch 238/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0144 - val_loss: 0.0467\n",
      "Epoch 239/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0145 - val_loss: 0.0467\n",
      "Epoch 240/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0147 - val_loss: 0.0466\n",
      "Epoch 241/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0142 - val_loss: 0.0465\n",
      "Epoch 242/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0144 - val_loss: 0.0466\n",
      "Epoch 243/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0466\n",
      "Epoch 244/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0144 - val_loss: 0.0465\n",
      "Epoch 245/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0465\n",
      "Epoch 246/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0142 - val_loss: 0.0464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0463\n",
      "Epoch 248/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0463\n",
      "Epoch 249/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0463\n",
      "Epoch 250/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0462\n",
      "Epoch 251/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0141 - val_loss: 0.0462\n",
      "Epoch 252/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0140 - val_loss: 0.0462\n",
      "Epoch 253/1000\n",
      "9000/9000 [==============================] - 0s 6us/step - loss: 0.0139 - val_loss: 0.0461\n",
      "Epoch 254/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0139 - val_loss: 0.0461\n",
      "Epoch 255/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0460\n",
      "Epoch 256/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0141 - val_loss: 0.0461\n",
      "Epoch 257/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0139 - val_loss: 0.0461\n",
      "Epoch 258/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0139 - val_loss: 0.0460\n",
      "Epoch 259/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0139 - val_loss: 0.0460\n",
      "Epoch 260/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0136 - val_loss: 0.0459\n",
      "Epoch 261/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0457\n",
      "Epoch 262/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0456\n",
      "Epoch 263/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0138 - val_loss: 0.0455\n",
      "Epoch 264/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0137 - val_loss: 0.0454\n",
      "Epoch 265/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0137 - val_loss: 0.0453\n",
      "Epoch 266/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0137 - val_loss: 0.0453\n",
      "Epoch 267/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0138 - val_loss: 0.0453\n",
      "Epoch 268/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0453\n",
      "Epoch 269/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0136 - val_loss: 0.0453\n",
      "Epoch 270/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0452\n",
      "Epoch 271/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0136 - val_loss: 0.0452\n",
      "Epoch 272/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0136 - val_loss: 0.0452\n",
      "Epoch 273/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0136 - val_loss: 0.0452\n",
      "Epoch 274/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0136 - val_loss: 0.0452\n",
      "Epoch 275/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0453\n",
      "Epoch 276/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0134 - val_loss: 0.0454\n",
      "Epoch 277/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0137 - val_loss: 0.0455\n",
      "Epoch 278/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0455\n",
      "Epoch 279/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0454\n",
      "Epoch 280/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0133 - val_loss: 0.0453\n",
      "Epoch 281/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0135 - val_loss: 0.0452\n",
      "Epoch 282/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0135 - val_loss: 0.0451\n",
      "Epoch 283/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0133 - val_loss: 0.0451\n",
      "Epoch 284/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0134 - val_loss: 0.0451\n",
      "Epoch 285/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0134 - val_loss: 0.0450\n",
      "Epoch 286/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0133 - val_loss: 0.0450\n",
      "Epoch 287/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0449\n",
      "Epoch 288/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0132 - val_loss: 0.0448\n",
      "Epoch 289/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0134 - val_loss: 0.0447\n",
      "Epoch 290/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0132 - val_loss: 0.0446\n",
      "Epoch 291/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0131 - val_loss: 0.0445\n",
      "Epoch 292/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0132 - val_loss: 0.0446\n",
      "Epoch 293/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0446\n",
      "Epoch 294/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0131 - val_loss: 0.0446\n",
      "Epoch 295/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0446\n",
      "Epoch 296/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0131 - val_loss: 0.0447\n",
      "Epoch 297/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0130 - val_loss: 0.0447\n",
      "Epoch 298/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0132 - val_loss: 0.0447\n",
      "Epoch 299/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0446\n",
      "Epoch 300/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0131 - val_loss: 0.0446\n",
      "Epoch 301/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0131 - val_loss: 0.0446\n",
      "Epoch 302/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0128 - val_loss: 0.0447\n",
      "Epoch 303/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0128 - val_loss: 0.0447\n",
      "Epoch 304/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0448\n",
      "Epoch 305/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0128 - val_loss: 0.0449\n",
      "Epoch 306/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0128 - val_loss: 0.0450\n",
      "Epoch 307/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0130 - val_loss: 0.0450\n",
      "Epoch 308/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0131 - val_loss: 0.0449\n",
      "Epoch 309/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0448\n",
      "Epoch 310/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0130 - val_loss: 0.0446\n",
      "Epoch 311/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0129 - val_loss: 0.0445\n",
      "Epoch 312/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0129 - val_loss: 0.0443\n",
      "Epoch 313/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0127 - val_loss: 0.0443\n",
      "Epoch 314/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0125 - val_loss: 0.0441\n",
      "Epoch 315/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0126 - val_loss: 0.0441\n",
      "Epoch 316/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0127 - val_loss: 0.0442\n",
      "Epoch 317/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0127 - val_loss: 0.0442\n",
      "Epoch 318/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0127 - val_loss: 0.0443\n",
      "Epoch 319/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0127 - val_loss: 0.0443\n",
      "Epoch 320/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0127 - val_loss: 0.0443\n",
      "Epoch 321/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0125 - val_loss: 0.0443\n",
      "Epoch 322/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 0.0442\n",
      "Epoch 323/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0128 - val_loss: 0.0441\n",
      "Epoch 324/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0124 - val_loss: 0.0440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0126 - val_loss: 0.0439\n",
      "Epoch 326/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0127 - val_loss: 0.0438\n",
      "Epoch 327/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0438\n",
      "Epoch 328/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0127 - val_loss: 0.0438\n",
      "Epoch 329/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 0.0438\n",
      "Epoch 330/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0437\n",
      "Epoch 331/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0125 - val_loss: 0.0437\n",
      "Epoch 332/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0435\n",
      "Epoch 333/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0126 - val_loss: 0.0434\n",
      "Epoch 334/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0124 - val_loss: 0.0432\n",
      "Epoch 335/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0124 - val_loss: 0.0432\n",
      "Epoch 336/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 0.0433\n",
      "Epoch 337/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 0.0434\n",
      "Epoch 338/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0124 - val_loss: 0.0436\n",
      "Epoch 339/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0123 - val_loss: 0.0437\n",
      "Epoch 340/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0437\n",
      "Epoch 341/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0436\n",
      "Epoch 342/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0123 - val_loss: 0.0436\n",
      "Epoch 343/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0435\n",
      "Epoch 344/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0124 - val_loss: 0.0435\n",
      "Epoch 345/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0120 - val_loss: 0.0435\n",
      "Epoch 346/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0435\n",
      "Epoch 347/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0434\n",
      "Epoch 348/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0121 - val_loss: 0.0434\n",
      "Epoch 349/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0123 - val_loss: 0.0433\n",
      "Epoch 350/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0123 - val_loss: 0.0432\n",
      "Epoch 351/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 0.0431\n",
      "Epoch 352/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0122 - val_loss: 0.0431\n",
      "Epoch 353/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0431\n",
      "Epoch 354/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0431\n",
      "Epoch 355/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0121 - val_loss: 0.0432\n",
      "Epoch 356/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0433\n",
      "Epoch 357/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0123 - val_loss: 0.0434\n",
      "Epoch 358/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0122 - val_loss: 0.0433\n",
      "Epoch 359/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0432\n",
      "Epoch 360/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0121 - val_loss: 0.0431\n",
      "Epoch 361/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0122 - val_loss: 0.0431\n",
      "Epoch 362/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0430\n",
      "Epoch 363/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0430\n",
      "Epoch 364/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0120 - val_loss: 0.0430\n",
      "Epoch 365/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 0.0430\n",
      "Epoch 366/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 0.0429\n",
      "Epoch 367/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0122 - val_loss: 0.0428\n",
      "Epoch 368/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0120 - val_loss: 0.0426\n",
      "Epoch 369/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 0.0424\n",
      "Epoch 370/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0120 - val_loss: 0.0422\n",
      "Epoch 371/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 0.0422\n",
      "Epoch 372/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0118 - val_loss: 0.0423\n",
      "Epoch 373/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0121 - val_loss: 0.0424\n",
      "Epoch 374/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0118 - val_loss: 0.0426\n",
      "Epoch 375/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 0.0427\n",
      "Epoch 376/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0118 - val_loss: 0.0428\n",
      "Epoch 377/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0118 - val_loss: 0.0428\n",
      "Epoch 378/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0120 - val_loss: 0.0427\n",
      "Epoch 379/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 0.0426\n",
      "Epoch 380/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0116 - val_loss: 0.0424\n",
      "Epoch 381/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0118 - val_loss: 0.0423\n",
      "Epoch 382/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0422\n",
      "Epoch 383/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0118 - val_loss: 0.0422\n",
      "Epoch 384/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0117 - val_loss: 0.0421\n",
      "Epoch 385/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0118 - val_loss: 0.0421\n",
      "Epoch 386/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 0.0421\n",
      "Epoch 387/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0117 - val_loss: 0.0421\n",
      "Epoch 388/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0117 - val_loss: 0.0421\n",
      "Epoch 389/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0117 - val_loss: 0.0422\n",
      "Epoch 390/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0116 - val_loss: 0.0422\n",
      "Epoch 391/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0118 - val_loss: 0.0422\n",
      "Epoch 392/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0116 - val_loss: 0.0422\n",
      "Epoch 393/1000\n",
      "9000/9000 [==============================] - 0s 6us/step - loss: 0.0116 - val_loss: 0.0422\n",
      "Epoch 394/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0117 - val_loss: 0.0422\n",
      "Epoch 395/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0118 - val_loss: 0.0422\n",
      "Epoch 396/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0116 - val_loss: 0.0422\n",
      "Epoch 397/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0115 - val_loss: 0.0423\n",
      "Epoch 398/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0115 - val_loss: 0.0422\n",
      "Epoch 399/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0116 - val_loss: 0.0422\n",
      "Epoch 400/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0117 - val_loss: 0.0421\n",
      "Epoch 401/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0114 - val_loss: 0.0421\n",
      "Epoch 402/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0114 - val_loss: 0.0421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0116 - val_loss: 0.0421\n",
      "Epoch 404/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0115 - val_loss: 0.0422\n",
      "Epoch 405/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0116 - val_loss: 0.0422\n",
      "Epoch 406/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0115 - val_loss: 0.0421\n",
      "Epoch 407/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0115 - val_loss: 0.0421\n",
      "Epoch 408/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0115 - val_loss: 0.0421\n",
      "Epoch 409/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0115 - val_loss: 0.0420\n",
      "Epoch 410/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0114 - val_loss: 0.0418\n",
      "Epoch 411/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0416\n",
      "Epoch 412/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0414\n",
      "Epoch 413/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0414\n",
      "Epoch 414/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0414\n",
      "Epoch 415/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0415\n",
      "Epoch 416/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0114 - val_loss: 0.0417\n",
      "Epoch 417/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0418\n",
      "Epoch 418/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0112 - val_loss: 0.0419\n",
      "Epoch 419/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0418\n",
      "Epoch 420/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0417\n",
      "Epoch 421/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0417\n",
      "Epoch 422/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0417\n",
      "Epoch 423/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0417\n",
      "Epoch 424/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0418\n",
      "Epoch 425/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0418\n",
      "Epoch 426/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0113 - val_loss: 0.0418\n",
      "Epoch 427/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0112 - val_loss: 0.0417\n",
      "Epoch 428/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0113 - val_loss: 0.0417\n",
      "Epoch 429/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0113 - val_loss: 0.0416\n",
      "Epoch 430/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0111 - val_loss: 0.0416\n",
      "Epoch 431/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0112 - val_loss: 0.0415\n",
      "Epoch 432/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0113 - val_loss: 0.0415\n",
      "Epoch 433/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0112 - val_loss: 0.0415\n",
      "Epoch 434/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0111 - val_loss: 0.0415\n",
      "Epoch 435/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0112 - val_loss: 0.0416\n",
      "Epoch 436/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0111 - val_loss: 0.0416\n",
      "Epoch 437/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0112 - val_loss: 0.0416\n",
      "Epoch 438/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0111 - val_loss: 0.0415\n",
      "Epoch 439/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0111 - val_loss: 0.0415\n",
      "Epoch 440/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0111 - val_loss: 0.0415\n",
      "Epoch 441/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0109 - val_loss: 0.0414\n",
      "Epoch 442/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0412\n",
      "Epoch 443/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0411\n",
      "Epoch 444/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0111 - val_loss: 0.0410\n",
      "Epoch 445/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0410\n",
      "Epoch 446/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0411\n",
      "Epoch 447/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0412\n",
      "Epoch 448/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0413\n",
      "Epoch 449/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0413\n",
      "Epoch 450/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0413\n",
      "Epoch 451/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0412\n",
      "Epoch 452/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0412\n",
      "Epoch 453/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0411\n",
      "Epoch 454/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0109 - val_loss: 0.0410\n",
      "Epoch 455/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0410\n",
      "Epoch 456/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0410\n",
      "Epoch 457/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0411\n",
      "Epoch 458/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0109 - val_loss: 0.0411\n",
      "Epoch 459/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0412\n",
      "Epoch 460/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0109 - val_loss: 0.0411\n",
      "Epoch 461/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0109 - val_loss: 0.0410\n",
      "Epoch 462/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0110 - val_loss: 0.0410\n",
      "Epoch 463/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 0.0410\n",
      "Epoch 464/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0409\n",
      "Epoch 465/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0409\n",
      "Epoch 466/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 0.0410\n",
      "Epoch 467/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0109 - val_loss: 0.0410\n",
      "Epoch 468/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 0.0410\n",
      "Epoch 469/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0410\n",
      "Epoch 470/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0109 - val_loss: 0.0410\n",
      "Epoch 471/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0109 - val_loss: 0.0410\n",
      "Epoch 472/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 0.0410\n",
      "Epoch 473/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 0.0409\n",
      "Epoch 474/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0409\n",
      "Epoch 475/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0409\n",
      "Epoch 476/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0107 - val_loss: 0.0410\n",
      "Epoch 477/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0409\n",
      "Epoch 478/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0409\n",
      "Epoch 479/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0408\n",
      "Epoch 480/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 0.0408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0407\n",
      "Epoch 482/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0407\n",
      "Epoch 483/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0408\n",
      "Epoch 484/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0408\n",
      "Epoch 485/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 0.0408\n",
      "Epoch 486/1000\n",
      "9000/9000 [==============================] - 0s 6us/step - loss: 0.0105 - val_loss: 0.0408\n",
      "Epoch 487/1000\n",
      "9000/9000 [==============================] - 0s 6us/step - loss: 0.0105 - val_loss: 0.0407\n",
      "Epoch 488/1000\n",
      "9000/9000 [==============================] - 0s 6us/step - loss: 0.0108 - val_loss: 0.0407\n",
      "Epoch 489/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0406\n",
      "Epoch 490/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0406\n",
      "Epoch 491/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0407\n",
      "Epoch 492/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0407\n",
      "Epoch 493/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0408\n",
      "Epoch 494/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0408\n",
      "Epoch 495/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0409\n",
      "Epoch 496/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0104 - val_loss: 0.0408\n",
      "Epoch 497/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0105 - val_loss: 0.0408\n",
      "Epoch 498/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0104 - val_loss: 0.0407\n",
      "Epoch 499/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0105 - val_loss: 0.0407\n",
      "Epoch 500/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0105 - val_loss: 0.0407\n",
      "Epoch 501/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0105 - val_loss: 0.0407\n",
      "Epoch 502/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0106 - val_loss: 0.0407\n",
      "Epoch 503/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0107 - val_loss: 0.0407\n",
      "Epoch 504/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0407\n",
      "Epoch 505/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0103 - val_loss: 0.0407\n",
      "Epoch 506/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0106 - val_loss: 0.0407\n",
      "Epoch 507/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0106 - val_loss: 0.0407\n",
      "Epoch 508/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0104 - val_loss: 0.0407\n",
      "Epoch 509/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0106 - val_loss: 0.0408\n",
      "Epoch 510/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0103 - val_loss: 0.0408\n",
      "Epoch 511/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0104 - val_loss: 0.0407\n",
      "Epoch 512/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0407\n",
      "Epoch 513/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0105 - val_loss: 0.0406\n",
      "Epoch 514/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0105 - val_loss: 0.0405\n",
      "Epoch 515/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0103 - val_loss: 0.0404\n",
      "Epoch 516/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0104 - val_loss: 0.0403\n",
      "Epoch 517/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0403\n",
      "Epoch 518/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0104 - val_loss: 0.0403\n",
      "Epoch 519/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0403\n",
      "Epoch 520/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0402\n",
      "Epoch 521/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0401\n",
      "Epoch 522/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0400\n",
      "Epoch 523/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0399\n",
      "Epoch 524/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0399\n",
      "Epoch 525/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0399\n",
      "Epoch 526/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0400\n",
      "Epoch 527/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0401\n",
      "Epoch 528/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0104 - val_loss: 0.0401\n",
      "Epoch 529/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0402\n",
      "Epoch 530/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0402\n",
      "Epoch 531/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0104 - val_loss: 0.0401\n",
      "Epoch 532/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0401\n",
      "Epoch 533/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0103 - val_loss: 0.0401\n",
      "Epoch 534/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0402\n",
      "Epoch 535/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0403\n",
      "Epoch 536/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0102 - val_loss: 0.0403\n",
      "Epoch 537/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0402\n",
      "Epoch 538/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0401\n",
      "Epoch 539/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0400\n",
      "Epoch 540/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0398\n",
      "Epoch 541/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0102 - val_loss: 0.0397\n",
      "Epoch 542/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0397\n",
      "Epoch 543/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0398\n",
      "Epoch 544/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0399\n",
      "Epoch 545/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0398\n",
      "Epoch 546/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0398\n",
      "Epoch 547/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0398\n",
      "Epoch 548/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0398\n",
      "Epoch 549/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0398\n",
      "Epoch 550/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0398\n",
      "Epoch 551/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0398\n",
      "Epoch 552/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0399\n",
      "Epoch 553/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0399\n",
      "Epoch 554/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0399\n",
      "Epoch 555/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0100 - val_loss: 0.0399\n",
      "Epoch 556/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0399\n",
      "Epoch 557/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0399\n",
      "Epoch 558/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0100 - val_loss: 0.0400\n",
      "Epoch 560/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0401\n",
      "Epoch 561/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0101 - val_loss: 0.0400\n",
      "Epoch 562/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0400\n",
      "Epoch 563/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0398\n",
      "Epoch 564/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0397\n",
      "Epoch 565/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0397\n",
      "Epoch 566/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0397\n",
      "Epoch 567/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0397\n",
      "Epoch 568/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0397\n",
      "Epoch 569/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0397\n",
      "Epoch 570/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0396\n",
      "Epoch 571/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0396\n",
      "Epoch 572/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0396\n",
      "Epoch 573/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0396\n",
      "Epoch 574/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0099 - val_loss: 0.0396\n",
      "Epoch 575/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0395\n",
      "Epoch 576/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0395\n",
      "Epoch 577/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0100 - val_loss: 0.0395\n",
      "Epoch 578/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0099 - val_loss: 0.0394\n",
      "Epoch 579/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0099 - val_loss: 0.0394\n",
      "Epoch 580/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0099 - val_loss: 0.0394\n",
      "Epoch 581/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0394\n",
      "Epoch 582/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0100 - val_loss: 0.0393\n",
      "Epoch 583/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0099 - val_loss: 0.0393\n",
      "Epoch 584/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0393\n",
      "Epoch 585/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0099 - val_loss: 0.0394\n",
      "Epoch 586/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0394\n",
      "Epoch 587/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0395\n",
      "Epoch 588/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0395\n",
      "Epoch 589/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0395\n",
      "Epoch 590/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0099 - val_loss: 0.0394\n",
      "Epoch 591/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0393\n",
      "Epoch 592/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0393\n",
      "Epoch 593/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0392\n",
      "Epoch 594/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0393\n",
      "Epoch 595/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0394\n",
      "Epoch 596/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0395\n",
      "Epoch 597/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0395\n",
      "Epoch 598/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0394\n",
      "Epoch 599/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0393\n",
      "Epoch 600/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0391\n",
      "Epoch 601/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0390\n",
      "Epoch 602/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0390\n",
      "Epoch 603/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0391\n",
      "Epoch 604/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0392\n",
      "Epoch 605/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0393\n",
      "Epoch 606/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0393\n",
      "Epoch 607/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0098 - val_loss: 0.0393\n",
      "Epoch 608/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0393\n",
      "Epoch 609/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0392\n",
      "Epoch 610/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0390\n",
      "Epoch 611/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0389\n",
      "Epoch 612/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0389\n",
      "Epoch 613/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0390\n",
      "Epoch 614/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0391\n",
      "Epoch 615/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0392\n",
      "Epoch 616/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0392\n",
      "Epoch 617/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0096 - val_loss: 0.0392\n",
      "Epoch 618/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0096 - val_loss: 0.0390\n",
      "Epoch 619/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0096 - val_loss: 0.0389\n",
      "Epoch 620/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0389\n",
      "Epoch 621/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0389\n",
      "Epoch 622/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0390\n",
      "Epoch 623/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0390\n",
      "Epoch 624/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0390\n",
      "Epoch 625/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0389\n",
      "Epoch 626/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0389\n",
      "Epoch 627/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0389\n",
      "Epoch 628/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0390\n",
      "Epoch 629/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0391\n",
      "Epoch 630/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0391\n",
      "Epoch 631/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0391\n",
      "Epoch 632/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0390\n",
      "Epoch 633/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0390\n",
      "Epoch 634/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0390\n",
      "Epoch 635/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0391\n",
      "Epoch 636/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 637/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0393\n",
      "Epoch 638/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0096 - val_loss: 0.0393\n",
      "Epoch 639/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0393\n",
      "Epoch 640/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0392\n",
      "Epoch 641/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0391\n",
      "Epoch 642/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0391\n",
      "Epoch 643/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0391\n",
      "Epoch 644/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0391\n",
      "Epoch 645/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0391\n",
      "Epoch 646/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0391\n",
      "Epoch 647/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0391\n",
      "Epoch 648/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0390\n",
      "Epoch 649/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0389\n",
      "Epoch 650/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0389\n",
      "Epoch 651/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0388\n",
      "Epoch 652/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0388\n",
      "Epoch 653/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0389\n",
      "Epoch 654/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0389\n",
      "Epoch 655/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0390\n",
      "Epoch 656/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0390\n",
      "Epoch 657/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0391\n",
      "Epoch 658/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0391\n",
      "Epoch 659/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0391\n",
      "Epoch 660/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0390\n",
      "Epoch 661/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0388\n",
      "Epoch 662/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0387\n",
      "Epoch 663/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0387\n",
      "Epoch 664/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0387\n",
      "Epoch 665/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0388\n",
      "Epoch 666/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0388\n",
      "Epoch 667/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0387\n",
      "Epoch 668/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0387\n",
      "Epoch 669/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0092 - val_loss: 0.0386\n",
      "Epoch 670/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0385\n",
      "Epoch 671/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0386\n",
      "Epoch 672/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0387\n",
      "Epoch 673/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0092 - val_loss: 0.0388\n",
      "Epoch 674/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0389\n",
      "Epoch 675/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0389\n",
      "Epoch 676/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0389\n",
      "Epoch 677/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0389\n",
      "Epoch 678/1000\n",
      "9000/9000 [==============================] - 0s 6us/step - loss: 0.0092 - val_loss: 0.0388\n",
      "Epoch 679/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0387\n",
      "Epoch 680/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0094 - val_loss: 0.0387\n",
      "Epoch 681/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0387\n",
      "Epoch 682/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0388\n",
      "Epoch 683/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0388\n",
      "Epoch 684/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0389\n",
      "Epoch 685/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0389\n",
      "Epoch 686/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0092 - val_loss: 0.0388\n",
      "Epoch 687/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0388\n",
      "Epoch 688/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0387\n",
      "Epoch 689/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0387\n",
      "Epoch 690/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0386\n",
      "Epoch 691/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0092 - val_loss: 0.0385\n",
      "Epoch 692/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0384\n",
      "Epoch 693/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0384\n",
      "Epoch 694/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0093 - val_loss: 0.0384\n",
      "Epoch 695/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0385\n",
      "Epoch 696/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0386\n",
      "Epoch 697/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0386\n",
      "Epoch 698/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0387\n",
      "Epoch 699/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0386\n",
      "Epoch 700/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0386\n",
      "Epoch 701/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0385\n",
      "Epoch 702/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0385\n",
      "Epoch 703/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0385\n",
      "Epoch 704/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0385\n",
      "Epoch 705/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0385\n",
      "Epoch 706/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0385\n",
      "Epoch 707/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0384\n",
      "Epoch 708/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0384\n",
      "Epoch 709/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0383\n",
      "Epoch 710/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0383\n",
      "Epoch 711/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0383\n",
      "Epoch 712/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0383\n",
      "Epoch 713/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0384\n",
      "Epoch 714/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0092 - val_loss: 0.0385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0385\n",
      "Epoch 716/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0385\n",
      "Epoch 717/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0384\n",
      "Epoch 718/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0384\n",
      "Epoch 719/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0384\n",
      "Epoch 720/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0383\n",
      "Epoch 721/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0384\n",
      "Epoch 722/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0384\n",
      "Epoch 723/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0384\n",
      "Epoch 724/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0383\n",
      "Epoch 725/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0382\n",
      "Epoch 726/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0382\n",
      "Epoch 727/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0382\n",
      "Epoch 728/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0382\n",
      "Epoch 729/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0381\n",
      "Epoch 730/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0380\n",
      "Epoch 731/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0380\n",
      "Epoch 732/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0380\n",
      "Epoch 733/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0380\n",
      "Epoch 734/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0380\n",
      "Epoch 735/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0381\n",
      "Epoch 736/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0381\n",
      "Epoch 737/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0383\n",
      "Epoch 738/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0384\n",
      "Epoch 739/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0385\n",
      "Epoch 740/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0384\n",
      "Epoch 741/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0383\n",
      "Epoch 742/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0383\n",
      "Epoch 743/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0382\n",
      "Epoch 744/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0383\n",
      "Epoch 745/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0383\n",
      "Epoch 746/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0383\n",
      "Epoch 747/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0383\n",
      "Epoch 748/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0381\n",
      "Epoch 749/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0380\n",
      "Epoch 750/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0380\n",
      "Epoch 751/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0380\n",
      "Epoch 752/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0381\n",
      "Epoch 753/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0382\n",
      "Epoch 754/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0382\n",
      "Epoch 755/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0382\n",
      "Epoch 756/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0382\n",
      "Epoch 757/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0383\n",
      "Epoch 758/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0383\n",
      "Epoch 759/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0090 - val_loss: 0.0382\n",
      "Epoch 760/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0382\n",
      "Epoch 761/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0382\n",
      "Epoch 762/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0381\n",
      "Epoch 763/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0380\n",
      "Epoch 764/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0379\n",
      "Epoch 765/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0379\n",
      "Epoch 766/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0379\n",
      "Epoch 767/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0380\n",
      "Epoch 768/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0381\n",
      "Epoch 769/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0383\n",
      "Epoch 770/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0383\n",
      "Epoch 771/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0384\n",
      "Epoch 772/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0385\n",
      "Epoch 773/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0385\n",
      "Epoch 774/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0384\n",
      "Epoch 775/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0383\n",
      "Epoch 776/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0382\n",
      "Epoch 777/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0382\n",
      "Epoch 778/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0382\n",
      "Epoch 779/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0382\n",
      "Epoch 780/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0383\n",
      "Epoch 781/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0383\n",
      "Epoch 782/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 0.0382\n",
      "Epoch 783/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0381\n",
      "Epoch 784/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 0.0380\n",
      "Epoch 785/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0380\n",
      "Epoch 786/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0380\n",
      "Epoch 787/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0380\n",
      "Epoch 788/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0380\n",
      "Epoch 789/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0381\n",
      "Epoch 790/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0382\n",
      "Epoch 791/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0382\n",
      "Epoch 792/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 793/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0381\n",
      "Epoch 794/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 0.0379\n",
      "Epoch 795/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 0.0379\n",
      "Epoch 796/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0379\n",
      "Epoch 797/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0380\n",
      "Epoch 798/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0380\n",
      "Epoch 799/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0379\n",
      "Epoch 800/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0378\n",
      "Epoch 801/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0378\n",
      "Epoch 802/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0378\n",
      "Epoch 803/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0379\n",
      "Epoch 804/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0379\n",
      "Epoch 805/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 806/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 0.0380\n",
      "Epoch 807/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0379\n",
      "Epoch 808/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0378\n",
      "Epoch 809/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0378\n",
      "Epoch 810/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0379\n",
      "Epoch 811/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 812/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0381\n",
      "Epoch 813/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0381\n",
      "Epoch 814/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0381\n",
      "Epoch 815/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 0.0381\n",
      "Epoch 816/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 817/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0379\n",
      "Epoch 818/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 819/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 820/1000\n",
      "9000/9000 [==============================] - 0s 6us/step - loss: 0.0084 - val_loss: 0.0381\n",
      "Epoch 821/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0381\n",
      "Epoch 822/1000\n",
      "9000/9000 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0381\n",
      "Epoch 823/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 824/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 825/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 826/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0380\n",
      "Epoch 827/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0380\n",
      "Epoch 828/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 829/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0380\n",
      "Epoch 830/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 831/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0380\n",
      "Epoch 832/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0379\n",
      "Epoch 833/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0379\n",
      "Epoch 834/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0379\n",
      "Epoch 835/1000\n",
      "9000/9000 [==============================] - 0s 10us/step - loss: 0.0084 - val_loss: 0.0380\n",
      "Epoch 836/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0381\n",
      "Epoch 837/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0381\n",
      "Epoch 838/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0380\n",
      "Epoch 839/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0380\n",
      "Epoch 840/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0379\n",
      "Epoch 841/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0379\n",
      "Epoch 842/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0379\n",
      "Epoch 843/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0379\n",
      "Epoch 844/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0378\n",
      "Epoch 845/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0378\n",
      "Epoch 846/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0377\n",
      "Epoch 847/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0377\n",
      "Epoch 848/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0377\n",
      "Epoch 849/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0377\n",
      "Epoch 850/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0377\n",
      "Epoch 851/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0377\n",
      "Epoch 852/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0377\n",
      "Epoch 853/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0378\n",
      "Epoch 854/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0379\n",
      "Epoch 855/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0380\n",
      "Epoch 856/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0380\n",
      "Epoch 857/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0379\n",
      "Epoch 858/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0379\n",
      "Epoch 859/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0379\n",
      "Epoch 860/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0380\n",
      "Epoch 861/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0380\n",
      "Epoch 862/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0380\n",
      "Epoch 863/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0380\n",
      "Epoch 864/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0380\n",
      "Epoch 865/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0379\n",
      "Epoch 866/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0378\n",
      "Epoch 867/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0377\n",
      "Epoch 868/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0377\n",
      "Epoch 869/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0377\n",
      "Epoch 870/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0377\n",
      "Epoch 872/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0378\n",
      "Epoch 873/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0378\n",
      "Epoch 874/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0377\n",
      "Epoch 875/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0377\n",
      "Epoch 876/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0376\n",
      "Epoch 877/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0375\n",
      "Epoch 878/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0376\n",
      "Epoch 879/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0377\n",
      "Epoch 880/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0378\n",
      "Epoch 881/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0379\n",
      "Epoch 882/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0379\n",
      "Epoch 883/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0379\n",
      "Epoch 884/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0377\n",
      "Epoch 885/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0376\n",
      "Epoch 886/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0375\n",
      "Epoch 887/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0375\n",
      "Epoch 888/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0375\n",
      "Epoch 889/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0375\n",
      "Epoch 890/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0375\n",
      "Epoch 891/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0375\n",
      "Epoch 892/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0375\n",
      "Epoch 893/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0374\n",
      "Epoch 894/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0373\n",
      "Epoch 895/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0373\n",
      "Epoch 896/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0373\n",
      "Epoch 897/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0373\n",
      "Epoch 898/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0373\n",
      "Epoch 899/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0373\n",
      "Epoch 900/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0372\n",
      "Epoch 901/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0372\n",
      "Epoch 902/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0372\n",
      "Epoch 903/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0373\n",
      "Epoch 904/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0373\n",
      "Epoch 905/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0374\n",
      "Epoch 906/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0375\n",
      "Epoch 907/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0375\n",
      "Epoch 908/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0374\n",
      "Epoch 909/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0373\n",
      "Epoch 910/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0373\n",
      "Epoch 911/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0372\n",
      "Epoch 912/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0372\n",
      "Epoch 913/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0373\n",
      "Epoch 914/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0374\n",
      "Epoch 915/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0375\n",
      "Epoch 916/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0375\n",
      "Epoch 917/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0375\n",
      "Epoch 918/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0375\n",
      "Epoch 919/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0374\n",
      "Epoch 920/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0373\n",
      "Epoch 921/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0372\n",
      "Epoch 922/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0372\n",
      "Epoch 923/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0374\n",
      "Epoch 924/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0375\n",
      "Epoch 925/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0376\n",
      "Epoch 926/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0376\n",
      "Epoch 927/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0376\n",
      "Epoch 928/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0375\n",
      "Epoch 929/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0376\n",
      "Epoch 930/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0376\n",
      "Epoch 931/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0377\n",
      "Epoch 932/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0378\n",
      "Epoch 933/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0378\n",
      "Epoch 934/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0378\n",
      "Epoch 935/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0376\n",
      "Epoch 936/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0375\n",
      "Epoch 937/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0374\n",
      "Epoch 938/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0374\n",
      "Epoch 939/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0374\n",
      "Epoch 940/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0374\n",
      "Epoch 941/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0373\n",
      "Epoch 942/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0371\n",
      "Epoch 943/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0371\n",
      "Epoch 944/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0372\n",
      "Epoch 945/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0373\n",
      "Epoch 946/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0374\n",
      "Epoch 947/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0375\n",
      "Epoch 948/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0374\n",
      "Epoch 950/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0373\n",
      "Epoch 951/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0373\n",
      "Epoch 952/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0373\n",
      "Epoch 953/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0374\n",
      "Epoch 954/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0374\n",
      "Epoch 955/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0374\n",
      "Epoch 956/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0373\n",
      "Epoch 957/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0371\n",
      "Epoch 958/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0370\n",
      "Epoch 959/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0370\n",
      "Epoch 960/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0370\n",
      "Epoch 961/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0370\n",
      "Epoch 962/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0371\n",
      "Epoch 963/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0372\n",
      "Epoch 964/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0373\n",
      "Epoch 965/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0373\n",
      "Epoch 966/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0372\n",
      "Epoch 967/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0371\n",
      "Epoch 968/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0370\n",
      "Epoch 969/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0370\n",
      "Epoch 970/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0371\n",
      "Epoch 971/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0372\n",
      "Epoch 972/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0373\n",
      "Epoch 973/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0372\n",
      "Epoch 974/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0371\n",
      "Epoch 975/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0370\n",
      "Epoch 976/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0370\n",
      "Epoch 977/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0371\n",
      "Epoch 978/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0371\n",
      "Epoch 979/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0371\n",
      "Epoch 980/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0371\n",
      "Epoch 981/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0372\n",
      "Epoch 982/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0372\n",
      "Epoch 983/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0372\n",
      "Epoch 984/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0371\n",
      "Epoch 985/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0371\n",
      "Epoch 986/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0370\n",
      "Epoch 987/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0370\n",
      "Epoch 988/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0369\n",
      "Epoch 989/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0369\n",
      "Epoch 990/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0369\n",
      "Epoch 991/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0369\n",
      "Epoch 992/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0368\n",
      "Epoch 993/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0368\n",
      "Epoch 994/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0368\n",
      "Epoch 995/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0368\n",
      "Epoch 996/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0369\n",
      "Epoch 997/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0369\n",
      "Epoch 998/1000\n",
      "9000/9000 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0369\n",
      "Epoch 999/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0368\n",
      "Epoch 1000/1000\n",
      "9000/9000 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0368\n",
      "Durchlauf:  2\n",
      "positions calculated\n",
      "tcp calculated\n",
      "duplicates erased\n",
      "Train on 8998 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.2116 - val_loss: 0.2249\n",
      "Epoch 2/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.1768 - val_loss: 0.1515\n",
      "Epoch 3/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.1382 - val_loss: 0.1003\n",
      "Epoch 4/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.1184 - val_loss: 0.0750\n",
      "Epoch 5/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.1122 - val_loss: 0.0661\n",
      "Epoch 6/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.1095 - val_loss: 0.0684\n",
      "Epoch 7/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.1058 - val_loss: 0.0777\n",
      "Epoch 8/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0985 - val_loss: 0.0934\n",
      "Epoch 9/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0929 - val_loss: 0.1174\n",
      "Epoch 10/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0894 - val_loss: 0.1464\n",
      "Epoch 11/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0900 - val_loss: 0.1723\n",
      "Epoch 12/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0886 - val_loss: 0.1877\n",
      "Epoch 13/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0859 - val_loss: 0.1887\n",
      "Epoch 14/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0815 - val_loss: 0.1760\n",
      "Epoch 15/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0770 - val_loss: 0.1551\n",
      "Epoch 16/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0738 - val_loss: 0.1329\n",
      "Epoch 17/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0725 - val_loss: 0.1152\n",
      "Epoch 18/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0712 - val_loss: 0.1035\n",
      "Epoch 19/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0695 - val_loss: 0.0985\n",
      "Epoch 20/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0659 - val_loss: 0.0998\n",
      "Epoch 21/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0620 - val_loss: 0.1045\n",
      "Epoch 22/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0590 - val_loss: 0.1089\n",
      "Epoch 23/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0572 - val_loss: 0.1112\n",
      "Epoch 24/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0558 - val_loss: 0.1108\n",
      "Epoch 25/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0540 - val_loss: 0.1076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0522 - val_loss: 0.1021\n",
      "Epoch 27/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0494 - val_loss: 0.0961\n",
      "Epoch 28/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0469 - val_loss: 0.0916\n",
      "Epoch 29/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0454 - val_loss: 0.0897\n",
      "Epoch 30/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0452 - val_loss: 0.0904\n",
      "Epoch 31/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0447 - val_loss: 0.0937\n",
      "Epoch 32/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0434 - val_loss: 0.0991\n",
      "Epoch 33/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0417 - val_loss: 0.1057\n",
      "Epoch 34/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0404 - val_loss: 0.1115\n",
      "Epoch 35/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0392 - val_loss: 0.1149\n",
      "Epoch 36/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0393 - val_loss: 0.1148\n",
      "Epoch 37/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0380 - val_loss: 0.1114\n",
      "Epoch 38/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0377 - val_loss: 0.1054\n",
      "Epoch 39/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0371 - val_loss: 0.0991\n",
      "Epoch 40/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0362 - val_loss: 0.0939\n",
      "Epoch 41/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0359 - val_loss: 0.0908\n",
      "Epoch 42/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0357 - val_loss: 0.0899\n",
      "Epoch 43/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0352 - val_loss: 0.0916\n",
      "Epoch 44/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0343 - val_loss: 0.0949\n",
      "Epoch 45/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0337 - val_loss: 0.0989\n",
      "Epoch 46/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0332 - val_loss: 0.1025\n",
      "Epoch 47/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0328 - val_loss: 0.1048\n",
      "Epoch 48/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0322 - val_loss: 0.1054\n",
      "Epoch 49/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0318 - val_loss: 0.1041\n",
      "Epoch 50/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0319 - val_loss: 0.1013\n",
      "Epoch 51/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0315 - val_loss: 0.0980\n",
      "Epoch 52/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0307 - val_loss: 0.0949\n",
      "Epoch 53/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0305 - val_loss: 0.0927\n",
      "Epoch 54/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0302 - val_loss: 0.0917\n",
      "Epoch 55/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0302 - val_loss: 0.0920\n",
      "Epoch 56/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0297 - val_loss: 0.0931\n",
      "Epoch 57/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0293 - val_loss: 0.0948\n",
      "Epoch 58/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0290 - val_loss: 0.0967\n",
      "Epoch 59/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0290 - val_loss: 0.0979\n",
      "Epoch 60/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0286 - val_loss: 0.0982\n",
      "Epoch 61/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0285 - val_loss: 0.0974\n",
      "Epoch 62/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0282 - val_loss: 0.0961\n",
      "Epoch 63/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0281 - val_loss: 0.0947\n",
      "Epoch 64/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0275 - val_loss: 0.0935\n",
      "Epoch 65/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0274 - val_loss: 0.0929\n",
      "Epoch 66/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0272 - val_loss: 0.0929\n",
      "Epoch 67/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0270 - val_loss: 0.0935\n",
      "Epoch 68/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0267 - val_loss: 0.0947\n",
      "Epoch 69/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0263 - val_loss: 0.0963\n",
      "Epoch 70/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0263 - val_loss: 0.0978\n",
      "Epoch 71/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0263 - val_loss: 0.0990\n",
      "Epoch 72/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0260 - val_loss: 0.0995\n",
      "Epoch 73/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0257 - val_loss: 0.0994\n",
      "Epoch 74/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0257 - val_loss: 0.0985\n",
      "Epoch 75/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0254 - val_loss: 0.0973\n",
      "Epoch 76/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0253 - val_loss: 0.0960\n",
      "Epoch 77/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0249 - val_loss: 0.0950\n",
      "Epoch 78/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0248 - val_loss: 0.0946\n",
      "Epoch 79/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0250 - val_loss: 0.0949\n",
      "Epoch 80/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0246 - val_loss: 0.0955\n",
      "Epoch 81/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0247 - val_loss: 0.0964\n",
      "Epoch 82/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0242 - val_loss: 0.0973\n",
      "Epoch 83/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0244 - val_loss: 0.0977\n",
      "Epoch 84/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0240 - val_loss: 0.0978\n",
      "Epoch 85/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0240 - val_loss: 0.0974\n",
      "Epoch 86/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0241 - val_loss: 0.0968\n",
      "Epoch 87/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0237 - val_loss: 0.0961\n",
      "Epoch 88/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0236 - val_loss: 0.0955\n",
      "Epoch 89/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0236 - val_loss: 0.0953\n",
      "Epoch 90/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0234 - val_loss: 0.0954\n",
      "Epoch 91/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0230 - val_loss: 0.0956\n",
      "Epoch 92/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0227 - val_loss: 0.0959\n",
      "Epoch 93/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0230 - val_loss: 0.0963\n",
      "Epoch 94/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0227 - val_loss: 0.0965\n",
      "Epoch 95/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0228 - val_loss: 0.0965\n",
      "Epoch 96/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0229 - val_loss: 0.0963\n",
      "Epoch 97/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0225 - val_loss: 0.0961\n",
      "Epoch 98/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0224 - val_loss: 0.0961\n",
      "Epoch 99/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0222 - val_loss: 0.0962\n",
      "Epoch 100/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0219 - val_loss: 0.0963\n",
      "Epoch 101/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0223 - val_loss: 0.0964\n",
      "Epoch 102/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0221 - val_loss: 0.0966\n",
      "Epoch 103/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0220 - val_loss: 0.0966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0219 - val_loss: 0.0964\n",
      "Epoch 105/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0216 - val_loss: 0.0964\n",
      "Epoch 106/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0215 - val_loss: 0.0963\n",
      "Epoch 107/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0215 - val_loss: 0.0963\n",
      "Epoch 108/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0215 - val_loss: 0.0960\n",
      "Epoch 109/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0216 - val_loss: 0.0959\n",
      "Epoch 110/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0213 - val_loss: 0.0956\n",
      "Epoch 111/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0212 - val_loss: 0.0953\n",
      "Epoch 112/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0209 - val_loss: 0.0953\n",
      "Epoch 113/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0209 - val_loss: 0.0955\n",
      "Epoch 114/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0208 - val_loss: 0.0957\n",
      "Epoch 115/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0211 - val_loss: 0.0959\n",
      "Epoch 116/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0208 - val_loss: 0.0963\n",
      "Epoch 117/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0205 - val_loss: 0.0964\n",
      "Epoch 118/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0209 - val_loss: 0.0965\n",
      "Epoch 119/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0207 - val_loss: 0.0963\n",
      "Epoch 120/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0203 - val_loss: 0.0958\n",
      "Epoch 121/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0204 - val_loss: 0.0953\n",
      "Epoch 122/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0202 - val_loss: 0.0949\n",
      "Epoch 123/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0203 - val_loss: 0.0947\n",
      "Epoch 124/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0202 - val_loss: 0.0948\n",
      "Epoch 125/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0200 - val_loss: 0.0950\n",
      "Epoch 126/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0199 - val_loss: 0.0952\n",
      "Epoch 127/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0198 - val_loss: 0.0954\n",
      "Epoch 128/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0198 - val_loss: 0.0956\n",
      "Epoch 129/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0196 - val_loss: 0.0956\n",
      "Epoch 130/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0196 - val_loss: 0.0955\n",
      "Epoch 131/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0198 - val_loss: 0.0953\n",
      "Epoch 132/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0197 - val_loss: 0.0951\n",
      "Epoch 133/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0194 - val_loss: 0.0952\n",
      "Epoch 134/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0193 - val_loss: 0.0952\n",
      "Epoch 135/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0195 - val_loss: 0.0952\n",
      "Epoch 136/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0195 - val_loss: 0.0953\n",
      "Epoch 137/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0194 - val_loss: 0.0954\n",
      "Epoch 138/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0191 - val_loss: 0.0953\n",
      "Epoch 139/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0193 - val_loss: 0.0954\n",
      "Epoch 140/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0190 - val_loss: 0.0955\n",
      "Epoch 141/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0188 - val_loss: 0.0955\n",
      "Epoch 142/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0190 - val_loss: 0.0955\n",
      "Epoch 143/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0189 - val_loss: 0.0954\n",
      "Epoch 144/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0192 - val_loss: 0.0954\n",
      "Epoch 145/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0191 - val_loss: 0.0953\n",
      "Epoch 146/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0187 - val_loss: 0.0951\n",
      "Epoch 147/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0184 - val_loss: 0.0949\n",
      "Epoch 148/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0187 - val_loss: 0.0949\n",
      "Epoch 149/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0186 - val_loss: 0.0949\n",
      "Epoch 150/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0183 - val_loss: 0.0951\n",
      "Epoch 151/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0186 - val_loss: 0.0954\n",
      "Epoch 152/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0184 - val_loss: 0.0956\n",
      "Epoch 153/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 0.0959\n",
      "Epoch 154/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 0.0960\n",
      "Epoch 155/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 0.0960\n",
      "Epoch 156/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0182 - val_loss: 0.0960\n",
      "Epoch 157/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 0.0956\n",
      "Epoch 158/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 0.0953\n",
      "Epoch 159/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0179 - val_loss: 0.0950\n",
      "Epoch 160/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0179 - val_loss: 0.0948\n",
      "Epoch 161/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0180 - val_loss: 0.0947\n",
      "Epoch 162/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0177 - val_loss: 0.0947\n",
      "Epoch 163/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0178 - val_loss: 0.0947\n",
      "Epoch 164/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0178 - val_loss: 0.0949\n",
      "Epoch 165/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0177 - val_loss: 0.0953\n",
      "Epoch 166/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0178 - val_loss: 0.0956\n",
      "Epoch 167/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0178 - val_loss: 0.0959\n",
      "Epoch 168/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 0.0959\n",
      "Epoch 169/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0178 - val_loss: 0.0959\n",
      "Epoch 170/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0174 - val_loss: 0.0957\n",
      "Epoch 171/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 0.0955\n",
      "Epoch 172/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0170 - val_loss: 0.0954\n",
      "Epoch 173/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0174 - val_loss: 0.0953\n",
      "Epoch 174/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0172 - val_loss: 0.0952\n",
      "Epoch 175/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0174 - val_loss: 0.0950\n",
      "Epoch 176/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 0.0949\n",
      "Epoch 177/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0172 - val_loss: 0.0950\n",
      "Epoch 178/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0172 - val_loss: 0.0951\n",
      "Epoch 179/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0172 - val_loss: 0.0954\n",
      "Epoch 180/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0170 - val_loss: 0.0954\n",
      "Epoch 181/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0170 - val_loss: 0.0954\n",
      "Epoch 183/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0169 - val_loss: 0.0953\n",
      "Epoch 184/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0171 - val_loss: 0.0951\n",
      "Epoch 185/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0951\n",
      "Epoch 186/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0165 - val_loss: 0.0951\n",
      "Epoch 187/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0950\n",
      "Epoch 188/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0167 - val_loss: 0.0951\n",
      "Epoch 189/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0165 - val_loss: 0.0951\n",
      "Epoch 190/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0951\n",
      "Epoch 191/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0168 - val_loss: 0.0951\n",
      "Epoch 192/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0166 - val_loss: 0.0951\n",
      "Epoch 193/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0164 - val_loss: 0.0951\n",
      "Epoch 194/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0165 - val_loss: 0.0950\n",
      "Epoch 195/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0162 - val_loss: 0.0948\n",
      "Epoch 196/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0947\n",
      "Epoch 197/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0947\n",
      "Epoch 198/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0162 - val_loss: 0.0948\n",
      "Epoch 199/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0163 - val_loss: 0.0949\n",
      "Epoch 200/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0161 - val_loss: 0.0948\n",
      "Epoch 201/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0947\n",
      "Epoch 202/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0946\n",
      "Epoch 203/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0163 - val_loss: 0.0946\n",
      "Epoch 204/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0160 - val_loss: 0.0947\n",
      "Epoch 205/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0162 - val_loss: 0.0946\n",
      "Epoch 206/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0945\n",
      "Epoch 207/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0946\n",
      "Epoch 208/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0160 - val_loss: 0.0947\n",
      "Epoch 209/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0159 - val_loss: 0.0948\n",
      "Epoch 210/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0161 - val_loss: 0.0946\n",
      "Epoch 211/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0944\n",
      "Epoch 212/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0943\n",
      "Epoch 213/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0943\n",
      "Epoch 214/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0945\n",
      "Epoch 215/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0946\n",
      "Epoch 216/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0947\n",
      "Epoch 217/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0947\n",
      "Epoch 218/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0946\n",
      "Epoch 219/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0944\n",
      "Epoch 220/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0156 - val_loss: 0.0944\n",
      "Epoch 221/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0944\n",
      "Epoch 222/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0945\n",
      "Epoch 223/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0156 - val_loss: 0.0947\n",
      "Epoch 224/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0154 - val_loss: 0.0947\n",
      "Epoch 225/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0154 - val_loss: 0.0948\n",
      "Epoch 226/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0154 - val_loss: 0.0947\n",
      "Epoch 227/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0946\n",
      "Epoch 228/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0154 - val_loss: 0.0946\n",
      "Epoch 229/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0152 - val_loss: 0.0944\n",
      "Epoch 230/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0154 - val_loss: 0.0944\n",
      "Epoch 231/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0153 - val_loss: 0.0944\n",
      "Epoch 232/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0153 - val_loss: 0.0944\n",
      "Epoch 233/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0153 - val_loss: 0.0943\n",
      "Epoch 234/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0155 - val_loss: 0.0943\n",
      "Epoch 235/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0944\n",
      "Epoch 236/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0152 - val_loss: 0.0946\n",
      "Epoch 237/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0151 - val_loss: 0.0949\n",
      "Epoch 238/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 0.0953\n",
      "Epoch 239/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0151 - val_loss: 0.0955\n",
      "Epoch 240/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0954\n",
      "Epoch 241/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0151 - val_loss: 0.0952\n",
      "Epoch 242/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0950\n",
      "Epoch 243/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0147 - val_loss: 0.0946\n",
      "Epoch 244/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0149 - val_loss: 0.0943\n",
      "Epoch 245/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0147 - val_loss: 0.0942\n",
      "Epoch 246/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 0.0941\n",
      "Epoch 247/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0148 - val_loss: 0.0942\n",
      "Epoch 248/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0944\n",
      "Epoch 249/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0945\n",
      "Epoch 250/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0145 - val_loss: 0.0946\n",
      "Epoch 251/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0145 - val_loss: 0.0947\n",
      "Epoch 252/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0947\n",
      "Epoch 253/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0145 - val_loss: 0.0948\n",
      "Epoch 254/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0147 - val_loss: 0.0947\n",
      "Epoch 255/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0946\n",
      "Epoch 256/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0144 - val_loss: 0.0945\n",
      "Epoch 257/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0147 - val_loss: 0.0943\n",
      "Epoch 258/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0147 - val_loss: 0.0940\n",
      "Epoch 259/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0939\n",
      "Epoch 260/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0939\n",
      "Epoch 261/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0940\n",
      "Epoch 262/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0942\n",
      "Epoch 263/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0945\n",
      "Epoch 264/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0947\n",
      "Epoch 265/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0144 - val_loss: 0.0949\n",
      "Epoch 266/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0949\n",
      "Epoch 267/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0945\n",
      "Epoch 268/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0944\n",
      "Epoch 269/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0142 - val_loss: 0.0942\n",
      "Epoch 270/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0941\n",
      "Epoch 271/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0940\n",
      "Epoch 272/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0941\n",
      "Epoch 273/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0943\n",
      "Epoch 274/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0943\n",
      "Epoch 275/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0943\n",
      "Epoch 276/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0941\n",
      "Epoch 277/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0140 - val_loss: 0.0941\n",
      "Epoch 278/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0941\n",
      "Epoch 279/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0940\n",
      "Epoch 280/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0941\n",
      "Epoch 281/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0944\n",
      "Epoch 282/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0946\n",
      "Epoch 283/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0948\n",
      "Epoch 284/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0949\n",
      "Epoch 285/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0947\n",
      "Epoch 286/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0946\n",
      "Epoch 287/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0943\n",
      "Epoch 288/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0940\n",
      "Epoch 289/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0937\n",
      "Epoch 290/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0938\n",
      "Epoch 291/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0938\n",
      "Epoch 292/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0939\n",
      "Epoch 293/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0939\n",
      "Epoch 294/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0939\n",
      "Epoch 295/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0938\n",
      "Epoch 296/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0937\n",
      "Epoch 297/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0937\n",
      "Epoch 298/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0936\n",
      "Epoch 299/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0937\n",
      "Epoch 300/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0938\n",
      "Epoch 301/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0940\n",
      "Epoch 302/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0939\n",
      "Epoch 303/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0938\n",
      "Epoch 304/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0938\n",
      "Epoch 305/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0936\n",
      "Epoch 306/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0934\n",
      "Epoch 307/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0935\n",
      "Epoch 308/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0937\n",
      "Epoch 309/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0938\n",
      "Epoch 310/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0938\n",
      "Epoch 311/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0937\n",
      "Epoch 312/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0935\n",
      "Epoch 313/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0933\n",
      "Epoch 314/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0930\n",
      "Epoch 315/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0928\n",
      "Epoch 316/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0927\n",
      "Epoch 317/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0930\n",
      "Epoch 318/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0931\n",
      "Epoch 319/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0932\n",
      "Epoch 320/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0932\n",
      "Epoch 321/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0931\n",
      "Epoch 322/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0930\n",
      "Epoch 323/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0929\n",
      "Epoch 324/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0929\n",
      "Epoch 325/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0930\n",
      "Epoch 326/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0931\n",
      "Epoch 327/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0932\n",
      "Epoch 328/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0931\n",
      "Epoch 329/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0929\n",
      "Epoch 330/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0928\n",
      "Epoch 331/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0928\n",
      "Epoch 332/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0930\n",
      "Epoch 333/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0931\n",
      "Epoch 334/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0931\n",
      "Epoch 335/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0931\n",
      "Epoch 336/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0929\n",
      "Epoch 338/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0927\n",
      "Epoch 339/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0926\n",
      "Epoch 340/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0925\n",
      "Epoch 341/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0926\n",
      "Epoch 342/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0927\n",
      "Epoch 343/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0930\n",
      "Epoch 344/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0933\n",
      "Epoch 345/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0933\n",
      "Epoch 346/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0932\n",
      "Epoch 347/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0931\n",
      "Epoch 348/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0928\n",
      "Epoch 349/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0926\n",
      "Epoch 350/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0925\n",
      "Epoch 351/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0923\n",
      "Epoch 352/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0924\n",
      "Epoch 353/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0925\n",
      "Epoch 354/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0926\n",
      "Epoch 355/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0926\n",
      "Epoch 356/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0926\n",
      "Epoch 357/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0926\n",
      "Epoch 358/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0926\n",
      "Epoch 359/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0926\n",
      "Epoch 360/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0925\n",
      "Epoch 361/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0925\n",
      "Epoch 362/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0925\n",
      "Epoch 363/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0924\n",
      "Epoch 364/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0924\n",
      "Epoch 365/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0921\n",
      "Epoch 366/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0920\n",
      "Epoch 367/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0918\n",
      "Epoch 368/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0918\n",
      "Epoch 369/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0919\n",
      "Epoch 370/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0921\n",
      "Epoch 371/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0923\n",
      "Epoch 372/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0926\n",
      "Epoch 373/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0927\n",
      "Epoch 374/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0925\n",
      "Epoch 375/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0923\n",
      "Epoch 376/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0921\n",
      "Epoch 377/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0919\n",
      "Epoch 378/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0918\n",
      "Epoch 379/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0918\n",
      "Epoch 380/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0121 - val_loss: 0.0919\n",
      "Epoch 381/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0921\n",
      "Epoch 382/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0922\n",
      "Epoch 383/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0923\n",
      "Epoch 384/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0922\n",
      "Epoch 385/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0921\n",
      "Epoch 386/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0920\n",
      "Epoch 387/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0922\n",
      "Epoch 388/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0922\n",
      "Epoch 389/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0924\n",
      "Epoch 390/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0923\n",
      "Epoch 391/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0922\n",
      "Epoch 392/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0921\n",
      "Epoch 393/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0921\n",
      "Epoch 394/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0920\n",
      "Epoch 395/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0920\n",
      "Epoch 396/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0918\n",
      "Epoch 397/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0916\n",
      "Epoch 398/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0914\n",
      "Epoch 399/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0913\n",
      "Epoch 400/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0912\n",
      "Epoch 401/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0119 - val_loss: 0.0912\n",
      "Epoch 402/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0914\n",
      "Epoch 403/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0916\n",
      "Epoch 404/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0919\n",
      "Epoch 405/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0922\n",
      "Epoch 406/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0924\n",
      "Epoch 407/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0926\n",
      "Epoch 408/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0927\n",
      "Epoch 409/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0926\n",
      "Epoch 410/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0923\n",
      "Epoch 411/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0919\n",
      "Epoch 412/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0915\n",
      "Epoch 413/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0912\n",
      "Epoch 414/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0118 - val_loss: 0.0910\n",
      "Epoch 416/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0911\n",
      "Epoch 417/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0912\n",
      "Epoch 418/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0914\n",
      "Epoch 419/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0916\n",
      "Epoch 420/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0916\n",
      "Epoch 421/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0914\n",
      "Epoch 422/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0913\n",
      "Epoch 423/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0912\n",
      "Epoch 424/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0912\n",
      "Epoch 425/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0913\n",
      "Epoch 426/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0913\n",
      "Epoch 427/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0915\n",
      "Epoch 428/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0115 - val_loss: 0.0915\n",
      "Epoch 429/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0916\n",
      "Epoch 430/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0918\n",
      "Epoch 431/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0919\n",
      "Epoch 432/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0917\n",
      "Epoch 433/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0914\n",
      "Epoch 434/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0116 - val_loss: 0.0909\n",
      "Epoch 435/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0906\n",
      "Epoch 436/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0905\n",
      "Epoch 437/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0906\n",
      "Epoch 438/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0908\n",
      "Epoch 439/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0111 - val_loss: 0.0911\n",
      "Epoch 440/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0912\n",
      "Epoch 441/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0912\n",
      "Epoch 442/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0911\n",
      "Epoch 443/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0910\n",
      "Epoch 444/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0111 - val_loss: 0.0909\n",
      "Epoch 445/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0909\n",
      "Epoch 446/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0908\n",
      "Epoch 447/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0907\n",
      "Epoch 448/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0114 - val_loss: 0.0906\n",
      "Epoch 449/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0907\n",
      "Epoch 450/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0908\n",
      "Epoch 451/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 0.0911\n",
      "Epoch 452/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0911\n",
      "Epoch 453/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0910\n",
      "Epoch 454/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0910\n",
      "Epoch 455/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0908\n",
      "Epoch 456/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0908\n",
      "Epoch 457/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0909\n",
      "Epoch 458/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0113 - val_loss: 0.0910\n",
      "Epoch 459/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0911\n",
      "Epoch 460/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0113 - val_loss: 0.0912\n",
      "Epoch 461/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0911\n",
      "Epoch 462/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0113 - val_loss: 0.0909\n",
      "Epoch 463/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 0.0906\n",
      "Epoch 464/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0905\n",
      "Epoch 465/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0905\n",
      "Epoch 466/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0907\n",
      "Epoch 467/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0109 - val_loss: 0.0908\n",
      "Epoch 468/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0910\n",
      "Epoch 469/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 0.0910\n",
      "Epoch 470/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0910\n",
      "Epoch 471/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0911\n",
      "Epoch 472/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0910\n",
      "Epoch 473/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0910\n",
      "Epoch 474/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0910\n",
      "Epoch 475/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0111 - val_loss: 0.0907\n",
      "Epoch 476/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0903\n",
      "Epoch 477/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0110 - val_loss: 0.0901\n",
      "Epoch 478/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0899\n",
      "Epoch 479/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0899\n",
      "Epoch 480/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0900\n",
      "Epoch 481/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0901\n",
      "Epoch 482/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0903\n",
      "Epoch 483/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0904\n",
      "Epoch 484/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0904\n",
      "Epoch 485/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0902\n",
      "Epoch 486/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0901\n",
      "Epoch 487/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0900\n",
      "Epoch 488/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0900\n",
      "Epoch 489/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0901\n",
      "Epoch 490/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0902\n",
      "Epoch 491/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0905\n",
      "Epoch 492/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0904\n",
      "Epoch 494/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0902\n",
      "Epoch 495/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0900\n",
      "Epoch 496/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0900\n",
      "Epoch 497/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0900\n",
      "Epoch 498/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0902\n",
      "Epoch 499/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0903\n",
      "Epoch 500/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0905\n",
      "Epoch 501/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 0.0904\n",
      "Epoch 502/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0902\n",
      "Epoch 503/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0899\n",
      "Epoch 504/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0897\n",
      "Epoch 505/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0895\n",
      "Epoch 506/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0896\n",
      "Epoch 507/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0897\n",
      "Epoch 508/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0898\n",
      "Epoch 509/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0107 - val_loss: 0.0898\n",
      "Epoch 510/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0898\n",
      "Epoch 511/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0896\n",
      "Epoch 512/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0894\n",
      "Epoch 513/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0893\n",
      "Epoch 514/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0108 - val_loss: 0.0892\n",
      "Epoch 515/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0107 - val_loss: 0.0893\n",
      "Epoch 516/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0106 - val_loss: 0.0894\n",
      "Epoch 517/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0897\n",
      "Epoch 518/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0899\n",
      "Epoch 519/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0901\n",
      "Epoch 520/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0902\n",
      "Epoch 521/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0900\n",
      "Epoch 522/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0107 - val_loss: 0.0898\n",
      "Epoch 523/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0106 - val_loss: 0.0897\n",
      "Epoch 524/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0105 - val_loss: 0.0896\n",
      "Epoch 525/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0895\n",
      "Epoch 526/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0894\n",
      "Epoch 527/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0894\n",
      "Epoch 528/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0108 - val_loss: 0.0896\n",
      "Epoch 529/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0899\n",
      "Epoch 530/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0899\n",
      "Epoch 531/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0104 - val_loss: 0.0898\n",
      "Epoch 532/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0896\n",
      "Epoch 533/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0107 - val_loss: 0.0894\n",
      "Epoch 534/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0892\n",
      "Epoch 535/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0105 - val_loss: 0.0891\n",
      "Epoch 536/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0891\n",
      "Epoch 537/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0102 - val_loss: 0.0892\n",
      "Epoch 538/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0893\n",
      "Epoch 539/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0895\n",
      "Epoch 540/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0897\n",
      "Epoch 541/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0898\n",
      "Epoch 542/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0898\n",
      "Epoch 543/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0898\n",
      "Epoch 544/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0898\n",
      "Epoch 545/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0896\n",
      "Epoch 546/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0893\n",
      "Epoch 547/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0890\n",
      "Epoch 548/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0888\n",
      "Epoch 549/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0887\n",
      "Epoch 550/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0887\n",
      "Epoch 551/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0888\n",
      "Epoch 552/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0890\n",
      "Epoch 553/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0893\n",
      "Epoch 554/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0894\n",
      "Epoch 555/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0895\n",
      "Epoch 556/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0893\n",
      "Epoch 557/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0892\n",
      "Epoch 558/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0890\n",
      "Epoch 559/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0891\n",
      "Epoch 560/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0890\n",
      "Epoch 561/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0889\n",
      "Epoch 562/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0888\n",
      "Epoch 563/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0887\n",
      "Epoch 564/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0886\n",
      "Epoch 565/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0887\n",
      "Epoch 566/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0889\n",
      "Epoch 567/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0890\n",
      "Epoch 568/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0892\n",
      "Epoch 569/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0892\n",
      "Epoch 570/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0890\n",
      "Epoch 572/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0888\n",
      "Epoch 573/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0885\n",
      "Epoch 574/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0884\n",
      "Epoch 575/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0884\n",
      "Epoch 576/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0885\n",
      "Epoch 577/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0889\n",
      "Epoch 578/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0892\n",
      "Epoch 579/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0895\n",
      "Epoch 580/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0894\n",
      "Epoch 581/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0890\n",
      "Epoch 582/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0102 - val_loss: 0.0887\n",
      "Epoch 583/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0103 - val_loss: 0.0884\n",
      "Epoch 584/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0882\n",
      "Epoch 585/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0881\n",
      "Epoch 586/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0881\n",
      "Epoch 587/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0882\n",
      "Epoch 588/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0884\n",
      "Epoch 589/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0101 - val_loss: 0.0886\n",
      "Epoch 590/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0886\n",
      "Epoch 591/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0101 - val_loss: 0.0884\n",
      "Epoch 592/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0099 - val_loss: 0.0883\n",
      "Epoch 593/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0101 - val_loss: 0.0881\n",
      "Epoch 594/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0101 - val_loss: 0.0881\n",
      "Epoch 595/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0882\n",
      "Epoch 596/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0883\n",
      "Epoch 597/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0100 - val_loss: 0.0882\n",
      "Epoch 598/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0881\n",
      "Epoch 599/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0880\n",
      "Epoch 600/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0881\n",
      "Epoch 601/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0883\n",
      "Epoch 602/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0883\n",
      "Epoch 603/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0100 - val_loss: 0.0884\n",
      "Epoch 604/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0883\n",
      "Epoch 605/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0882\n",
      "Epoch 606/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0878\n",
      "Epoch 607/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0874\n",
      "Epoch 608/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0098 - val_loss: 0.0873\n",
      "Epoch 609/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0100 - val_loss: 0.0876\n",
      "Epoch 610/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0098 - val_loss: 0.0879\n",
      "Epoch 611/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0882\n",
      "Epoch 612/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0884\n",
      "Epoch 613/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0886\n",
      "Epoch 614/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0101 - val_loss: 0.0884\n",
      "Epoch 615/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0099 - val_loss: 0.0882\n",
      "Epoch 616/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0097 - val_loss: 0.0879\n",
      "Epoch 617/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0874\n",
      "Epoch 618/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0873\n",
      "Epoch 619/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0100 - val_loss: 0.0874\n",
      "Epoch 620/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0098 - val_loss: 0.0876\n",
      "Epoch 621/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0098 - val_loss: 0.0878\n",
      "Epoch 622/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0880\n",
      "Epoch 623/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0881\n",
      "Epoch 624/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0881\n",
      "Epoch 625/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0098 - val_loss: 0.0880\n",
      "Epoch 626/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0100 - val_loss: 0.0879\n",
      "Epoch 627/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0879\n",
      "Epoch 628/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0880\n",
      "Epoch 629/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0881\n",
      "Epoch 630/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0096 - val_loss: 0.0881\n",
      "Epoch 631/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0879\n",
      "Epoch 632/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0877\n",
      "Epoch 633/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0875\n",
      "Epoch 634/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0097 - val_loss: 0.0874\n",
      "Epoch 635/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0098 - val_loss: 0.0875\n",
      "Epoch 636/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0097 - val_loss: 0.0876\n",
      "Epoch 637/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0877\n",
      "Epoch 638/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0877\n",
      "Epoch 639/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0877\n",
      "Epoch 640/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0875\n",
      "Epoch 641/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0097 - val_loss: 0.0873\n",
      "Epoch 642/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0871\n",
      "Epoch 643/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0871\n",
      "Epoch 644/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0872\n",
      "Epoch 645/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0874\n",
      "Epoch 646/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0876\n",
      "Epoch 647/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0096 - val_loss: 0.0879\n",
      "Epoch 648/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0096 - val_loss: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0095 - val_loss: 0.0883\n",
      "Epoch 650/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0883\n",
      "Epoch 651/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0880\n",
      "Epoch 652/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0877\n",
      "Epoch 653/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0875\n",
      "Epoch 654/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0872\n",
      "Epoch 655/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0872\n",
      "Epoch 656/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0871\n",
      "Epoch 657/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0872\n",
      "Epoch 658/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0874\n",
      "Epoch 659/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0875\n",
      "Epoch 660/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0875\n",
      "Epoch 661/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0874\n",
      "Epoch 662/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0874\n",
      "Epoch 663/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0872\n",
      "Epoch 664/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0872\n",
      "Epoch 665/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0873\n",
      "Epoch 666/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0875\n",
      "Epoch 667/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0876\n",
      "Epoch 668/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0877\n",
      "Epoch 669/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0875\n",
      "Epoch 670/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0095 - val_loss: 0.0872\n",
      "Epoch 671/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0869\n",
      "Epoch 672/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0095 - val_loss: 0.0865\n",
      "Epoch 673/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0864\n",
      "Epoch 674/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0095 - val_loss: 0.0864\n",
      "Epoch 675/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0867\n",
      "Epoch 676/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0871\n",
      "Epoch 677/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0096 - val_loss: 0.0876\n",
      "Epoch 678/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0879\n",
      "Epoch 679/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0879\n",
      "Epoch 680/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0876\n",
      "Epoch 681/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0097 - val_loss: 0.0871\n",
      "Epoch 682/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0865\n",
      "Epoch 683/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0862\n",
      "Epoch 684/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0862\n",
      "Epoch 685/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0862\n",
      "Epoch 686/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 0.0865\n",
      "Epoch 687/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 0.0869\n",
      "Epoch 688/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0873\n",
      "Epoch 689/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0095 - val_loss: 0.0875\n",
      "Epoch 690/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 0.0874\n",
      "Epoch 691/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 0.0871\n",
      "Epoch 692/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0866\n",
      "Epoch 693/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0861\n",
      "Epoch 694/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0859\n",
      "Epoch 695/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0092 - val_loss: 0.0859\n",
      "Epoch 696/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0860\n",
      "Epoch 697/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0862\n",
      "Epoch 698/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0864\n",
      "Epoch 699/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0864\n",
      "Epoch 700/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 0.0865\n",
      "Epoch 701/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0095 - val_loss: 0.0864\n",
      "Epoch 702/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0863\n",
      "Epoch 703/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0861\n",
      "Epoch 704/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0860\n",
      "Epoch 705/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0861\n",
      "Epoch 706/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0862\n",
      "Epoch 707/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0865\n",
      "Epoch 708/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0866\n",
      "Epoch 709/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0866\n",
      "Epoch 710/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0865\n",
      "Epoch 711/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 0.0864\n",
      "Epoch 712/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0865\n",
      "Epoch 713/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 0.0865\n",
      "Epoch 714/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0865\n",
      "Epoch 715/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0092 - val_loss: 0.0865\n",
      "Epoch 716/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0867\n",
      "Epoch 717/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0868\n",
      "Epoch 718/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0867\n",
      "Epoch 719/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0866\n",
      "Epoch 720/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0863\n",
      "Epoch 721/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0862\n",
      "Epoch 722/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0862\n",
      "Epoch 723/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0091 - val_loss: 0.0861\n",
      "Epoch 724/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0092 - val_loss: 0.0862\n",
      "Epoch 725/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0864\n",
      "Epoch 726/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 727/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0866\n",
      "Epoch 728/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0866\n",
      "Epoch 729/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0865\n",
      "Epoch 730/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0092 - val_loss: 0.0864\n",
      "Epoch 731/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0863\n",
      "Epoch 732/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0863\n",
      "Epoch 733/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0091 - val_loss: 0.0863\n",
      "Epoch 734/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0863\n",
      "Epoch 735/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0864\n",
      "Epoch 736/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0864\n",
      "Epoch 737/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0864\n",
      "Epoch 738/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0091 - val_loss: 0.0863\n",
      "Epoch 739/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0863\n",
      "Epoch 740/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0864\n",
      "Epoch 741/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0091 - val_loss: 0.0867\n",
      "Epoch 742/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0091 - val_loss: 0.0868\n",
      "Epoch 743/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0867\n",
      "Epoch 744/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0867\n",
      "Epoch 745/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0092 - val_loss: 0.0865\n",
      "Epoch 746/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0865\n",
      "Epoch 747/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0864\n",
      "Epoch 748/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0090 - val_loss: 0.0861\n",
      "Epoch 749/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0859\n",
      "Epoch 750/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0857\n",
      "Epoch 751/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0858\n",
      "Epoch 752/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0091 - val_loss: 0.0859\n",
      "Epoch 753/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0861\n",
      "Epoch 754/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0861\n",
      "Epoch 755/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0088 - val_loss: 0.0860\n",
      "Epoch 756/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0860\n",
      "Epoch 757/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0089 - val_loss: 0.0860\n",
      "Epoch 758/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0862\n",
      "Epoch 759/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0089 - val_loss: 0.0863\n",
      "Epoch 760/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0866\n",
      "Epoch 761/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0090 - val_loss: 0.0866\n",
      "Epoch 762/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0091 - val_loss: 0.0866\n",
      "Epoch 763/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0864\n",
      "Epoch 764/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0091 - val_loss: 0.0863\n",
      "Epoch 765/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0090 - val_loss: 0.0862\n",
      "Epoch 766/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0092 - val_loss: 0.0861\n",
      "Epoch 767/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0863\n",
      "Epoch 768/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0863\n",
      "Epoch 769/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0866\n",
      "Epoch 770/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0868\n",
      "Epoch 771/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0869\n",
      "Epoch 772/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0870\n",
      "Epoch 773/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0869\n",
      "Epoch 774/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0868\n",
      "Epoch 775/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0866\n",
      "Epoch 776/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0862\n",
      "Epoch 777/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0088 - val_loss: 0.0860\n",
      "Epoch 778/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0860\n",
      "Epoch 779/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0861\n",
      "Epoch 780/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0865\n",
      "Epoch 781/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0867\n",
      "Epoch 782/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0090 - val_loss: 0.0869\n",
      "Epoch 783/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0869\n",
      "Epoch 784/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0868\n",
      "Epoch 785/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0866\n",
      "Epoch 786/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0864\n",
      "Epoch 787/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0863\n",
      "Epoch 788/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0862\n",
      "Epoch 789/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0863\n",
      "Epoch 790/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0087 - val_loss: 0.0863\n",
      "Epoch 791/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0865\n",
      "Epoch 792/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0869\n",
      "Epoch 793/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0871\n",
      "Epoch 794/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0870\n",
      "Epoch 795/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0867\n",
      "Epoch 796/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0863\n",
      "Epoch 797/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0859\n",
      "Epoch 798/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0858\n",
      "Epoch 799/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0857\n",
      "Epoch 800/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0859\n",
      "Epoch 801/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0861\n",
      "Epoch 802/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0863\n",
      "Epoch 803/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0862\n",
      "Epoch 804/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 805/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0857\n",
      "Epoch 806/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0857\n",
      "Epoch 807/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0859\n",
      "Epoch 808/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0860\n",
      "Epoch 809/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0860\n",
      "Epoch 810/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0860\n",
      "Epoch 811/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0859\n",
      "Epoch 812/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0089 - val_loss: 0.0858\n",
      "Epoch 813/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0859\n",
      "Epoch 814/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0860\n",
      "Epoch 815/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0860\n",
      "Epoch 816/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0861\n",
      "Epoch 817/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0863\n",
      "Epoch 818/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0862\n",
      "Epoch 819/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0862\n",
      "Epoch 820/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0861\n",
      "Epoch 821/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0087 - val_loss: 0.0861\n",
      "Epoch 822/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0087 - val_loss: 0.0859\n",
      "Epoch 823/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0857\n",
      "Epoch 824/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0856\n",
      "Epoch 825/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0087 - val_loss: 0.0855\n",
      "Epoch 826/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0854\n",
      "Epoch 827/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0088 - val_loss: 0.0855\n",
      "Epoch 828/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0857\n",
      "Epoch 829/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0858\n",
      "Epoch 830/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0858\n",
      "Epoch 831/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0859\n",
      "Epoch 832/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0088 - val_loss: 0.0860\n",
      "Epoch 833/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0088 - val_loss: 0.0859\n",
      "Epoch 834/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0857\n",
      "Epoch 835/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0085 - val_loss: 0.0856\n",
      "Epoch 836/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0855\n",
      "Epoch 837/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0853\n",
      "Epoch 838/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0853\n",
      "Epoch 839/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0852\n",
      "Epoch 840/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0087 - val_loss: 0.0853\n",
      "Epoch 841/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0853\n",
      "Epoch 842/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0854\n",
      "Epoch 843/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0853\n",
      "Epoch 844/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0852\n",
      "Epoch 845/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0852\n",
      "Epoch 846/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0087 - val_loss: 0.0854\n",
      "Epoch 847/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0087 - val_loss: 0.0856\n",
      "Epoch 848/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0856\n",
      "Epoch 849/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0857\n",
      "Epoch 850/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0856\n",
      "Epoch 851/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0855\n",
      "Epoch 852/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0853\n",
      "Epoch 853/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0853\n",
      "Epoch 854/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0853\n",
      "Epoch 855/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0852\n",
      "Epoch 856/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0851\n",
      "Epoch 857/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0850\n",
      "Epoch 858/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0850\n",
      "Epoch 859/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0851\n",
      "Epoch 860/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0853\n",
      "Epoch 861/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0855\n",
      "Epoch 862/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0855\n",
      "Epoch 863/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0854\n",
      "Epoch 864/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0851\n",
      "Epoch 865/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0849\n",
      "Epoch 866/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0848\n",
      "Epoch 867/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0848\n",
      "Epoch 868/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0851\n",
      "Epoch 869/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0856\n",
      "Epoch 870/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0860\n",
      "Epoch 871/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0859\n",
      "Epoch 872/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0084 - val_loss: 0.0857\n",
      "Epoch 873/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0854\n",
      "Epoch 874/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0850\n",
      "Epoch 875/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0848\n",
      "Epoch 876/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0848\n",
      "Epoch 877/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0850\n",
      "Epoch 878/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0851\n",
      "Epoch 879/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0851\n",
      "Epoch 880/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0851\n",
      "Epoch 881/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0085 - val_loss: 0.0851\n",
      "Epoch 882/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 883/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0847\n",
      "Epoch 884/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0847\n",
      "Epoch 885/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0085 - val_loss: 0.0848\n",
      "Epoch 886/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0851\n",
      "Epoch 887/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0853\n",
      "Epoch 888/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0856\n",
      "Epoch 889/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0857\n",
      "Epoch 890/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0856\n",
      "Epoch 891/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0854\n",
      "Epoch 892/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0850\n",
      "Epoch 893/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0848\n",
      "Epoch 894/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0848\n",
      "Epoch 895/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0850\n",
      "Epoch 896/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0853\n",
      "Epoch 897/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0853\n",
      "Epoch 898/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0855\n",
      "Epoch 899/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0854\n",
      "Epoch 900/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0852\n",
      "Epoch 901/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0082 - val_loss: 0.0851\n",
      "Epoch 902/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0852\n",
      "Epoch 903/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0851\n",
      "Epoch 904/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0852\n",
      "Epoch 905/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0853\n",
      "Epoch 906/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0854\n",
      "Epoch 907/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0856\n",
      "Epoch 908/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0855\n",
      "Epoch 909/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0853\n",
      "Epoch 910/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0851\n",
      "Epoch 911/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0847\n",
      "Epoch 912/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0846\n",
      "Epoch 913/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0083 - val_loss: 0.0846\n",
      "Epoch 914/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0848\n",
      "Epoch 915/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0851\n",
      "Epoch 916/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0854\n",
      "Epoch 917/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0856\n",
      "Epoch 918/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0855\n",
      "Epoch 919/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0855\n",
      "Epoch 920/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0853\n",
      "Epoch 921/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0852\n",
      "Epoch 922/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0851\n",
      "Epoch 923/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0848\n",
      "Epoch 924/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0847\n",
      "Epoch 925/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0847\n",
      "Epoch 926/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0850\n",
      "Epoch 927/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0853\n",
      "Epoch 928/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0854\n",
      "Epoch 929/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0855\n",
      "Epoch 930/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0855\n",
      "Epoch 931/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0854\n",
      "Epoch 932/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0853\n",
      "Epoch 933/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0851\n",
      "Epoch 934/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0850\n",
      "Epoch 935/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0084 - val_loss: 0.0851\n",
      "Epoch 936/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0853\n",
      "Epoch 937/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0853\n",
      "Epoch 938/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0853\n",
      "Epoch 939/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0853\n",
      "Epoch 940/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0851\n",
      "Epoch 941/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0850\n",
      "Epoch 942/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0849\n",
      "Epoch 943/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0082 - val_loss: 0.0848\n",
      "Epoch 944/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0082 - val_loss: 0.0848\n",
      "Epoch 945/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0080 - val_loss: 0.0848\n",
      "Epoch 946/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0847\n",
      "Epoch 947/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0847\n",
      "Epoch 948/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0847\n",
      "Epoch 949/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0848\n",
      "Epoch 950/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0081 - val_loss: 0.0851\n",
      "Epoch 951/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0853\n",
      "Epoch 952/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0854\n",
      "Epoch 953/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0852\n",
      "Epoch 954/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0851\n",
      "Epoch 955/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0849\n",
      "Epoch 956/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0849\n",
      "Epoch 957/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0082 - val_loss: 0.0848\n",
      "Epoch 958/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0848\n",
      "Epoch 959/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0849\n",
      "Epoch 960/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0848\n",
      "Epoch 962/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0847\n",
      "Epoch 963/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0080 - val_loss: 0.0848\n",
      "Epoch 964/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0849\n",
      "Epoch 965/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0849\n",
      "Epoch 966/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0849\n",
      "Epoch 967/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0083 - val_loss: 0.0849\n",
      "Epoch 968/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0850\n",
      "Epoch 969/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0849\n",
      "Epoch 970/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0847\n",
      "Epoch 971/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0846\n",
      "Epoch 972/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0846\n",
      "Epoch 973/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0848\n",
      "Epoch 974/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0850\n",
      "Epoch 975/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0078 - val_loss: 0.0852\n",
      "Epoch 976/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0854\n",
      "Epoch 977/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0855\n",
      "Epoch 978/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0855\n",
      "Epoch 979/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0853\n",
      "Epoch 980/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0851\n",
      "Epoch 981/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0848\n",
      "Epoch 982/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0843\n",
      "Epoch 983/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0078 - val_loss: 0.0840\n",
      "Epoch 984/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0839\n",
      "Epoch 985/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0841\n",
      "Epoch 986/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0847\n",
      "Epoch 987/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0854\n",
      "Epoch 988/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0858\n",
      "Epoch 989/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0859\n",
      "Epoch 990/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0857\n",
      "Epoch 991/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0852\n",
      "Epoch 992/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0847\n",
      "Epoch 993/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0844\n",
      "Epoch 994/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0842\n",
      "Epoch 995/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0081 - val_loss: 0.0842\n",
      "Epoch 996/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0841\n",
      "Epoch 997/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0844\n",
      "Epoch 998/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0845\n",
      "Epoch 999/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0848\n",
      "Epoch 1000/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0080 - val_loss: 0.0850\n",
      "Durchlauf:  3\n",
      "positions calculated\n",
      "tcp calculated\n",
      "duplicates erased\n",
      "Train on 8998 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.1745 - val_loss: 0.2796\n",
      "Epoch 2/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.1436 - val_loss: 0.2237\n",
      "Epoch 3/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.1096 - val_loss: 0.1633\n",
      "Epoch 4/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0911 - val_loss: 0.1196\n",
      "Epoch 5/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0844 - val_loss: 0.1010\n",
      "Epoch 6/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0815 - val_loss: 0.0960\n",
      "Epoch 7/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0807 - val_loss: 0.0953\n",
      "Epoch 8/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0797 - val_loss: 0.0959\n",
      "Epoch 9/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0796 - val_loss: 0.0963\n",
      "Epoch 10/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0782 - val_loss: 0.0940\n",
      "Epoch 11/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0743 - val_loss: 0.0899\n",
      "Epoch 12/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0678 - val_loss: 0.0866\n",
      "Epoch 13/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0611 - val_loss: 0.0850\n",
      "Epoch 14/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0554 - val_loss: 0.0821\n",
      "Epoch 15/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0513 - val_loss: 0.0771\n",
      "Epoch 16/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0476 - val_loss: 0.0725\n",
      "Epoch 17/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0455 - val_loss: 0.0716\n",
      "Epoch 18/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0433 - val_loss: 0.0739\n",
      "Epoch 19/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0413 - val_loss: 0.0755\n",
      "Epoch 20/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0389 - val_loss: 0.0731\n",
      "Epoch 21/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0359 - val_loss: 0.0676\n",
      "Epoch 22/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0328 - val_loss: 0.0624\n",
      "Epoch 23/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0309 - val_loss: 0.0594\n",
      "Epoch 24/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0294 - val_loss: 0.0577\n",
      "Epoch 25/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0283 - val_loss: 0.0559\n",
      "Epoch 26/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0275 - val_loss: 0.0538\n",
      "Epoch 27/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0277 - val_loss: 0.0516\n",
      "Epoch 28/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0281 - val_loss: 0.0497\n",
      "Epoch 29/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0277 - val_loss: 0.0486\n",
      "Epoch 30/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0268 - val_loss: 0.0479\n",
      "Epoch 31/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0257 - val_loss: 0.0470\n",
      "Epoch 32/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0249 - val_loss: 0.0453\n",
      "Epoch 33/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0237 - val_loss: 0.0429\n",
      "Epoch 34/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0226 - val_loss: 0.0405\n",
      "Epoch 35/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0218 - val_loss: 0.0392\n",
      "Epoch 36/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0208 - val_loss: 0.0391\n",
      "Epoch 37/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0205 - val_loss: 0.0397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0202 - val_loss: 0.0400\n",
      "Epoch 39/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0201 - val_loss: 0.0399\n",
      "Epoch 40/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0199 - val_loss: 0.0395\n",
      "Epoch 41/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0200 - val_loss: 0.0388\n",
      "Epoch 42/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0199 - val_loss: 0.0379\n",
      "Epoch 43/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0192 - val_loss: 0.0368\n",
      "Epoch 44/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0186 - val_loss: 0.0357\n",
      "Epoch 45/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0185 - val_loss: 0.0347\n",
      "Epoch 46/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0180 - val_loss: 0.0339\n",
      "Epoch 47/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0176 - val_loss: 0.0335\n",
      "Epoch 48/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0174 - val_loss: 0.0334\n",
      "Epoch 49/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0174 - val_loss: 0.0334\n",
      "Epoch 50/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0170 - val_loss: 0.0334\n",
      "Epoch 51/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0169 - val_loss: 0.0334\n",
      "Epoch 52/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0166 - val_loss: 0.0335\n",
      "Epoch 53/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0165 - val_loss: 0.0339\n",
      "Epoch 54/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0164 - val_loss: 0.0344\n",
      "Epoch 55/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0159 - val_loss: 0.0349\n",
      "Epoch 56/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0160 - val_loss: 0.0350\n",
      "Epoch 57/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0158 - val_loss: 0.0350\n",
      "Epoch 58/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0155 - val_loss: 0.0347\n",
      "Epoch 59/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0342\n",
      "Epoch 60/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0154 - val_loss: 0.0339\n",
      "Epoch 61/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0152 - val_loss: 0.0337\n",
      "Epoch 62/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0148 - val_loss: 0.0335\n",
      "Epoch 63/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0147 - val_loss: 0.0331\n",
      "Epoch 64/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0148 - val_loss: 0.0327\n",
      "Epoch 65/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0144 - val_loss: 0.0323\n",
      "Epoch 66/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0146 - val_loss: 0.0319\n",
      "Epoch 67/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0144 - val_loss: 0.0316\n",
      "Epoch 68/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0143 - val_loss: 0.0314\n",
      "Epoch 69/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0142 - val_loss: 0.0313\n",
      "Epoch 70/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0312\n",
      "Epoch 71/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0313\n",
      "Epoch 72/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0315\n",
      "Epoch 73/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0317\n",
      "Epoch 74/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0318\n",
      "Epoch 75/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 0.0317\n",
      "Epoch 76/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0316\n",
      "Epoch 77/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0135 - val_loss: 0.0315\n",
      "Epoch 78/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0314\n",
      "Epoch 79/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0315\n",
      "Epoch 80/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0316\n",
      "Epoch 81/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0316\n",
      "Epoch 82/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0312\n",
      "Epoch 83/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0309\n",
      "Epoch 84/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0306\n",
      "Epoch 85/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0304\n",
      "Epoch 86/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0128 - val_loss: 0.0304\n",
      "Epoch 87/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0128 - val_loss: 0.0304\n",
      "Epoch 88/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0304\n",
      "Epoch 89/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0127 - val_loss: 0.0304\n",
      "Epoch 90/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0304\n",
      "Epoch 91/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0127 - val_loss: 0.0302\n",
      "Epoch 92/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0300\n",
      "Epoch 93/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0124 - val_loss: 0.0298\n",
      "Epoch 94/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0297\n",
      "Epoch 95/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0297\n",
      "Epoch 96/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0297\n",
      "Epoch 97/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0297\n",
      "Epoch 98/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0120 - val_loss: 0.0298\n",
      "Epoch 99/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0297\n",
      "Epoch 100/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0118 - val_loss: 0.0296\n",
      "Epoch 101/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0294\n",
      "Epoch 102/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0292\n",
      "Epoch 103/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0292\n",
      "Epoch 104/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0291\n",
      "Epoch 105/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0289\n",
      "Epoch 106/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 0.0288\n",
      "Epoch 107/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0117 - val_loss: 0.0287\n",
      "Epoch 108/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0286\n",
      "Epoch 109/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0287\n",
      "Epoch 110/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0116 - val_loss: 0.0287\n",
      "Epoch 111/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0114 - val_loss: 0.0286\n",
      "Epoch 112/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0113 - val_loss: 0.0284\n",
      "Epoch 113/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0114 - val_loss: 0.0283\n",
      "Epoch 114/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0112 - val_loss: 0.0282\n",
      "Epoch 115/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0113 - val_loss: 0.0281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0112 - val_loss: 0.0280\n",
      "Epoch 117/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0279\n",
      "Epoch 118/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 0.0279\n",
      "Epoch 119/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0279\n",
      "Epoch 120/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0279\n",
      "Epoch 121/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 0.0279\n",
      "Epoch 122/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0277\n",
      "Epoch 123/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0275\n",
      "Epoch 124/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0108 - val_loss: 0.0274\n",
      "Epoch 125/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0110 - val_loss: 0.0274\n",
      "Epoch 126/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0109 - val_loss: 0.0274\n",
      "Epoch 127/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0275\n",
      "Epoch 128/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0275\n",
      "Epoch 129/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 0.0274\n",
      "Epoch 130/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0271\n",
      "Epoch 131/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0270\n",
      "Epoch 132/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0271\n",
      "Epoch 133/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0272\n",
      "Epoch 134/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0272\n",
      "Epoch 135/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 0.0272\n",
      "Epoch 136/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 0.0272\n",
      "Epoch 137/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0106 - val_loss: 0.0272\n",
      "Epoch 138/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0104 - val_loss: 0.0271\n",
      "Epoch 139/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0103 - val_loss: 0.0271\n",
      "Epoch 140/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0271\n",
      "Epoch 141/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0270\n",
      "Epoch 142/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0101 - val_loss: 0.0269\n",
      "Epoch 143/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0270\n",
      "Epoch 144/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0101 - val_loss: 0.0271\n",
      "Epoch 145/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0101 - val_loss: 0.0271\n",
      "Epoch 146/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0270\n",
      "Epoch 147/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0268\n",
      "Epoch 148/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0267\n",
      "Epoch 149/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 0.0267\n",
      "Epoch 150/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0267\n",
      "Epoch 151/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0100 - val_loss: 0.0267\n",
      "Epoch 152/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 0.0267\n",
      "Epoch 153/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0266\n",
      "Epoch 154/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0264\n",
      "Epoch 155/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0263\n",
      "Epoch 156/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0263\n",
      "Epoch 157/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0099 - val_loss: 0.0264\n",
      "Epoch 158/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0265\n",
      "Epoch 159/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0098 - val_loss: 0.0264\n",
      "Epoch 160/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0263\n",
      "Epoch 161/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0262\n",
      "Epoch 162/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0262\n",
      "Epoch 163/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0263\n",
      "Epoch 164/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0263\n",
      "Epoch 165/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0097 - val_loss: 0.0263\n",
      "Epoch 166/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0097 - val_loss: 0.0262\n",
      "Epoch 167/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0096 - val_loss: 0.0263\n",
      "Epoch 168/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0096 - val_loss: 0.0263\n",
      "Epoch 169/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0264\n",
      "Epoch 170/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0095 - val_loss: 0.0262\n",
      "Epoch 171/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 0.0260\n",
      "Epoch 172/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0259\n",
      "Epoch 173/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 0.0258\n",
      "Epoch 174/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0093 - val_loss: 0.0260\n",
      "Epoch 175/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0094 - val_loss: 0.0262\n",
      "Epoch 176/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0263\n",
      "Epoch 177/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0263\n",
      "Epoch 178/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0262\n",
      "Epoch 179/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0093 - val_loss: 0.0261\n",
      "Epoch 180/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0261\n",
      "Epoch 181/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0260\n",
      "Epoch 182/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0092 - val_loss: 0.0259\n",
      "Epoch 183/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0260\n",
      "Epoch 184/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0260\n",
      "Epoch 185/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 0.0260\n",
      "Epoch 186/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0260\n",
      "Epoch 187/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0257\n",
      "Epoch 188/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0256\n",
      "Epoch 189/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0255\n",
      "Epoch 190/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 0.0256\n",
      "Epoch 191/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0256\n",
      "Epoch 192/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0257\n",
      "Epoch 193/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0256\n",
      "Epoch 195/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0256\n",
      "Epoch 196/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0256\n",
      "Epoch 197/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0256\n",
      "Epoch 198/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0090 - val_loss: 0.0256\n",
      "Epoch 199/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0089 - val_loss: 0.0256\n",
      "Epoch 200/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 0.0255\n",
      "Epoch 201/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0089 - val_loss: 0.0255\n",
      "Epoch 202/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0088 - val_loss: 0.0255\n",
      "Epoch 203/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0254\n",
      "Epoch 204/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0253\n",
      "Epoch 205/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0251\n",
      "Epoch 206/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0251\n",
      "Epoch 207/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0251\n",
      "Epoch 208/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0252\n",
      "Epoch 209/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 0.0252\n",
      "Epoch 210/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 0.0251\n",
      "Epoch 211/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0250\n",
      "Epoch 212/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0086 - val_loss: 0.0250\n",
      "Epoch 213/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0250\n",
      "Epoch 214/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0251\n",
      "Epoch 215/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0252\n",
      "Epoch 216/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 0.0252\n",
      "Epoch 217/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0252\n",
      "Epoch 218/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0086 - val_loss: 0.0252\n",
      "Epoch 219/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0085 - val_loss: 0.0252\n",
      "Epoch 220/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0251\n",
      "Epoch 221/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0085 - val_loss: 0.0248\n",
      "Epoch 222/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0084 - val_loss: 0.0247\n",
      "Epoch 223/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0084 - val_loss: 0.0248\n",
      "Epoch 224/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0084 - val_loss: 0.0249\n",
      "Epoch 225/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0086 - val_loss: 0.0250\n",
      "Epoch 226/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0084 - val_loss: 0.0250\n",
      "Epoch 227/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0084 - val_loss: 0.0247\n",
      "Epoch 228/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0083 - val_loss: 0.0245\n",
      "Epoch 229/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0083 - val_loss: 0.0244\n",
      "Epoch 230/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0084 - val_loss: 0.0245\n",
      "Epoch 231/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0247\n",
      "Epoch 232/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0082 - val_loss: 0.0248\n",
      "Epoch 233/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0082 - val_loss: 0.0247\n",
      "Epoch 234/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0246\n",
      "Epoch 235/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0246\n",
      "Epoch 236/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0246\n",
      "Epoch 237/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0247\n",
      "Epoch 238/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0247\n",
      "Epoch 239/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0081 - val_loss: 0.0245\n",
      "Epoch 240/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0081 - val_loss: 0.0244\n",
      "Epoch 241/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0081 - val_loss: 0.0244\n",
      "Epoch 242/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0082 - val_loss: 0.0245\n",
      "Epoch 243/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0245\n",
      "Epoch 244/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0082 - val_loss: 0.0245\n",
      "Epoch 245/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0245\n",
      "Epoch 246/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 0.0245\n",
      "Epoch 247/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0246\n",
      "Epoch 248/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 0.0246\n",
      "Epoch 249/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0247\n",
      "Epoch 250/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0246\n",
      "Epoch 251/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0080 - val_loss: 0.0244\n",
      "Epoch 252/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0243\n",
      "Epoch 253/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0079 - val_loss: 0.0242\n",
      "Epoch 254/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0242\n",
      "Epoch 255/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0243\n",
      "Epoch 256/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0244\n",
      "Epoch 257/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0080 - val_loss: 0.0244\n",
      "Epoch 258/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0079 - val_loss: 0.0244\n",
      "Epoch 259/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0080 - val_loss: 0.0242\n",
      "Epoch 260/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0241\n",
      "Epoch 261/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0078 - val_loss: 0.0240\n",
      "Epoch 262/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0078 - val_loss: 0.0240\n",
      "Epoch 263/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0079 - val_loss: 0.0241\n",
      "Epoch 264/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0241\n",
      "Epoch 265/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0078 - val_loss: 0.0242\n",
      "Epoch 266/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0078 - val_loss: 0.0241\n",
      "Epoch 267/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0079 - val_loss: 0.0241\n",
      "Epoch 268/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0077 - val_loss: 0.0242\n",
      "Epoch 269/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0241\n",
      "Epoch 270/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0241\n",
      "Epoch 271/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0077 - val_loss: 0.0240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 0.0239\n",
      "Epoch 273/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0077 - val_loss: 0.0240\n",
      "Epoch 274/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0077 - val_loss: 0.0241\n",
      "Epoch 275/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0242\n",
      "Epoch 276/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0241\n",
      "Epoch 277/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0077 - val_loss: 0.0240\n",
      "Epoch 278/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0076 - val_loss: 0.0238\n",
      "Epoch 279/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0077 - val_loss: 0.0237\n",
      "Epoch 280/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0076 - val_loss: 0.0238\n",
      "Epoch 281/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0077 - val_loss: 0.0240\n",
      "Epoch 282/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0077 - val_loss: 0.0241\n",
      "Epoch 283/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0075 - val_loss: 0.0240\n",
      "Epoch 284/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0076 - val_loss: 0.0238\n",
      "Epoch 285/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0077 - val_loss: 0.0237\n",
      "Epoch 286/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0077 - val_loss: 0.0238\n",
      "Epoch 287/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0075 - val_loss: 0.0238\n",
      "Epoch 288/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0075 - val_loss: 0.0239\n",
      "Epoch 289/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0075 - val_loss: 0.0238\n",
      "Epoch 290/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0075 - val_loss: 0.0238\n",
      "Epoch 291/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0077 - val_loss: 0.0238\n",
      "Epoch 292/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0076 - val_loss: 0.0238\n",
      "Epoch 293/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0075 - val_loss: 0.0238\n",
      "Epoch 294/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0075 - val_loss: 0.0238\n",
      "Epoch 295/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 0.0237\n",
      "Epoch 296/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0075 - val_loss: 0.0236\n",
      "Epoch 297/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0074 - val_loss: 0.0235\n",
      "Epoch 298/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 0.0235\n",
      "Epoch 299/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0075 - val_loss: 0.0236\n",
      "Epoch 300/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 0.0236\n",
      "Epoch 301/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0075 - val_loss: 0.0236\n",
      "Epoch 302/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0074 - val_loss: 0.0235\n",
      "Epoch 303/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0072 - val_loss: 0.0236\n",
      "Epoch 304/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 0.0237\n",
      "Epoch 305/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0075 - val_loss: 0.0237\n",
      "Epoch 306/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 0.0237\n",
      "Epoch 307/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 0.0236\n",
      "Epoch 308/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 0.0235\n",
      "Epoch 309/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0073 - val_loss: 0.0235\n",
      "Epoch 310/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 0.0235\n",
      "Epoch 311/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0074 - val_loss: 0.0235\n",
      "Epoch 312/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0235\n",
      "Epoch 313/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0236\n",
      "Epoch 314/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0235\n",
      "Epoch 315/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0073 - val_loss: 0.0235\n",
      "Epoch 316/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0073 - val_loss: 0.0234\n",
      "Epoch 317/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0233\n",
      "Epoch 318/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0232\n",
      "Epoch 319/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0073 - val_loss: 0.0231\n",
      "Epoch 320/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0073 - val_loss: 0.0230\n",
      "Epoch 321/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0072 - val_loss: 0.0231\n",
      "Epoch 322/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0073 - val_loss: 0.0232\n",
      "Epoch 323/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0073 - val_loss: 0.0233\n",
      "Epoch 324/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0233\n",
      "Epoch 325/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0073 - val_loss: 0.0233\n",
      "Epoch 326/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0073 - val_loss: 0.0232\n",
      "Epoch 327/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0231\n",
      "Epoch 328/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0073 - val_loss: 0.0232\n",
      "Epoch 329/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0233\n",
      "Epoch 330/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0233\n",
      "Epoch 331/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0233\n",
      "Epoch 332/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0233\n",
      "Epoch 333/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0072 - val_loss: 0.0233\n",
      "Epoch 334/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0232\n",
      "Epoch 335/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0072 - val_loss: 0.0231\n",
      "Epoch 336/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0071 - val_loss: 0.0231\n",
      "Epoch 337/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0231\n",
      "Epoch 338/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0231\n",
      "Epoch 339/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0231\n",
      "Epoch 340/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0232\n",
      "Epoch 341/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0233\n",
      "Epoch 342/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0071 - val_loss: 0.0233\n",
      "Epoch 343/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0233\n",
      "Epoch 344/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0232\n",
      "Epoch 345/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0231\n",
      "Epoch 346/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0230\n",
      "Epoch 347/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0230\n",
      "Epoch 348/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0231\n",
      "Epoch 349/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0070 - val_loss: 0.0232\n",
      "Epoch 351/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0231\n",
      "Epoch 352/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0229\n",
      "Epoch 353/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0069 - val_loss: 0.0228\n",
      "Epoch 354/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0071 - val_loss: 0.0228\n",
      "Epoch 355/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0229\n",
      "Epoch 356/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0230\n",
      "Epoch 357/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0070 - val_loss: 0.0231\n",
      "Epoch 358/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0230\n",
      "Epoch 359/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0069 - val_loss: 0.0228\n",
      "Epoch 360/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0227\n",
      "Epoch 361/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0228\n",
      "Epoch 362/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0228\n",
      "Epoch 363/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0228\n",
      "Epoch 364/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0228\n",
      "Epoch 365/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0228\n",
      "Epoch 366/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0228\n",
      "Epoch 367/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0070 - val_loss: 0.0229\n",
      "Epoch 368/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0229\n",
      "Epoch 369/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0229\n",
      "Epoch 370/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0228\n",
      "Epoch 371/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0227\n",
      "Epoch 372/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0228\n",
      "Epoch 373/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0228\n",
      "Epoch 374/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0227\n",
      "Epoch 375/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0226\n",
      "Epoch 376/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0069 - val_loss: 0.0226\n",
      "Epoch 377/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0227\n",
      "Epoch 378/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0228\n",
      "Epoch 379/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0229\n",
      "Epoch 380/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0067 - val_loss: 0.0228\n",
      "Epoch 381/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0228\n",
      "Epoch 382/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0068 - val_loss: 0.0228\n",
      "Epoch 383/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0067 - val_loss: 0.0228\n",
      "Epoch 384/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0068 - val_loss: 0.0228\n",
      "Epoch 385/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0227\n",
      "Epoch 386/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0067 - val_loss: 0.0227\n",
      "Epoch 387/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0227\n",
      "Epoch 388/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0068 - val_loss: 0.0227\n",
      "Epoch 389/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0227\n",
      "Epoch 390/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0227\n",
      "Epoch 391/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0227\n",
      "Epoch 392/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0226\n",
      "Epoch 393/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0067 - val_loss: 0.0226\n",
      "Epoch 394/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0067 - val_loss: 0.0226\n",
      "Epoch 395/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0067 - val_loss: 0.0226\n",
      "Epoch 396/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0068 - val_loss: 0.0226\n",
      "Epoch 397/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0227\n",
      "Epoch 398/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0228\n",
      "Epoch 399/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0228\n",
      "Epoch 400/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0067 - val_loss: 0.0227\n",
      "Epoch 401/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0067 - val_loss: 0.0227\n",
      "Epoch 402/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0226\n",
      "Epoch 403/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0226\n",
      "Epoch 404/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0225\n",
      "Epoch 405/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0225\n",
      "Epoch 406/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0066 - val_loss: 0.0225\n",
      "Epoch 407/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0066 - val_loss: 0.0225\n",
      "Epoch 408/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0225\n",
      "Epoch 409/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0065 - val_loss: 0.0226\n",
      "Epoch 410/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0066 - val_loss: 0.0227\n",
      "Epoch 411/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0066 - val_loss: 0.0226\n",
      "Epoch 412/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0224\n",
      "Epoch 413/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0223\n",
      "Epoch 414/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0224\n",
      "Epoch 415/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0225\n",
      "Epoch 416/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0227\n",
      "Epoch 417/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0226\n",
      "Epoch 418/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0226\n",
      "Epoch 419/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0226\n",
      "Epoch 420/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0065 - val_loss: 0.0225\n",
      "Epoch 421/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0065 - val_loss: 0.0225\n",
      "Epoch 422/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0225\n",
      "Epoch 423/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0224\n",
      "Epoch 424/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0066 - val_loss: 0.0224\n",
      "Epoch 425/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0224\n",
      "Epoch 426/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0065 - val_loss: 0.0224\n",
      "Epoch 427/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 0.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0066 - val_loss: 0.0224\n",
      "Epoch 429/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0223\n",
      "Epoch 430/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0223\n",
      "Epoch 431/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0223\n",
      "Epoch 432/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0224\n",
      "Epoch 433/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0224\n",
      "Epoch 434/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0223\n",
      "Epoch 435/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0222\n",
      "Epoch 436/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 437/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0065 - val_loss: 0.0224\n",
      "Epoch 438/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 0.0225\n",
      "Epoch 439/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 0.0225\n",
      "Epoch 440/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0224\n",
      "Epoch 441/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0224\n",
      "Epoch 442/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0065 - val_loss: 0.0223\n",
      "Epoch 443/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 444/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0224\n",
      "Epoch 445/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0224\n",
      "Epoch 446/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0224\n",
      "Epoch 447/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0224\n",
      "Epoch 448/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0223\n",
      "Epoch 449/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0224\n",
      "Epoch 450/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0223\n",
      "Epoch 451/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 452/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0064 - val_loss: 0.0221\n",
      "Epoch 453/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0221\n",
      "Epoch 454/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0221\n",
      "Epoch 455/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 456/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 0.0223\n",
      "Epoch 457/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 458/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 459/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0221\n",
      "Epoch 460/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0220\n",
      "Epoch 461/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0220\n",
      "Epoch 462/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0222\n",
      "Epoch 463/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 0.0222\n",
      "Epoch 464/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0221\n",
      "Epoch 465/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0221\n",
      "Epoch 466/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 467/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0222\n",
      "Epoch 468/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 0.0222\n",
      "Epoch 469/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0220\n",
      "Epoch 470/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 0.0220\n",
      "Epoch 471/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 0.0220\n",
      "Epoch 472/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0220\n",
      "Epoch 473/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0220\n",
      "Epoch 474/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 0.0221\n",
      "Epoch 475/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0220\n",
      "Epoch 476/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0220\n",
      "Epoch 477/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0063 - val_loss: 0.0219\n",
      "Epoch 478/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0219\n",
      "Epoch 479/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 0.0220\n",
      "Epoch 480/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 0.0221\n",
      "Epoch 481/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 0.0220\n",
      "Epoch 482/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0063 - val_loss: 0.0219\n",
      "Epoch 483/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0219\n",
      "Epoch 484/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 0.0220\n",
      "Epoch 485/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 0.0220\n",
      "Epoch 486/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 487/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 0.0220\n",
      "Epoch 488/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0220\n",
      "Epoch 489/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 0.0220\n",
      "Epoch 490/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0220\n",
      "Epoch 491/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0220\n",
      "Epoch 492/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 493/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 0.0219\n",
      "Epoch 494/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 495/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 0.0219\n",
      "Epoch 496/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 497/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 498/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 499/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 500/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 501/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 502/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 0.0219\n",
      "Epoch 503/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0060 - val_loss: 0.0219\n",
      "Epoch 504/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0219\n",
      "Epoch 505/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0062 - val_loss: 0.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0218\n",
      "Epoch 507/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0218\n",
      "Epoch 508/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 509/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 510/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0061 - val_loss: 0.0218\n",
      "Epoch 511/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 512/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0059 - val_loss: 0.0217\n",
      "Epoch 513/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 514/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 0.0217\n",
      "Epoch 515/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 516/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 0.0217\n",
      "Epoch 517/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0219\n",
      "Epoch 518/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0060 - val_loss: 0.0219\n",
      "Epoch 519/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0218\n",
      "Epoch 520/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0059 - val_loss: 0.0217\n",
      "Epoch 521/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0059 - val_loss: 0.0216\n",
      "Epoch 522/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 523/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0216\n",
      "Epoch 524/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0059 - val_loss: 0.0215\n",
      "Epoch 525/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0215\n",
      "Epoch 526/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0215\n",
      "Epoch 527/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 528/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0218\n",
      "Epoch 529/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0059 - val_loss: 0.0218\n",
      "Epoch 530/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0218\n",
      "Epoch 531/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 532/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0216\n",
      "Epoch 533/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0060 - val_loss: 0.0216\n",
      "Epoch 534/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0059 - val_loss: 0.0216\n",
      "Epoch 535/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0059 - val_loss: 0.0217\n",
      "Epoch 536/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0059 - val_loss: 0.0217\n",
      "Epoch 537/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0217\n",
      "Epoch 538/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0059 - val_loss: 0.0216\n",
      "Epoch 539/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0060 - val_loss: 0.0216\n",
      "Epoch 540/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0059 - val_loss: 0.0215\n",
      "Epoch 541/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0058 - val_loss: 0.0215\n",
      "Epoch 542/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0216\n",
      "Epoch 543/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0060 - val_loss: 0.0215\n",
      "Epoch 544/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0059 - val_loss: 0.0215\n",
      "Epoch 545/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0059 - val_loss: 0.0215\n",
      "Epoch 546/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0059 - val_loss: 0.0215\n",
      "Epoch 547/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0215\n",
      "Epoch 548/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0215\n",
      "Epoch 549/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0059 - val_loss: 0.0216\n",
      "Epoch 550/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0058 - val_loss: 0.0216\n",
      "Epoch 551/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0059 - val_loss: 0.0216\n",
      "Epoch 552/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0058 - val_loss: 0.0216\n",
      "Epoch 553/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0215\n",
      "Epoch 554/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 555/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0058 - val_loss: 0.0213\n",
      "Epoch 556/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0060 - val_loss: 0.0213\n",
      "Epoch 557/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 558/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0059 - val_loss: 0.0215\n",
      "Epoch 559/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0059 - val_loss: 0.0217\n",
      "Epoch 560/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0059 - val_loss: 0.0216\n",
      "Epoch 561/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0059 - val_loss: 0.0215\n",
      "Epoch 562/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 563/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0058 - val_loss: 0.0213\n",
      "Epoch 564/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0059 - val_loss: 0.0213\n",
      "Epoch 565/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0059 - val_loss: 0.0213\n",
      "Epoch 566/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 567/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 568/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 569/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0215\n",
      "Epoch 570/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0214\n",
      "Epoch 571/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0213\n",
      "Epoch 572/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0213\n",
      "Epoch 573/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0213\n",
      "Epoch 574/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0214\n",
      "Epoch 575/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0214\n",
      "Epoch 576/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 577/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0059 - val_loss: 0.0215\n",
      "Epoch 578/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0214\n",
      "Epoch 579/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0213\n",
      "Epoch 580/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 581/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 582/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0214\n",
      "Epoch 583/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 584/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0213\n",
      "Epoch 585/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0212\n",
      "Epoch 586/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0212\n",
      "Epoch 587/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0212\n",
      "Epoch 588/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 589/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 590/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 591/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 592/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 593/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0214\n",
      "Epoch 594/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0213\n",
      "Epoch 595/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0214\n",
      "Epoch 596/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0214\n",
      "Epoch 597/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 0.0214\n",
      "Epoch 598/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 599/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 600/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0212\n",
      "Epoch 601/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 0.0212\n",
      "Epoch 602/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 603/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0214\n",
      "Epoch 604/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0215\n",
      "Epoch 605/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0214\n",
      "Epoch 606/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0212\n",
      "Epoch 607/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0212\n",
      "Epoch 608/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0212\n",
      "Epoch 609/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 0.0212\n",
      "Epoch 610/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 611/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0213\n",
      "Epoch 612/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 613/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0212\n",
      "Epoch 614/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 615/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 616/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0211\n",
      "Epoch 617/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0210\n",
      "Epoch 618/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0210\n",
      "Epoch 619/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0209\n",
      "Epoch 620/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0209\n",
      "Epoch 621/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0210\n",
      "Epoch 622/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0057 - val_loss: 0.0211\n",
      "Epoch 623/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0213\n",
      "Epoch 624/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 0.0215\n",
      "Epoch 625/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0215\n",
      "Epoch 626/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0214\n",
      "Epoch 627/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 628/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0211\n",
      "Epoch 629/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0211\n",
      "Epoch 630/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0210\n",
      "Epoch 631/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0209\n",
      "Epoch 632/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 633/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0212\n",
      "Epoch 634/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0213\n",
      "Epoch 635/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0214\n",
      "Epoch 636/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0213\n",
      "Epoch 637/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 638/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0211\n",
      "Epoch 639/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 640/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 641/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 642/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0056 - val_loss: 0.0212\n",
      "Epoch 643/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0211\n",
      "Epoch 644/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 645/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 646/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0213\n",
      "Epoch 647/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0212\n",
      "Epoch 648/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 649/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0210\n",
      "Epoch 650/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0210\n",
      "Epoch 651/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0210\n",
      "Epoch 652/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 0.0211\n",
      "Epoch 653/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 654/1000\n",
      "8998/8998 [==============================] - 0s 7us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 655/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 656/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 657/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0209\n",
      "Epoch 658/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0210\n",
      "Epoch 659/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 660/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0210\n",
      "Epoch 661/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 662/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0208\n",
      "Epoch 663/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 664/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 665/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0055 - val_loss: 0.0210\n",
      "Epoch 666/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0211\n",
      "Epoch 667/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0211\n",
      "Epoch 668/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0054 - val_loss: 0.0211\n",
      "Epoch 669/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 670/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 671/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 672/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0210\n",
      "Epoch 673/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 674/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 675/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0054 - val_loss: 0.0211\n",
      "Epoch 676/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0211\n",
      "Epoch 677/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 678/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 0.0208\n",
      "Epoch 679/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 680/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 681/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 682/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0211\n",
      "Epoch 683/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0211\n",
      "Epoch 684/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0210\n",
      "Epoch 685/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 686/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 687/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 688/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 689/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 690/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 691/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 692/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 693/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 694/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0209\n",
      "Epoch 695/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0209\n",
      "Epoch 696/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 0.0209\n",
      "Epoch 697/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 0.0209\n",
      "Epoch 698/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0209\n",
      "Epoch 699/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0209\n",
      "Epoch 700/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 701/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 702/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 703/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 704/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 705/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0207\n",
      "Epoch 706/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 0.0206\n",
      "Epoch 707/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0206\n",
      "Epoch 708/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 709/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 710/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 711/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 712/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0209\n",
      "Epoch 713/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0210\n",
      "Epoch 714/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0210\n",
      "Epoch 715/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0209\n",
      "Epoch 716/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 717/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 718/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0207\n",
      "Epoch 719/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0052 - val_loss: 0.0207\n",
      "Epoch 720/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 721/1000\n",
      "8998/8998 [==============================] - 0s 10us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 722/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 0.0206\n",
      "Epoch 723/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 724/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 725/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 726/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0208\n",
      "Epoch 727/1000\n",
      "8998/8998 [==============================] - 0s 9us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 728/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0207\n",
      "Epoch 729/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0206\n",
      "Epoch 730/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0206\n",
      "Epoch 731/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0206\n",
      "Epoch 732/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0207\n",
      "Epoch 733/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0208\n",
      "Epoch 734/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 735/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0208\n",
      "Epoch 736/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0207\n",
      "Epoch 737/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0206\n",
      "Epoch 738/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0206\n",
      "Epoch 739/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 0.0206\n",
      "Epoch 741/1000\n",
      "8998/8998 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 0.0206\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-94d441372ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Durchlauf: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mjpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import Generator\n",
    "\n",
    "# generator = Generator()\n",
    "# model.fit(tpos, jpos, epochs=300, batch_size=90000, validation_split=0.1)\n",
    "for i in range(10):\n",
    "    print(\"Durchlauf: \",i)\n",
    "    jpos, tpos = gen(10000)\n",
    "    model.fit(tpos, jpos, epochs=1000, batch_size=10000, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 30ms/step - loss: 0.1903 - val_loss: 0.1109\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.2188 - val_loss: 0.2961\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.2323 - val_loss: 0.1918\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.2096 - val_loss: 0.1639\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1960 - val_loss: 0.1656\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1840 - val_loss: 0.1031\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1756 - val_loss: 0.1679\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1796 - val_loss: 0.2147\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1774 - val_loss: 0.1569\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1651 - val_loss: 0.1514\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1607 - val_loss: 0.0956\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1637 - val_loss: 0.1672\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1539 - val_loss: 0.1272\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1568 - val_loss: 0.0726\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1704 - val_loss: 0.1904\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1505 - val_loss: 0.2541\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1630 - val_loss: 0.1616\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1707 - val_loss: 0.1905\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1821 - val_loss: 0.1260\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1567 - val_loss: 0.1323\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1689 - val_loss: 0.1685\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1678 - val_loss: 0.2501\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1730 - val_loss: 0.1566\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1682 - val_loss: 0.0967\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.1468 - val_loss: 0.1272\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1824 - val_loss: 0.0553\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1832 - val_loss: 0.1399\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1854 - val_loss: 0.1873\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1871 - val_loss: 0.1646\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1765 - val_loss: 0.1919\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1625 - val_loss: 0.1832\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1582 - val_loss: 0.1841\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1639 - val_loss: 0.2131\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1705 - val_loss: 0.1363\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.1662 - val_loss: 0.2123\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.1653 - val_loss: 0.1847\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1615 - val_loss: 0.1397\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1628 - val_loss: 0.1069\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1659 - val_loss: 0.1013\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1833 - val_loss: 0.2314\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1644 - val_loss: 0.1233\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1699 - val_loss: 0.1422\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1686 - val_loss: 0.2780\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1575 - val_loss: 0.1283\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1647 - val_loss: 0.2789\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1488 - val_loss: 0.1069\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1643 - val_loss: 0.1199\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1614 - val_loss: 0.1633\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1521 - val_loss: 0.1743\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1544 - val_loss: 0.1751\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.1669 - val_loss: 0.1861\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1600 - val_loss: 0.1716\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1687 - val_loss: 0.1231\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1602 - val_loss: 0.1457\n",
      "Epoch 55/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1487 - val_loss: 0.1541\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1597 - val_loss: 0.1237\n",
      "Epoch 57/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1818 - val_loss: 0.2055\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1678 - val_loss: 0.1353\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1675 - val_loss: 0.2051\n",
      "Epoch 60/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1589 - val_loss: 0.1067\n",
      "Epoch 61/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1540 - val_loss: 0.1071\n",
      "Epoch 62/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1527 - val_loss: 0.1310\n",
      "Epoch 63/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1614 - val_loss: 0.1662\n",
      "Epoch 64/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1661 - val_loss: 0.1625\n",
      "Epoch 65/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1601 - val_loss: 0.2179\n",
      "Epoch 66/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1664 - val_loss: 0.2081\n",
      "Epoch 67/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1671 - val_loss: 0.1937\n",
      "Epoch 68/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1633 - val_loss: 0.1720\n",
      "Epoch 69/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1683 - val_loss: 0.1746\n",
      "Epoch 70/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1815 - val_loss: 0.1098\n",
      "Epoch 71/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1673 - val_loss: 0.1991\n",
      "Epoch 72/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1660 - val_loss: 0.1764\n",
      "Epoch 73/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1617 - val_loss: 0.0987\n",
      "Epoch 74/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1543 - val_loss: 0.1389\n",
      "Epoch 75/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1638 - val_loss: 0.1586\n",
      "Epoch 76/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1762 - val_loss: 0.1864\n",
      "Epoch 77/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1779 - val_loss: 0.1226\n",
      "Epoch 78/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1656 - val_loss: 0.0837\n",
      "Epoch 79/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1744 - val_loss: 0.1346\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1833 - val_loss: 0.1396\n",
      "Epoch 81/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1548 - val_loss: 0.1803\n",
      "Epoch 82/200\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.1652 - val_loss: 0.1211\n",
      "Epoch 83/200\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1645 - val_loss: 0.1531\n",
      "Epoch 84/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1568 - val_loss: 0.2237\n",
      "Epoch 85/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1607 - val_loss: 0.1348\n",
      "Epoch 86/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1761 - val_loss: 0.1607\n",
      "Epoch 87/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1884 - val_loss: 0.1462\n",
      "Epoch 88/200\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1842 - val_loss: 0.1164\n",
      "Epoch 89/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1750 - val_loss: 0.2709\n",
      "Epoch 90/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1766 - val_loss: 0.1335\n",
      "Epoch 91/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1636 - val_loss: 0.2213\n",
      "Epoch 92/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1637 - val_loss: 0.0886\n",
      "Epoch 93/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1596 - val_loss: 0.1771\n",
      "Epoch 94/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1519 - val_loss: 0.1339\n",
      "Epoch 95/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1606 - val_loss: 0.1734\n",
      "Epoch 96/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1631 - val_loss: 0.1819\n",
      "Epoch 97/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1628 - val_loss: 0.1217\n",
      "Epoch 98/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1568 - val_loss: 0.1325\n",
      "Epoch 99/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1555 - val_loss: 0.2741\n",
      "Epoch 100/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1456 - val_loss: 0.1316\n",
      "Epoch 101/200\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.1663 - val_loss: 0.2330\n",
      "Epoch 102/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1639 - val_loss: 0.1022\n",
      "Epoch 103/200\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1540 - val_loss: 0.1668\n",
      "Epoch 104/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1564 - val_loss: 0.1728\n",
      "Epoch 105/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1675 - val_loss: 0.1516\n",
      "Epoch 106/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1745 - val_loss: 0.2088\n",
      "Epoch 107/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1634 - val_loss: 0.1677\n",
      "Epoch 108/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1659 - val_loss: 0.2519\n",
      "Epoch 109/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1678 - val_loss: 0.0806\n",
      "Epoch 110/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1598 - val_loss: 0.1766\n",
      "Epoch 111/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1644 - val_loss: 0.1849\n",
      "Epoch 112/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1630 - val_loss: 0.0912\n",
      "Epoch 113/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1659 - val_loss: 0.0763\n",
      "Epoch 114/200\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.1710 - val_loss: 0.1606\n",
      "Epoch 115/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1626 - val_loss: 0.1197\n",
      "Epoch 116/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1554 - val_loss: 0.1332\n",
      "Epoch 117/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1607 - val_loss: 0.2661\n",
      "Epoch 118/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1659 - val_loss: 0.2853\n",
      "Epoch 119/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1621 - val_loss: 0.1266\n",
      "Epoch 120/200\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1512 - val_loss: 0.1316\n",
      "Epoch 121/200\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1589 - val_loss: 0.2509\n",
      "Epoch 122/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1710 - val_loss: 0.1251\n",
      "Epoch 123/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1660 - val_loss: 0.2168\n",
      "Epoch 124/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1664 - val_loss: 0.2014\n",
      "Epoch 125/200\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1633 - val_loss: 0.1413\n",
      "Epoch 126/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1525 - val_loss: 0.1192\n",
      "Epoch 127/200\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1605 - val_loss: 0.1804\n",
      "Epoch 128/200\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1707 - val_loss: 0.0987\n",
      "Epoch 129/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1617 - val_loss: 0.1576\n",
      "Epoch 130/200\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1624 - val_loss: 0.0976\n",
      "Epoch 131/200\n",
      " 34/100 [=========>....................] - ETA: 0s - loss: 0.1726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-66:\n",
      "Process ForkPoolWorker-56:\n",
      "Process ForkPoolWorker-63:\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-65:\n",
      "Process ForkPoolWorker-58:\n",
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-61:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-57:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Process ForkPoolWorker-55:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-62:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-64:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/keras/utils/data_utils.py\", line 650, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/keras/utils/data_utils.py\", line 650, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nex/Code/DL-inversekinematic/utils.py\", line 180, in make\n",
      "    jpos, tcp = self.generate_data(batch_size)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/nex/Code/DL-inversekinematic/utils.py\", line 147, in generate_data\n",
      "    frame = buildDhTcpFrame(positions[i])\n",
      "  File \"/home/nex/Code/DL-inversekinematic/utils.py\", line 180, in make\n",
      "    jpos, tcp = self.generate_data(batch_size)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nex/Code/DL-inversekinematic/utils.py\", line 112, in buildDhTcpFrame\n",
      "    dh_alpha_values[i])\n",
      "  File \"/home/nex/Code/DL-inversekinematic/utils.py\", line 147, in generate_data\n",
      "    frame = buildDhTcpFrame(positions[i])\n",
      "  File \"/home/nex/Code/DL-inversekinematic/utils.py\", line 113, in buildDhTcpFrame\n",
      "    dh_frame = np.matmul(dh_frame, tmp_dh_ith)\n",
      "  File \"/home/nex/Code/DL-inversekinematic/utils.py\", line 91, in dhIthFrame\n",
      "    [0, 0, 0, 1] ])\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py\", line 171, in __array_finalize__\n",
      "    if (isinstance(obj, matrix) and obj._getitem): return\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py\", line 147, in __new__\n",
      "    arr = N.array(data, dtype=dtype, copy=copy)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-51b90f179b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     use_multiprocessing = True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-67:\n",
      "Process ForkPoolWorker-68:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/nex/anaconda3/envs/keras-gpu/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(generator = Generator().make(20), \n",
    "                    validation_data  = Generator().make(10),\n",
    "                    steps_per_epoch  = 1000, \n",
    "                    epochs           = 200,\n",
    "                    validation_steps = 100,\n",
    "                    workers = 6,\n",
    "                    use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lo2ng.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('long.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tensf\n",
    "tensf.config.list_physical_devices('GPU') # True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions calculated\n",
      "tcp calculated\n",
      "duplicates erased\n"
     ]
    }
   ],
   "source": [
    "from utils import Drawer\n",
    "%matplotlib notebook\n",
    "pred_pos, pred_tcp = gen(20)\n",
    "out = model.predict(pred_tcp)\n",
    "denormalize(pred_pos)\n",
    "denormalize(out)\n",
    "# for i in range(10):\n",
    "#     print(pred_pos[i])\n",
    "#     print(out[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_gt, y_pred):\n",
    "\n",
    "    tcp_out = utils.buildDhTcpFrame(y_pred)\n",
    "    tcp_out = np.asarray(tcp_out.flatten())\n",
    "    tcp_out = tcp_out[0:, :12]\n",
    "    tcp_out = np.squeeze(tcp_out)\n",
    "  \n",
    "    xyz_gt = y_gt[3::4]\n",
    "    xyz_pred = tcp_out[3::4]\n",
    "    angles_gt = np.asarray([y_gt[0:3], y_gt[4:7], y_gt[8:11]])\n",
    "    angles_pred = np.asarray([tcp_out[0:3], tcp_out[4:7], tcp_out[8:11]]).flatten()\n",
    "\n",
    "    mse = 0\n",
    "    for i in range(3):\n",
    "        mse += np.mean((angles_gt[i] - angles_pred[i]) **2)\n",
    "    mse /= 3\n",
    "    dist = np.linalg.norm(xyz_gt - xyz_pred)\n",
    "    err = 0.5 * mse + 0.5 * dist\n",
    "\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4486289440153701\n"
     ]
    }
   ],
   "source": [
    "# out = model.predict(tpos)\n",
    "# pred_pos = jpos\n",
    "# denormalize(pred_pos)\n",
    "# denormalize(out)\n",
    "err = 0\n",
    "ranges = 5\n",
    "for i in range(ranges):\n",
    "    err += custom_loss(pred_tcp[i], out[i])\n",
    "err /= ranges\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "drawer = Drawer()\n",
    "\n",
    "o = 8\n",
    "drawer.draw_robot(pred_pos[o], out[o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jt, tt = generate_data(100)\n",
    "print(jt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
